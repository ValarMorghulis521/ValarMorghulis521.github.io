{"meta":{"title":"Contunued Story","subtitle":null,"description":"Like a bird in the sky","author":"zero","url":"http://yoursite.com","root":"/"},"pages":[{"title":"关于我","date":"2019-04-22T06:35:58.000Z","updated":"2019-10-12T14:07:18.670Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"有一个夜晚我烧毁了所有的记忆 从此我的梦就透明了 有一个早晨我扔掉了所有的昨天 从此我的脚步就轻盈了"},{"title":"分类","date":"2019-04-22T06:35:02.000Z","updated":"2019-10-11T03:35:44.717Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-04-22T06:35:49.000Z","updated":"2019-10-11T03:35:08.726Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringMVC","slug":"SpringMVC","date":"2020-02-29T03:49:09.000Z","updated":"2020-03-01T14:29:27.366Z","comments":true,"path":"2020/02/29/SpringMVC/","link":"","permalink":"http://yoursite.com/2020/02/29/SpringMVC/","excerpt":"","text":"Spring MVC属于SpringFrameWork的后续产品，已经融合在Spring Web Flow里面。 Spring的MVC框架主要由前端控制器、处理器映射、处理器(控制器)、视图解析器、视图组成。 原理图 组件说明以下组件通常使用框架提供实现： DispatcherServlet 前端控制器： Spring提供的前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。 HandlerMapping 处理器映射器： 处理器映射,能够完成客户请求到Controller映射。例如：配置文件方式，实现接口方式，注解方式等。 Controller接口 处理器： 需要为并发用户处理上述请求，因此实现Controller接口时，必须保证线程安全并且可重用。Controller将处理用户请求，这和Struts Action扮演的角色是一致的。一旦Controller处理完用户请求，则返回ModelAndView对象给DispatcherServlet前端控制器，ModelAndView中包含了模型（Model）和视图（View）。从宏观角度考虑，DispatcherServlet是整个Web应用的控制器；从微观考虑，Controller是单个Http请求处理过程中的控制器，而ModelAndView是Http请求过程中返回的模型（Model）和视图（View）。 ViewResolver 视图解析器： 通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。 HandlerAdapter 处理器适配器： 按照特定规则（HandlerAdapter要求的规则）去执行Handler通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。 SpringMVC流程 用户发送请求至前端控制器DispatcherServlet。 DispatcherServlet收到请求调用HandlerMapping处理器映射器。 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 DispatcherServlet调用HandlerAdapter处理器适配器。 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。 Controller执行完成返回ModelAndView。 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。 ViewReslover解析后返回具体View。 DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。 DispatcherServlet响应用户。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/categories/Spring/"}],"tags":[{"name":"MVC","slug":"MVC","permalink":"http://yoursite.com/tags/MVC/"}]},{"title":"Java基础总结","slug":"Java基础总结","date":"2020-01-04T02:49:26.000Z","updated":"2020-02-29T12:02:58.117Z","comments":true,"path":"2020/01/04/Java基础总结/","link":"","permalink":"http://yoursite.com/2020/01/04/Java基础总结/","excerpt":"","text":"面向对象和面向过程的区别 面向对象和面向过程最本质的区别在于考虑问题的出发点不同：面向过程是以事件流程为考虑问题的出发点，而面向对象则是以参与事件对象为考虑问题的出发点，所以面向对象在处理问题时更加灵活。目前，面向过程的语言更多被用于处理底层业务，而面向对象编程则更多用于实现一些业务逻辑复杂的大型系统。 面向过程性能比面向对象高。 因为类调用时需要实例化，开销比较大，比较消耗资源，所以当性能是最重要的考量因素的时候，比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发。 面向对象易维护、易复用、易扩展。 因为面向对象有封装、继承、多态性的特性，继承的核心特点是复用，避免模块间重复和模块内重复的问题，而多态的特点是灵活，所以可以设计出低耦合的系统，使系统更加灵活、更加易于维护。但是，面向对象性能比面向过程低。 Java和C++的区别? 都是面向对象的语言，都支持封装、继承和多态 Java 不提供指针来直接访问内存，程序内存更加安全 Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。 Java 有自动内存管理机制，不需要程序员手动释放无用内存 构造器 Constructor 是否可被 override?？ 父类的私有属性和构造方法并不能被继承，所以 Constructor 也就不能被 override（重写）,但是可以 overload（重载）,所以你可以看到一个类中有多个构造函数的情况。 重载和重写的区别 重载： 发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。 重写： 发生在父子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；如果父类方法访问修饰符为 private 则子类就不能重写该方法。 Java 面向对象编程三大特性: 封装 继承 多态 封装封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。 继承继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。 注意子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。 多态所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。 在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。 String StringBuffer 和 StringBuilder 的区别是什么？可变性 String 类中使用 final 关键字修饰字符数组来保存字符串，private final char value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串 char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。 线程安全性 String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 自动装箱与拆箱 装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型 int和Integer的区别 Integer是int的包装类，int则是java的一种基本数据类型 Integer变量必须实例化后才能使用，而int变量不需要 Integer实际是对象的引用，当new一个Integer时，实际上是生成一个指针指向此对象；而int则是直接存储数据值 Integer的默认值是null，int的默认值是0 延伸： 由于Integer变量实际上是对一个Integer对象的引用，所以两个通过new生成的Integer变量永远是不相等的（因为new生成的是两个对象，其内存地址不同）。 123Integer i = new Integer(100);Integer j = new Integer(100);System.out.print(i == j); //false Integer变量和int变量比较时，只要两个变量的值是向等的，则结果为true（因为包装类Integer和基本数据类型int比较时，java会自动拆包装为int，然后进行比较，实际上就变为两个int变量的比较） 123Integer i = new Integer(100);int j = 100；System.out.print(i == j); //true 对于两个非new生成的Integer对象，进行比较时，如果两个变量的值在区间-128到127之间，则比较结果为true，如果两个变量的值不在此区间，则比较结果为false 123Integer i = 100;Integer j = 100;System.out.print(i == j); //true 123Integer i = 128;Integer j = 128;System.out.print(i == j); //false java在编译Integer i = 100 ;时，会翻译成为Integer i = Integer.valueOf(100)；，而java API中对Integer类型的valueOf的定义如下： 1234567public static Integer valueOf(int i)&#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)&#123; return IntegerCache.cache[i + (-IntegerCache.low)]; &#125; return new Integer(i);&#125; 在 Java 中定义一个不做事且没有参数的构造方法的作用 Java 程序在执行子类的构造方法之前，如果没有用 super() 来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用 super() 来调用父类中特定的构造方法，则编译时将发生错误，因为 Java 程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。 接口和抽象类的区别是什么？ 接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。 接口中除了static、final变量，不能有其他变量，而抽象类中则不一定。 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过extends关键字扩展多个接口。 接口方法默认修饰符是public，抽象方法可以有public、protected和default这些修饰符（抽象方法就是为了被重写所以不能使用private关键字修饰！）。 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。 备注：在JDK8中，接口也可以定义静态方法，可以直接用接口名调用。实现类和实现是不可以调用的。如果同时实现两个接口，接口中定义了一样的默认方法，则必须重写，不然会报错。 一个类的构造方法的作用是什么? 若一个类没有声明构造方法，该程序能正确执行吗? 为什么? 主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。 构造方法有哪些特性？ 名字与类名相同。 没有返回值，但不能用void声明构造函数。 生成类的对象时自动执行，无需调用。 == 与 equals(重要) == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象(基本数据类型==比较的是值，引用数据类型==比较的是内存地址)。 equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 情况1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 hashCode 与 equals (重要) hashCode() 的作用就是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 在散列表中才有用，在其它情况下没用 在散列表中hashCode() 的作用是获取对象的散列码，进而确定该对象在散列表中的位置。 如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。 如果两个对象相等，则hashcode一定也是相同的,但是两个对象有相同的hashcode值，它们也不一定是相等的，因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 关于 final 关键字的一些总结 final关键字主要用在三个地方：变量、方法、类。 对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。 当用final修饰一个类时，表明这个类不能被继承。final类中的所有成员方法都会被隐式地指定为final方法。 使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。 static 关键字static 关键字主要有以下四种使用场景： 修饰成员变量和成员方法: 被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享，可以并且建议通过类名调用。被static 声明的成员变量属于静态成员变量，静态变量 存放在 Java 内存区域的方法区。调用格式：类名.静态变量名 类名.静态方法名() 静态代码块: 静态代码块定义在类中方法外, 静态代码块在非静态代码块之前执行(静态代码块—&gt;非静态代码块—&gt;构造方法)。 该类不管创建多少对象，静态代码块只执行一次.如果父类A和子类B都有静态代码块，非静态代码块和构造方法，如果实例化一个子类那么他们的执行顺序：A的静态代码块-&gt;B的静态代码块-&gt;父类的非静态代码块—&gt;父类的构造方法-&gt;子类的非静态代码块—&gt;子类的构造方法 静态内部类（static修饰类的话只能修饰内部类）： 静态内部类与非静态内部类之间存在一个最大的区别: 非静态内部类在编译完成之后会隐含地保存着一个引用，该引用是指向创建它的外围类，但是静态内部类却没有。没有这个引用就意味着：1. 它的创建是不需要依赖外围类的创建。2. 它不能使用任何外围类的非static成员变量和方法。 静态导包(用来导入类中的静态资源，1.5之后的新特性): 格式为：import static 这两个关键字连用可以指定导入某个类中的指定静态资源，并且不需要使用类名调用类中静态成员，可以直接使用类中静态成员变量和成员方法。 补充：静态方法属于类本身，非静态方法属于从该类生成的每个对象。 如果您的方法执行的操作不依赖于其类的各个变量和方法，请将其设置为静态（这将使程序的占用空间更小）。 否则，它应该是非静态的。 Servlet接口中有哪些方法及Servlet生命周期探秘生命周期： Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其init()方法进行Servlet的初始化；请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求对应的doGet或doPost等方法；当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的destroy()方法。init方法和destroy方法只会执行一次，service方法客户端每次请求Servlet都会执行。Servlet中有时会用到一些需要初始化与销毁的资源，因此可以把初始化资源的代码放入init方法中，销毁资源的代码放入destroy方法中，这样就不需要每次处理客户端的请求都要初始化与销毁资源。","categories":[],"tags":[]},{"title":"ArrayList的底层实现原理","slug":"ArrayList的底层实现原理","date":"2020-01-03T09:38:50.000Z","updated":"2020-02-28T05:51:23.990Z","comments":true,"path":"2020/01/03/ArrayList的底层实现原理/","link":"","permalink":"http://yoursite.com/2020/01/03/ArrayList的底层实现原理/","excerpt":"","text":"ArrayList简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。 在我们学数据结构的时候就知道了线性表的顺序存储，插入删除元素的时间复杂度为O（n）,求表长以及增加元素，取第 i 元素的时间复杂度为O（1） ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 ArrayList 实现了RandomAccess 接口， RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 ArrayList 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。 ArrayList 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。 和 Vector 不同，ArrayList 中的操作不是线程安全的！所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者 CopyOnWriteArrayList。 ArrayList核心源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498package java.util;import java.util.function.Consumer;import java.util.function.Predicate;import java.util.function.UnaryOperator;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //创建空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; /** *默认构造函数，DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10 */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; // elementData = c.toArray(); //如果指定集合元素个数不为0 if ((size = elementData.length) != 0) &#123; // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断， //这里用到了反射里面的getClass()方法 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 用空数组代替 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125;//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; //判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //比较minCapacity和 MAX_ARRAY_SIZE private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; /** *返回此列表中的元素数。 */ public int size() &#123; return size; &#125; /** * 如果此列表不包含元素，则返回 true 。 */ public boolean isEmpty() &#123; //注意=和==的区别 return size == 0; &#125; /** * 如果此列表包含指定的元素，则返回true 。 */ public boolean contains(Object o) &#123; //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 return indexOf(o) &gt;= 0; &#125; /** *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 */ public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) //equals()方法比较 if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。. */ public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。） */ public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度 v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // 这不应该发生，因为我们是可以克隆的 throw new InternalError(e); &#125; &#125; /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; /** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。 *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。 *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。 *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） */ @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // 新建一个运行时类型的数组，但是ArrayList数组的内容 return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //调用System提供的arraycopy()方法实现数组之间的复制 System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; // Positional Access Operations @SuppressWarnings(\"unchecked\") E elementData(int index) &#123; return (E) elementData[index]; &#125; /** * 返回此列表中指定位置的元素。 */ public E get(int index) &#123; rangeCheck(index); return elementData(index); &#125; /** * 用指定的元素替换此列表中指定位置的元素。 */ public E set(int index, E element) &#123; //对index进行界限检查 rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; //返回原来在这个位置的元素 return oldValue; &#125; /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()这个实现数组之间复制的方法一定要看一下，下面就用到了arraycopy()方法实现数组自己复制自己 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; /** * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。 */ public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work //从列表中删除的元素 return oldValue; &#125; /** * 从列表中删除指定元素的第一个出现（如果存在）。 如果列表不包含该元素，则它不会更改。 *返回true，如果此列表包含指定的元素 */ public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; /** * 从列表中删除所有元素。 */ public void clear() &#123; modCount++; // 把数组中所有的元素的值设为null for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; /** * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。 */ public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; /** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; /** * 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。 *将任何后续元素移动到左侧（减少其索引）。 */ protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; /** * 检查给定的索引是否在范围内。 */ private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * add和addAll使用的rangeCheck的一个版本 */ private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /** * 返回IndexOutOfBoundsException细节信息 */ private String outOfBoundsMsg(int index) &#123; return \"Index: \"+index+\", Size: \"+size; &#125; /** * 从此列表中删除指定集合中包含的所有元素。 */ public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); //如果此列表被修改则返回true return batchRemove(c, false); &#125; /** * 仅保留此列表中包含在指定集合中的元素。 *换句话说，从此列表中删除其中不包含在指定集合中的所有元素。 */ public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125; /** * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(\"Index: \"+index); return new ListItr(index); &#125; /** *返回列表中的列表迭代器（按适当的顺序）。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; /** *以正确的顺序返回该列表中的元素的迭代器。 *返回的迭代器是fail-fast 。 */ public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; ArrayList源码分析数组为什么要用 transient修饰？1234/*** 保存ArrayList数据的数组*/transient Object[] elementData; // non-private to simplify nested class access transient 关键字的作用是禁止虚拟机对该属性进行默认的序列化，ArrayList要这样做？ArrayList 序列化的方法 12345678910111213141516171819private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; //把虚拟机能默认序列化的元素进行序列化 s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // 按正确顺序写出所有有效的元素，因为数组不一定放满，没有放满的部分是不需要序列化的，有利于提高性能 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; System.arraycopy()和Arrays.copyOf()方法 通过上面源码我们发现这两个实现数组复制的方法被广泛使用而且很多地方都特别巧妙。比如下面add(int index, E element)方法就很巧妙的用到了arraycopy()方法让数组自己复制自己实现让index开始之后的所有成员后移一个位置: 123456789101112131415/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 又如toArray()方法中用到了copyOf()方法 12345678910/** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */public Object[] toArray() &#123;//elementData：要复制的数组；size：要复制的长度 return Arrays.copyOf(elementData, size);&#125; 两者联系与区别联系：看两者源代码可以发现copyOf()内部调用了System.arraycopy()方法区别： arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf()是系统自动在内部新建一个数组，并返回该数组。ArrayList 核心扩容技术1234567891011121314151617181920212223242526272829303132333435363738//下面是ArrayList的扩容机制//ArrayList的扩容机制提高了性能，如果每次只扩充一个，//那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; //判断是否需要扩容,上面两个方法都要调用 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 如果说minCapacity也就是所需的最小容量大于保存ArrayList数据的数组的长度的话，就需要调用grow(minCapacity)方法扩容。 //这个minCapacity到底为多少呢？举个例子在添加元素(add)方法中这个minCapacity的大小就为现在数组的长度加1 if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; 12345678910111213141516171819202122/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123; //elementData为保存ArrayList数据的数组 ///elementData.length求数组长度elementData.size是求数组中的元素个数 // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 扩容机制代码已经做了详细的解释。另外值得注意的是大家很容易忽略的一个运算符：移位运算符 简介：移位运算符就是在二进制的基础上对数字进行平移。按照平移的方向和填充数字的规则分为三种:&lt;&lt;(左移)、&gt;&gt;(带符号右移)和&gt;&gt;&gt;(无符号右移)。 作用：对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 比如这里：int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。 另外需要注意的是： java 中的length 属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. java 中的length()方法是针对字 符串String说的,如果想看这个字符串的长度则用到 length()这个方法. .java 中的size()方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看! ArrayList经典Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package list;import java.util.ArrayList;import java.util.Iterator;public class ArrayListDemo &#123; public static void main(String[] srgs)&#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); System.out.printf(\"Before add:arrayList.size() = %d\\n\",arrayList.size()); arrayList.add(1); arrayList.add(3); arrayList.add(5); arrayList.add(7); arrayList.add(9); System.out.printf(\"After add:arrayList.size() = %d\\n\",arrayList.size()); System.out.println(\"Printing elements of arrayList\"); // 三种遍历方式打印元素 // 第一种：通过迭代器遍历 System.out.print(\"通过迭代器遍历:\"); Iterator&lt;Integer&gt; it = arrayList.iterator(); while(it.hasNext())&#123; System.out.print(it.next() + \" \"); &#125; System.out.println(); // 第二种：通过索引值遍历 System.out.print(\"通过索引值遍历:\"); for(int i = 0; i &lt; arrayList.size(); i++)&#123; System.out.print(arrayList.get(i) + \" \"); &#125; System.out.println(); // 第三种：for循环遍历 System.out.print(\"for循环遍历:\"); for(Integer number : arrayList)&#123; System.out.print(number + \" \"); &#125; // toArray用法 // 第一种方式(最常用) Integer[] integer = arrayList.toArray(new Integer[0]); // 第二种方式(容易理解) Integer[] integer1 = new Integer[arrayList.size()]; arrayList.toArray(integer1); // 抛出异常，java不支持向下转型 //Integer[] integer2 = new Integer[arrayList.size()]; //integer2 = arrayList.toArray(); System.out.println(); // 在指定位置添加元素 arrayList.add(2,2); // 删除指定位置上的元素 arrayList.remove(2); // 删除指定元素 arrayList.remove((Object)3); // 判断arrayList是否包含5 System.out.println(\"ArrayList contains 5 is: \" + arrayList.contains(5)); // 清空ArrayList arrayList.clear(); // 判断ArrayList是否为空 System.out.println(\"ArrayList is empty: \" + arrayList.isEmpty()); &#125;&#125;","categories":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/categories/容器/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://yoursite.com/tags/ArrayList/"}]},{"title":"AQS原理以及AQS同步组件","slug":"AQS原理以及AQS同步组件","date":"2020-01-02T06:33:52.000Z","updated":"2020-01-02T12:18:25.160Z","comments":true,"path":"2020/01/02/AQS原理以及AQS同步组件/","link":"","permalink":"http://yoursite.com/2020/01/02/AQS原理以及AQS同步组件/","excerpt":"","text":"AQS 简单介绍AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。 AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 AQS 原理AQS 原理概览AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。 AQS(AbstractQueuedSynchronizer)原理图： AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过protected类型的getState，setState，compareAndSetState进行操作 123456789101112//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; AQS 对资源的共享方式AQS定义两种资源共享方式 Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在上层已经帮我们实现好了。 AQS底层使用了模板方法模式同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用，下面简单的给大家介绍一下模板方法模式，模板方法模式是一个很容易理解的设计模式之一。 模板方法模式是基于”继承“的，主要是为了在不改变模板结构的前提下在子类中重新定义模板中的内容以实现复用代码。举个很简单的例子假如我们要去一个地方的步骤是：购票buyTicket()-&gt;安检securityCheck()-&gt;乘坐某某工具回家ride()-&gt;到达目的地arrive()。我们可能乘坐不同的交通工具回家比如飞机或者火车，所以除了ride()方法，其他方法的实现几乎相同。我们可以定义一个包含了这些方法的抽象类，然后用户根据自己的需要继承该抽象类然后修改 ride()方法。 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法： 12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 AQS 组件总结 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch （倒计时器）： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。 CyclicBarrier(循环栅栏)： CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 Reference 《深入理解 Java 虚拟机》 《实战 Java 高并发程序设计》 《Java并发编程的艺术》 http://www.cnblogs.com/waterystone/p/4920797.html https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html https://www.journaldev.com/1076/java-threadlocal-example","categories":[{"name":"Java多线程与并发","slug":"Java多线程与并发","permalink":"http://yoursite.com/categories/Java多线程与并发/"}],"tags":[]},{"title":"乐观锁和悲观锁","slug":"乐观锁和悲观锁","date":"2020-01-02T06:33:01.000Z","updated":"2020-01-02T07:21:26.951Z","comments":true,"path":"2020/01/02/乐观锁和悲观锁/","link":"","permalink":"http://yoursite.com/2020/01/02/乐观锁和悲观锁/","excerpt":"","text":"何谓悲观锁与乐观锁 乐观锁对应于生活中乐观的人总是想着事情往好的方向发展，悲观锁对应于生活中悲观的人总是想着事情往坏的方向发展。这两种人各有优缺点，不能不以场景而定说一种人好于另外一种人。 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁 （共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程，一般多写的场景下用悲观锁就比较合适。) 。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量 。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁常见的两种实现方式 乐观锁一般会使用版本号机制或CAS算法实现。 1. 版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。 这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。 2.CAS算法即ccompare and swap（比较与交换）,是一种有名的无锁算法。 无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 乐观锁的缺点 ABA 问题是乐观锁一个常见的问题 1.ABA 问题如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。 JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 2.循环时间长开销大自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 3.只能保证一个共享变量的原子操作CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。 CAS与synchronized的使用情景 简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多） 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 J.U.C的atomic包提供了常用的原子性数据类型以及引用、数据等相关原子类型和更新操作工具，是很多线程安全程序的首选","categories":[{"name":"Java多线程与并发","slug":"Java多线程与并发","permalink":"http://yoursite.com/categories/Java多线程与并发/"}],"tags":[]},{"title":"设计模式","slug":"设计模式","date":"2019-12-18T04:30:55.000Z","updated":"2020-03-01T14:21:26.220Z","comments":true,"path":"2019/12/18/设计模式/","link":"","permalink":"http://yoursite.com/2019/12/18/设计模式/","excerpt":"","text":"总结一下之前的项目中出现的设计模式 单例模式单例模式是Java最简单的模式之一；这种类型的设计模式属于创建型模式，它提供一种创建对象的最佳方式。 注意： 单例类只能有一个实例 单例类必须自己创建自己的唯一实例 单例类给所有其他对象提供这一实例 主要解决：一个全局使用的类频繁的创建与销毁。所以需要控制实例数目，节省系统资源 ； 如何实现：系统判断是否已经有这个单例，如果有则返回，如果没有则创建，创建的实例静态私有，构造函数也是私有， 使用场景： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 代码实现双检锁/双重校验锁（DCL,即 double-checker locking） 注意事项：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 1234567891011121314public class Singleton&#123; private volatile static Singleton singleton; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(singleton == null)&#123; synchronized(Singleton.class)&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 项目中用到的代码例子 123456789101112131415161718192021222324252627282930313233343536373839public class ParseXmlService &#123; private static ParseXmlService instance; private IParseXmlManager mgr; /** * 通过实现xml2sheets业务方法,解析xml * * @param cls * 类 * @param key * xml mapping配置文件的key值 * @param filePath * xml配置文件路径,包含文件名 * @return 解析的对象 * @see ParseXmlManagerImpl#xml2object(Class, String, String) * @throws ParseXMLException * 解析出错抛异常 */ public Object xml2object(Class cls, String key, String filePath) throws ParseXMLException &#123; return this.mgr.xml2object(cls, key, filePath); &#125; private ParseXmlService() &#123; mgr = (IParseXmlManager) ApplicationContextHolder.getInstance() .getBean(&quot;ParseXmlManagerImpl&quot;); &#125; public static ParseXmlService create() &#123; if (instance == null) &#123; instance = new ParseXmlService(); &#125; return instance; &#125;&#125; 工厂模式工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式 主要解决：解决接口选择的问题 ，明确地计划不同条件下创建不同实例时 如何实现：让其子类实现工厂接口，返回的也是一个抽象的产品，创建过程在其子类执行。 使用场景： 日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 计一个连接服务器的框架，需要三个协议，”POP3”、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口。 优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。 缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 代码实现 创建建一个接口ID2NameDAO.java 12345678public interface ID2NameDAO &#123; /** * id转name * @param id 一般为表中的主键 * @return 返回主键对应的name(自定义) */ public String id2Name(String id); &#125; 创建实现接口的实体类 TawSystemProvinceDaoJdbcForDXLTE.java 123456789@Overridepublic class TawSystemProvinceDaoJdbcForDXLTE implements TawSystemProvinceDaoForDXLTE,ID2NameDAO&#123; @Override public String id2Name(String id) throws DictDAOException &#123; return CossUtil.getCfProvinceMgr().provinceId2Name(id); &#125;&#125; TawSystemCityDaoJdbcForDXLTE.java 123456789101112@Overridepublic class TawSystemCityDaoJdbcForDXLTE implements TawSystemCityDaoForDXLTE,ID2NameDAO &#123; @Override public String id2Name(String id) throws DictDAOException &#123; String cityName = &quot;&quot;; if(StringUtils.isEmpty(id))&#123; String cityId = id.replaceAll(&quot; &quot;, &quot;&quot;); cityName = CossUtil.getCfCityMgr().cityId2Name(cityId); &#125; return cityName; &#125;&#125; TawSystemUserDaoHibernate.java 1234567@Overridepublic String id2Name(final String id) throws DictDAOException &#123; HibernateCallback callback = new HibernateCallback() &#123; TawSystemUser user = null; user = (TawSystemUser) getHibernateTemplate().execute(callback); return user.getUsername(); &#125; 创建一个工厂，生成基于给定信息的实体类对象 12345678910111213141516171819public class ID2NameServiceImpl extends BaseManager implements ID2NameService &#123; public String id2Name(String id, String beanId) &#123; String name = null; try &#123; // 通过beanid取bean ID2NameDAO dao = (ID2NameDAO) ApplicationContextHolder.getInstance().getBean(beanId); // 转换后的name name = dao.id2Name(id); &#125; catch (Exception e) &#123; // 取id2name失败后的name默认值 name = Util.idNoName(); &#125; if (name == null || &quot;&quot;.equals(name)) &#123; name = Util.idNoName(); &#125; return name; &#125;&#125; 配置bean的信息 12345678&lt;bean id=&quot;ID2NameGetServiceCatch&quot; parent=&quot;dictBaseCacheProxy&quot;&gt; &lt;property name=&quot;target&quot;&gt; &lt;bean class=&quot;com.boco.eoms.commons.system.dict.service.impl.ID2NameServiceImpl&quot;&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; 使用该工厂123ID2NameService name = (ID2NameService) ApplicationContextHolder.getInstance().getBean(&quot;ID2NameGetServiceCatch&quot;);String provinceName = name.id2Name(mainProvince, &quot;tawSystemProvinceDaoForDXLTE&quot;);String regionName = name.id2Name(mainCity, &quot;tawSystemRegionDaoForDXLTE&quot;); 抽象工厂模式抽象工厂模式是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式。 主要解决：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品，主要解决接口选择的问题。 如何实现：在一个产品族里面，定义多个产品。 使用场景：一个继承体系中，如果存在着多个等级结构（即存在着多个抽象类），并且分属各个等级结构中的实现类之间存在着一定的关联或者约束，就可以使用抽象工厂模式。假如各个等级结构中的实现类之间不存在关联或约束，则使用多个独立的工厂来对产品进行创建，则更合适一点。 抽象工厂模式也就是不仅生产鼠标，同时生产键盘。 也就是 PC 厂商是个父类，有生产鼠标，生产键盘两个接口。 戴尔工厂，惠普工厂继承它，可以分别生产戴尔鼠标+戴尔键盘，和惠普鼠标+惠普键盘。 创建工厂时，由戴尔工厂创建。 后续工厂.生产鼠标()则生产戴尔鼠标，工厂.生产键盘()则生产戴尔键盘。 代理模式在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 主要解决：直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。想在访问一个类时做一些控制 如何实现：增加中间层；实现与被代理类组合。 简单例子代码实现： 新建一个接口实现pay方法 真实实现类和代理类都要实现该方法 在代理类中注入真实实现类，在代理类的实现方法pay()中调用真实实现类的pay()方法，然后增加做自己的业务逻辑 123public interface Payment&#123; void pay();&#125; 1234567public RealPayment implements Payment&#123; @Override public void pay()&#123; System.out.println(&quot;作为用户我只关心支付&quot;) &#125;&#125; 1234567891011121314151617public AliPay implements Payment&#123; private Payment payment; public AliPay(Payment payment) public void beforePay()&#123; System.out.println(&quot;从招行取款&quot;) &#125; @Override public void pay()&#123; beforePay()； payment.pay(); afterPay(); &#125; public void afterPay()&#123; System.out.println(&quot;支付给慕课网&quot;) &#125;&#125; 12Payment proxy = new AliPay(new RealPayment);proxy.pay(); 模板模式在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。模板模式也称钩子模式（hook），就是动态加载，是多态的一种应用。 主要解决：一些方法通用，却在每一个子类都重新写了这一方法。 如何实现：有一些通用的方法在抽象类实现，其他步骤在子类实现。 代码实现： 创建一个抽象类，它的模板方法被设置为 final。 123456789101112131415161718public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125; 创建扩展了上述类的实体类 1234567891011121314151617public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Cricket Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Cricket Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Cricket Game Started. Enjoy the game!\"); &#125;&#125; 使用 Game 的模板方法 play() 来演示游戏的定义方式。 12345678910public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125; MVC模式MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。 M-Model 模型（完成业务逻辑：有javaBean构成，service+dao+entity） V-View 视图（做界面的展示 jsp，html……） C-Controller 控制器（接收请求—&gt;调用模型—&gt;根据结果派发页面） MVC的原理图：","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/categories/设计模式/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://yoursite.com/tags/单例模式/"},{"name":"工厂模式","slug":"工厂模式","permalink":"http://yoursite.com/tags/工厂模式/"},{"name":"代理模式","slug":"代理模式","permalink":"http://yoursite.com/tags/代理模式/"}]},{"title":"容器部署","slug":"容器部署","date":"2019-11-19T05:20:36.000Z","updated":"2019-11-24T04:43:05.889Z","comments":true,"path":"2019/11/19/容器部署/","link":"","permalink":"http://yoursite.com/2019/11/19/容器部署/","excerpt":"","text":"实现IntelliJ IDEA快速部署到远程docker IntelliJ IDEA安装Docker插件Docker 增加一个docker远程连接，此时连接的是我虚拟机上的docker 在项目的根目录下创建Dockerfile文件 1234567891011121314#指定基础镜像，在其上进行定制FROM hub.c.163.com/library/java:8-alpine#维护者信息MAINTAINER sunchenming &lt;scm_5@outlook.com&gt;#添加target/*.jar 到容器里ADD target/*.jar app.jar#声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务EXPOSE 8761#指定容器启动程序及参数 &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot;ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;app.jar&quot;] 打开IDEA右上角的 Run/Debug Configurations，新增Docker启动方式，然后在配置中填写如下信息 点击启动，构建成功 查看docker镜像 将镜像推送到阿里云的镜像个人中心 123$ sudo docker login --username=sunchenming registry.cn-hangzhou.aliyuncs.com$ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/monster_body/springcloud_eureka:[镜像版本号]$ sudo docker push registry.cn-hangzhou.aliyuncs.com/monster_body/springcloud_eureka:[镜像版本号] Ranch Rancher入门：https://www.jianshu.com/p/3a492440c89b Rancher是使用一系列的Docker容器进行部署的。运行Rancher跟启动两个容器一样简单。一个容器作为管理服务器部署，另外一个作为集群节点的Agent部署 使用docker安装 1sudo docker run -d --restart=unless-stopped -p 8080:8080 rancher/server:stable 确认安全组或防火墙允许以下通讯:与其他所有主机之间的 UDP 端口 500 和 4500 (用于IPsec网络) 防火墙如何开启和关闭？ 123456sudo systemctl start firewalldsudo systemctl stop firewalldfirewall-cmd --permanent --zone=public --add-port=4500/udp 开启nc -vuz 192.168.1.106 500firewall-cmd --reload //更新防火墙规则 在Ranch中添加主机，启动一台注册了Rancher-angent的主机 在应用选项-添加应用-springcloud 在springcloud应用下去添加服务 项目版本升级","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[]},{"title":"链路监控","slug":"链路监控","date":"2019-11-18T12:13:22.000Z","updated":"2019-11-19T05:18:39.602Z","comments":true,"path":"2019/11/18/链路监控/","link":"","permalink":"http://yoursite.com/2019/11/18/链路监控/","excerpt":"","text":"Spring Cloud Sleuth 添加sleuth的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; 把 org.springframework.cloud.netflix.feign包 调整日志级别，添加配置 123logging: level: org.springframework.cloud.netflix.feign: debug 调用order服务的创建订单接口1INFO [order,5b8dbc3132a06305,5b8dbc3132a06305,false] 8940 --- [nio-8083-exec-2] c.netflix.config.ChainedDynamicProperty : sleuth打印的四个值[服务名,id1,id2,true/false]: id1: trace id,一条链路里面最多包含一条trans id，即一条链路的唯一 标识； id2: span id，一条链路一面可以包含多个span id，它是一个基本的工作单元（比如发送一个HTTP请求）； true：将信息输出给其他服务（如zipkin），反之为false Zipkin 链路可视化工具,集成Zinpin的步骤： docker 下安装 1docker run -d -p 9411:9411 openzipkin/zipkin 添加Zipkin的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 注：以上依赖包等同于 spring-cloud-starter-sleuth + spring-cloud-sleuth-zipkin的整合，因此原来的spring-cloud-starter-sleuth依赖可直接注释掉 配置参数 123456zipkin: base-url: http://192.168.1.106:9411///统计日志的百分比为全部，如果10%填0.1sleuth: sampler: percentage: 1 调用下单接口，访问 Zipkin地址 http://192.168.1.106:9411 OpenTracing OpenTracing是语义规范、是跨语言的，zipkin是根据这个规范的。 几个重要的概念：traceId：在哪生成的idspanId：下一次的请求idparentId：上一次请求的id 事件类型把一个请求的生命周期划成四种事件类型 cs(Client Send):客户端发起请求的时间 cr(Client Received):客户端收到处理完请求的时间 ss(Server Send):服务端处理完逻辑的时间 sr(Server Received):服务端收到调用端请求的时间","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[{"name":"链路监控","slug":"链路监控","permalink":"http://yoursite.com/tags/链路监控/"},{"name":"Spring Cloud Sleuth","slug":"Spring-Cloud-Sleuth","permalink":"http://yoursite.com/tags/Spring-Cloud-Sleuth/"},{"name":"Zipkin","slug":"Zipkin","permalink":"http://yoursite.com/tags/Zipkin/"}]},{"title":"服务容错Hystrix","slug":"服务容错Hystrix","date":"2019-11-18T02:55:46.000Z","updated":"2019-11-18T12:11:54.615Z","comments":true,"path":"2019/11/18/服务容错Hystrix/","link":"","permalink":"http://yoursite.com/2019/11/18/服务容错Hystrix/","excerpt":"","text":"防雪崩利器，雪崩就是A调用B，B调用C，C要是不好了，B也不好了 服务降级 优先核心服务，非核心业务不可用或弱可用 通过HystrixCommand注解指定 fallbackMethod（回退函数）中具体实现降级逻辑 实现步骤： 引入hystrix Jar包依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 启动类加注解@EnableCircuitBreaker ，或者可直接使用@SpringCloudApplication注解，此注解包含多个注解@SpringBootApplication、@EnableDiscoveryClient、@EnableCircuitBreaker 方法体上增加 @HystrixCommand(fallbackMethod = “fallback”) 注解，fallback是一个方法名，调用其他服务失败或方法内部抛出异常时会运行这个方法类上加@DefaultProperties(defaultFallback = “defaultFallback”) 注解 出现异常可默认调用defaultFallback方法处理 1234567891011121314@RestController@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)public class HystrixController &#123; @HystrixCommand(fallbackMethod = &quot;fallback&quot;) @GetMapping(&quot;/getProductInfoList&quot;) public String getProductInfoList()&#123; RestTemplate restTemplate = new RestTemplate(); return restTemplate.postForObject(&quot;http://127.0.0.1:8081/product/listForOrder&quot;, Arrays.asList(&quot;157875196366160022&quot;),String.class); &#125; private String fallback()&#123; return &quot;太拥挤了，请稍后再试&quot;; &#125;&#125; 超时设置 超时时间设置：方法上增加注解 123@HystrixCommand(commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.thread.timeoutInMilliseconds&quot;,value = &quot;3000&quot;) &#125;) 在yml文件中设置 12345678910111213hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 #给getProductInfoList方法单独设置 getProductInfoList: execution: isolation: thread: timeoutInMilliseconds: 1000 有时候第一次启动时都会超时。原因：因为第一次有懒加载的过程，造成了超时。解决方式：配置一下超时时间长一点就好了，如图 熔断 实现进程隔离，容器之间互不影响！ Hystrix依赖隔离：实现的是线程池的隔离，会为每个hystrix command创建独立的线程池，这样就是哪个在hystrix command包装的依赖服务出现延迟较高的情况，也只是对该依赖服务的调用产生影响，并不会拖慢其他服务。 使用了hystrix command把每个函数包装称hystrix mini时，hystrix框架就会自动为这个函数实现依赖隔离。所以，依赖隔离、服务降级在使用时都是一体化实现的！（一体化？？） 这样，利用hystrix来实现服务容错保护在编程模型上就非常方便了！ 依赖隔离： 线程池隔离 Hystrix 自动实现了依赖隔离 设置熔断的重要参数123456@HystrixCommand(commandProperties = &#123; @HystrixProperty(name=&quot;circuitBreaker.enabled&quot;,value = &quot;true&quot;), // 设置熔断 @HystrixProperty(name=&quot;circuitBreaker.requestVolumeThreshold&quot;,value = &quot;10&quot;),//最小请求数 @HystrixProperty(name=&quot;circuitBreaker.sleepWindowInMilliseconds&quot;,value = &quot;10000&quot;),//休眠时间窗口 @HystrixProperty(name=&quot;circuitBreaker.errorThresholdPercentage&quot;,value = &quot;60&quot;) //错误百分比 ，比如百分之70，就是10个请求有7个错误&#125;) Circuit Breaker：断路器 ，当故障达到一定值就跳闸 断路器状态机： closed，熔断器关闭状态，调用失败次数累计到一定阈值/比例，启动熔断机制，进入打开状态 open，熔断器打开状态，对服务直接返回错误，直接服务降级 half open，熔断器打开状态达到了一定的时间，会进入半熔断状态，允许定量的服务请求主逻辑。如果都调用成功，或者一定比例成功，则认为恢复，关闭熔断器；否则，熔断器回到打开状态 添加熔断的可视化组件 hystrix-dashboard 引入hystrix-dashboard包依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 启动类添加@EnableHystrixDashboard 注解 访问 http://localhost:8083/hystrix 添加配置进入","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[{"name":"服务容错","slug":"服务容错","permalink":"http://yoursite.com/tags/服务容错/"},{"name":"Hystrix","slug":"Hystrix","permalink":"http://yoursite.com/tags/Hystrix/"}]},{"title":"Zuul","slug":"Zuul","date":"2019-11-16T09:10:26.000Z","updated":"2019-11-18T07:38:48.900Z","comments":true,"path":"2019/11/16/Zuul/","link":"","permalink":"http://yoursite.com/2019/11/16/Zuul/","excerpt":"","text":"服务网关和Zuul常用的网关方案： Nginx+Lua Kong(配置比Nginx简单，很多要付费的插件) Tyk（各种支持、Go语言开发的） Spring Cloud Zuul(路由+过滤器，过滤：安全、监控、限流、路由…..) 服务网关作为请求入口，不能挂掉。需要保证稳定性、高可用、并发性、安全性、扩展性。网关适合处理非业务功能的绝佳场所：协议转发、日志监控、流量管控、api权限等等。 服务网管的要素 稳定性，高可用 性能、并发性 安全性 扩展性 Zuul组件内一次请求的生命周期 Zuul组件架构图 Zuul:路由转发，排除和自定义如何实现路由转发 新建项目api-getway 选择Cloud Routing -&gt;Zuul、Config Client、Eureka Client 配置config和eureka Application启动类添加 @EnableZuulProxy注解 直接访问 路由地址/服务名/接口地址 如 localhost:8080/product/product/list (8080为路由的端口) 如何自定义和排除1234567891011zuul: routes: # /myProduct/product/list -&gt; /product/product/list myProduct: path: /myProduct/** serviceId: product # 以上简洁写法 product: /myProduct/** # 排除某些路由，可写多个，- 表示空格 ignored-patterns: - /**/product/listForOrder 查看所有路由 localhost: 9090/application/routesZuul:Cookie和动态路由不过滤cookie的办法 sensitiveHeaders不填1234567891011management: security: enabled: falsezuul: ignored-patterns: - /**/product/listForOrder routes: myProduct: path: /myProduct/** sensitiveHeaders: &apos;&apos; serviceId: product 动态路由 使用spring Cloud Bus实现动态修改路由配置 如何在代码里修改配置不需要更新？1234567public class ZuuConfig &#123; @ConfigurationProperties(&quot;zuul&quot;) @RefreshScope public ZuulProperties zuulProperties()&#123; return new ZuulProperties() &#125;&#125; Zuul:高可用 Pre前置过滤器，限流。鉴权，把鉴权逻辑放在Pre。参数过滤，请求转发 Post后置过滤器，统计，日志 多台zuul，需要多台高可用，多个节点都注册到Eureka上面。 可用Nginx和Zuul进行混搭，使用Nginx暴露Url，把请求转发到多个Zuul服务上。Nginx继续做负载均衡 Zuul:Pre和Post过滤器 Pre过滤器的实现,继承ZuulFilter 实现四个方法 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class TokenFilter extends ZuulFilter&#123; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * filterOrder 是过滤器的顺序，越小的优先级越高 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; /** * 实现逻辑 * @return */ @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); //从url参数获取，也可以从cookie,header里获取 String tocken = request.getParameter(&quot;token&quot;); //token为空返回401 if(StringUtils.isEmpty(tocken))&#123; requestContext.setSendZuulResponse(false); requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); &#125; return null; &#125;&#125; Post过滤器的实现 12345678910111213141516171819202122232425@Componentpublic class AddResponseHeaderFilter extends ZuulFilter&#123; @Override public String filterType() &#123; return POST_TYPE; &#125; @Override public int filterOrder() &#123; return SEND_RESPONSE_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletResponse response = requestContext.getResponse(); //增加一个响应头 response.setHeader(&quot;X-Foo&quot;, UUID.randomUUID().toString()); return null; &#125;&#125; Zuul:限流令牌桶式限流时机：请求被转发之前调用 12345678910111213141516171819202122232425262728293031/** * 限流 */@Componentpublic class RateLimitFilter extends ZuulFilter &#123; //guava组件对令牌桶的实现 private static final RateLimiter RATE_LIMITER =RateLimiter.create(100); @Override public String filterType() &#123; return PRE_TYPE; &#125; @Override public int filterOrder() &#123; return SERVLET_DETECTION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; //尝试去取一个令牌 if(!RATE_LIMITER.tryAcquire())&#123; throw new RateLimitException(); &#125; return null; &#125;&#125; 继承ZuulFilter,实现4个方法，修改返回值 filterType()返回值为PRE_TYPE RateLimiter.create 限制100个 在run方法写限流抛异常 Zuul:鉴权要实现的业务： /order/create 只能买家访问 /order/finish 只能卖家访问 /product/list 都可以访问 /order/create 如何权限校验,先根据访问路径判断是否拦截，再根据买家和卖家各有的特点去判断 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 权限拦截（区分买家和卖家） */@Componentpublic class AuthBuyerFilter extends ZuulFilter&#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * filterOrder 是过滤器的顺序，越小的优先级越高 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); if(&quot;/order/order/create&quot;.equals(request.getRequestURI()))&#123; return true; &#125; return false; &#125; /** * 实现逻辑 * @return */ @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); /** * /order/create 创建订单只能买家访问 */ Cookie cookie = CookieUtil.get(request,&quot;openid&quot;); if(cookie == null || StringUtils.isEmpty(cookie.getValue()))&#123; requestContext.setSendZuulResponse(false); requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); &#125; return null; &#125;&#125; /order/finish 只能卖家访问 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 权限拦截（区分买家和卖家） */@Componentpublic class AuthSellerFilter extends ZuulFilter&#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * filterOrder 是过滤器的顺序，越小的优先级越高 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); if(&quot;/order/order/finish&quot;.equals(request.getRequestURI()))&#123; return true; &#125; return false; &#125; /** * 实现逻辑 * @return */ @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); /** * /order/finish 只能卖家访问 */ Cookie cookie = CookieUtil.get(request,&quot;token&quot;); if(cookie == null || StringUtils.isEmpty(cookie.getValue()) || StringUtils.isEmpty(stringRedisTemplate.opsForValue().get(String.format(RedisConstant.TOKEN_TEMPLATE,cookie.getValue()))) )&#123; requestContext.setSendZuulResponse(false); requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); &#125; return null; &#125;&#125; Zuul:跨域什么是跨域问题？ 同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。 同源 域名、协议、端口相同，也就是在同一个域里。 如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。 解决方案 在被调用的类或方法上增加@CrossOrigin注解 在Zuul里增加CorsFilter过滤器 12345678910111213141516171819202122/** * 跨域配置 * C-Cross O-Origin R-Resource S-Sharing */@Configurationpublic class CorsConfig &#123; @Bean public CorsFilter corsFilter()&#123; final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); final CorsConfiguration config = new CorsConfiguration(); //是否支持cookie跨域 config.setAllowCredentials(true); //原始域 http:a.com config.setAllowedOrigins(Arrays.asList(&quot;*&quot;)); config.setAllowedHeaders(Arrays.asList(&quot;*&quot;)); config.setAllowedMethods(Arrays.asList(&quot;*&quot;)); config.setMaxAge(300l); //把跨域的配置注册到source上 source.registerCorsConfiguration(&quot;*&quot;,config); return new CorsFilter(source); &#125;&#125;","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[{"name":"服务网关","slug":"服务网关","permalink":"http://yoursite.com/tags/服务网关/"},{"name":"Zuul","slug":"Zuul","permalink":"http://yoursite.com/tags/Zuul/"},{"name":"Cookie和动态路由","slug":"Cookie和动态路由","permalink":"http://yoursite.com/tags/Cookie和动态路由/"},{"name":"限流","slug":"限流","permalink":"http://yoursite.com/tags/限流/"},{"name":"鉴权","slug":"鉴权","permalink":"http://yoursite.com/tags/鉴权/"},{"name":"跨域","slug":"跨域","permalink":"http://yoursite.com/tags/跨域/"}]},{"title":"Docker的使用","slug":"docker的使用","date":"2019-11-13T06:20:52.000Z","updated":"2020-03-14T04:19:12.255Z","comments":true,"path":"2019/11/13/docker的使用/","link":"","permalink":"http://yoursite.com/2019/11/13/docker的使用/","excerpt":"","text":"什么是docker? 从系统环境开始，自底至上打包应用 轻量级，对资源的有效进程隔离和资源管理 使用image，可复用版本化 Docker思想 集装箱 标准化： 运输方式 存储方式 API接口 隔离:类似于虚拟机，更加轻量 Docker解决了什么问题：让快速扩展，弹性伸缩变得简单 Docker核心技术 Docker镜像，实质上就是一系列文件（包括应用程序的文件、应用的运行环境的文件），使用了基于分层的联合文件系统实现了镜像存储 Docker容器，本质就是一个进程；可以想象成一个虚拟机，但是是分层的，最上一层可读可写。通过一个镜像可以生成多个容器，独立运行； Docker仓库，构建镜像在其他服务器上去运行我的程序。先把我的镜像传到仓库，再从其他服务器拉取，类似于起到中转作用 Docker 安装 保证apt-get是最新版本 1apt-get update 安装Docker 1apt-get install -y docker.io 查看Docker版本 1docker version 如何创建一个Docker镜像 拉取镜像 1docker pull [OPTIONS] NAME[:TAG] 查看本机都有哪些镜像 1docker images [OPTIONS] [REPOSITORY][:TAG] 后台运行镜像 1docker run NAME -d Docker运行Nginx 去网易云镜像中心下载nginx镜像 https://c.163yun.com/hub或者Docker的nginx镜像仓库：https://hub.docker.com/ 1docker pull hub.c.163.com/library/nginx:latest 查看正在找运行的容器 1docker ps 进入容器内部 12docker exec [OPTION] CONTAINER COMMAND [ARG...]docker exec -it nginx bash 退出容器 1exit 停止容器 1docker stop 进程名 Docker网络网络类型 Bridge 桥接模式，独立ip，网络隔离 Host 宿主模式，跟主机一个网络 None 把nginx的80端口映射到主机的8080端口 1docker run -d -p 8080:80 nginx 制作自己的景象 写好Dockerfile 12345from hub.c.163.com/library/tomcatMAINTAINER sunchenming ***@163.comCOPY jpress.war /usr/local/tomcat/webapps 构建镜像，docker build 1docker build -t jpress:latest","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://yoursite.com/categories/开发工具/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"统一配置中心","slug":"统一配置中心","date":"2019-11-13T06:09:51.000Z","updated":"2020-03-14T15:03:08.630Z","comments":true,"path":"2019/11/13/统一配置中心/","link":"","permalink":"http://yoursite.com/2019/11/13/统一配置中心/","excerpt":"","text":"什么是统一配置中心？ 多人改一个配置不方便维护 配置中涉及到内容安全与权限，比如说数据库密码;这里可以把配置文件进行隔离不放进项目代码 重点（更新配置项目需重启）：统一配置中心可实现动态配置，不需重启项目（包括线上配置更新） 统一配置中心怎么实现的？ 一开始把配置放置在远端的git上面。config-server把它拉下来放在本地git，如果远端git出问题了，从本地git把配置拉出来。然后其它服务集成了 Config Client，从Config Server拿到自己的配置 Config的配置配置Config Server端 新建项目 选中Eureka Discovery Client和 Config Server 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; 启动类加注解 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableConfigServerpublic class ConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125;&#125; github上创建config-repo的仓库，在仓库中新增一个 order.yml 在config服务的application.yml增加github的配置信息如下： 12345678cloud: config: server: git: uri: https://github.com/ValarMorghulis521/config-repo.git username: ValarMorghulis521 password: ******** basedir: github的本地仓库地址 本地访问github上的yml配置信息 http://localhost:8080/release/order-dev.yml 配置命名的约定规则： /{name}-{profiles}.yml （/文件名-环境名.文件后缀） /{label}/{name}-{profiles}.yml （/分支名/文件名-环境名.文件后缀） name 代表服务名 profile 代表 环境名 label 代表分支 branch 如我要访问dev的配置（默认是master分支）http://localhost:8080/order-dev.yml如我要访问dev分支下dev的配置 http://localhost:8080/dev/order-dev.yml 配置Config Client端 在需要用到Config Client的服务上新增config-client依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; application.yml文件中新增config的配置,删除数据库其他配置信息 123456789spring: application: name: order cloud: config: discovery: enabled: true service-id: CONFIG profile: dev tips：当我们访问http://localhost:8080/dev/order-dev.yml 时是如何找到对应的配置？ appliction.name+profile.yml对应到github的配置 application.yml更名为bootstrap.yml，作为引导先启动；config-client会先去eureka上找配置的service-id,这里配置的是CONFIG，所以会去找名为“CONFIG”的服务，如果找不到会把127.0.0.01：8888当成config-server ;然后再从configServ上获取 order-dev.yml相关配置信息 只需要创建多个Config Server实例即可实现高可用，不需要相互注册 如果git上有多个配置文件order.yml，order-dev.yml (不管选择哪个环境，order.yml这个是一定会加载访问的，config会把order.yml 和 order-dev.yml里的配置合并，所以可以把公共配置放这order.yml，用不上则注释掉吧) Spring Cloud Bus bus:想上就上的公共汽车。这里是总线的意思 如何实现配置自动刷新 config-server用了Bus之后会提供一个/bus-refresh接口，访问这个接口，config-server便会将更新配置信息发送到消息队列里面（RabbitMQ） 把bus-refresh接口地址配置到git上，通过webhook访问 每次git上配置文件有了变更，便通知config-server Spring Cloud Bus实操 修改Spring Cloud 和Spring Boot的版本 添加Spring Cloud Bus的pom依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 配置rabbitmq连接地址：为什么没有配置rabbitmq却可以连上 ,没用配置则使用默认 12345public class RabbitProperties &#123; private String host = \"localhost\"; private int port = 5672; private String username = \"guest\"; private String password = \"guest\"; 如果你的mq不是搭建在本地，配置 123456spring: rabbitmq: host: port: username: password: feign组件升级为openfeign 配置Bus接口暴露出来： 1234management: endpoins: web: expose: \"*\" 在需要刷新配置的类上加 @RefreshScope 注解 远程git修改之后对bus-refresh发送post请求刷新内容 1curl -v -X POST “http://~~/actuator/bus-refresh” 配置git 的webhookURL:http:***/monitor (后面不是bus-refresh 而是monitor,因为config这个组件给我提供一个专门用户webhook的路由 monitor)Content type 选择application/json url需要外网地址，使用netapp.cn工具映射外网地址 使用配置的前缀来映射一个配置类： 配置文件： 123girl: name: lili age: 18 创建一个对应的类 12345678@Data@Component@ConfigurationProperties(\"girl\")@RefreshScopepublic class GirlConfig&#123; private String name; private Integer age;&#125;","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[{"name":"Config Server","slug":"Config-Server","permalink":"http://yoursite.com/tags/Config-Server/"},{"name":"Config Clent","slug":"Config-Clent","permalink":"http://yoursite.com/tags/Config-Clent/"},{"name":"Spring Cloud Bus","slug":"Spring-Cloud-Bus","permalink":"http://yoursite.com/tags/Spring-Cloud-Bus/"}]},{"title":"消息和异步","slug":"消息和异步","date":"2019-11-13T06:09:24.000Z","updated":"2020-03-15T06:02:41.001Z","comments":true,"path":"2019/11/13/消息和异步/","link":"","permalink":"http://yoursite.com/2019/11/13/消息和异步/","excerpt":"","text":"异步和消息什么是异步客户端请求不会阻塞进程，服务端的响应可以是非即时的 异步的常见形态 通知，一个单项请求 请求/异步响应，客户端发送请求到服务端，服务端异步响应请求，客户端不会阻塞，服务端默认响应不会立刻送达 消息 一对多形态的消息发布，客户端发送消息通知被零个或者多个消费者消费。 微服务和容器是天生一对 通过docker的镜像部署超快速实现水平扩展副本克隆 docker的隔离性实现了不同的应用服务打包成不同的 MQ应用场景 异步处理：用户注册之后需要发短信，加积分；用户注册成功后通过异步消息让短信服务和积分服务去做他们的事 流量削峰：秒杀活动会因为流量暴增，在应用前端加入消息队列，控制活动的人数，消息队列超过最大长度，直接抛弃请求跳转到错误页面。 日志处理:kafuka 用于日志处理，通过日志采集定时写入kafuka队列，然后kafuka消息队列对日志进行接收储存转发 引用解耦：如用户下单后订单服务通知商品服务 RabbitMQRabbitMQ在docker下的安装 下载镜像地址 1docker pull hub.c.163.com/library/rabbitmq:3.7.3-management 安装启动RabbitMQ 1docker run -d --hostname my-rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.7.3-management 15672端口是rabbitmq的界面管理地址 访问，因为是安装在了虚拟机上，所以本机访问虚拟机的地址 http://192.168.1.105:15672 ok!默认账号密码 guest，成功访问！ RabbitMQ的基本使用 添加RabbitMQ的pom.xml的依赖配置 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 在yml文件中新增连接RabbitMQ的配置 123456spring: rabbitmq: host: port: username: password: 创建一个接收端的类用来接收mq消息 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 接收mq消息 */@Slf4j@Componentpublic class MaReceiver &#123;// 1. @RabbitListener(queues = \"myQueue\")// 2. 自动创建队列 @RabbitListener(queuesToDeclare = @Queue(\"myQueue\"))// 3.自动创建，Exchange和Queue绑定 @RabbitListener(bindings = @QueueBinding( value = @Queue(\"myQueue\"), exchange =@Exchange(\"myExchange\") )) public void process(String message)&#123; log.info(\"MqReceiver:&#123;&#125;\",message); &#125; /** * 数码供应商服务接收消息 * @param message */ @RabbitListener(bindings = @QueueBinding( exchange =@Exchange(\"myOrder\"), key = \"computer\", value = @Queue(\"computerOrder\") )) public void processComputer(String message)&#123; log.info(\"computer MqReceiver:&#123;&#125;\",message); &#125; /** * 水果供应商服务接收消息 * @param message */ @RabbitListener(bindings = @QueueBinding( exchange =@Exchange(\"myOrder\"), key = \"fruit\", value = @Queue(\"fruitOrder\") )) public void processFruit(String message)&#123; log.info(\"fruit MqReceiver:&#123;&#125;\",message); &#125; 写一个发送方 用到amqpTemplate.convertAndSend() 12345678910111213141516171819/** * 发送mq消息测试 */@Componentpublic class MqSenderTest extends OrderApplicationTests &#123; @Autowired private AmqpTemplate amqpTemplate; @Test public void send()&#123; amqpTemplate.convertAndSend(\"myQueue\",\"now\"+ new Date()); &#125; //只会发送给 key=computer的监听 @Test public void sendOrder()&#123; amqpTemplate.convertAndSend(\"myOrder\",\"computer\",\"now\"+ new Date()); &#125;&#125; 创建queue的两种方式 ： @RabbitListener(queues = “myQueue”) 并在RabbitMQ中手动创建一个myQueue的队列 @RabbitListener(queuesToDeclare = @Queue(“myQueue”)) 可自动创建 key是分组的意思 什么情况下直接用queue就行了，什么情况下要和exchange绑定?商场做大之后卖的比较多了，对多种商品可以下单。订单，商家都有团队服务。订单要根据不同的商品类型，发送不同消息。这个时候要涉及到消息的分组,就是route的key就要产生变化了。exchanger不用变。 然后key就要变了。到了不同的消息队列也就是queueSpring Cloud Stream定义SpringCloud Stream提供更方便的消息处理，达到代码层面对消息中间件的无感知的效果，支持RabbitMQ和ActiveMQ。只需定义Input和Output，无需过多考虑rabbitmq的Exchange和RoutingKey Spring Cloud Stream的基本使用 添加Stream的pom.xml的依赖配置 123 &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 在yml中配置RabbitMQ的连接地址 先定义一个接口 1234567public interface StreamClient &#123; String INPUT = &quot;myMessage&quot;; @Input(StreamClient.INPUT) SubscribableChannel input(); @Output(StreamClient.INPUT) MessageChannel output();&#125; 定义一个接收端 123456789@Component@EnableBinding(StreamClient.class)@Slf4jpublic class StreamReceiver &#123; @StreamListener(StreamClient.INPUT) public void process(Object message)&#123; log.info(&quot;StreamReceiver:&#123;&#125;&quot;,message); &#125;&#125; 定义一个发送端 1234567891011@RestControllerpublic class SendMessageController &#123; @Autowired private StreamClient streamClient; @GetMapping(&quot;/sendMessage&quot;) public void process()&#123; String message = &quot;now&quot;+ new Date(); streamClient.output().send(MessageBuilder.withPayload(message).build()); &#125;&#125; 配置分组：一个实例发送消息只让一个实例收到消息group 表示分组；content-type表示传送的格式 12345stream: bindings: myMessage: group: order content-type: application/json 如何在收到消息后回发消息 12345678910111213@StreamListener(StreamClient.INPUT)@SendTo(StreamClient.INPUT2)public String process(Object message)&#123; log.info(&quot;StreamReceiver:&#123;&#125;&quot;,message); //使用SendTo 注解 回发mq消息给input2 return &quot;received.&quot;;&#125;@StreamListener(StreamClient.INPUT2)public void process2(String message)&#123; log.info(&quot;StreamReceiver2:&#123;&#125;&quot;,message);&#125; 商品和订单服务中使用MQ流程图 商品服务接入配置中心添加依赖 12345678910 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在yml文件中新增连接RabbitMQ的配置 123456spring: rabbitmq: host: port: username: password: 安装redis和RedisDesktopManager ，引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 启动redis 1docker run -d -p 6379:6379 redis:4.0.8 在订单服务中配置redis的信息 123redis: host: 192.168.1.105 port: 6379 在order服务中message包下新建ProductInfoReceiver 从mq中接受商品信息，把商品id和库存 放入redis中 123456789101112131415161718192021222324@Component@Slf4jpublic class ProductInfoReceiver &#123; private static final String PRODUCT_STOCK_TEMPLATE = &quot;product_stock_%s&quot;; @Autowired private StringRedisTemplate stringRedisTemplate; @RabbitListener(queuesToDeclare = @Queue(&quot;productInfo&quot;)) public void process(String message)&#123; //message =&gt; ProductInfoOutput //ProductInfoOutput productInfoOutput = (ProductInfoOutput)JsonUtil.fromJson(message, ProductInfoOutput.class); List&lt;ProductInfoOutput&gt; productInfoOutputList = ( List&lt;ProductInfoOutput&gt;)JsonUtil.fromJson(message, new TypeReference&lt; List&lt;ProductInfoOutput&gt;&gt;()&#123;&#125;); log.info(&quot;从&#123;&#125;接受到消息:&#123;&#125;&quot;,&quot;productInfo&quot;,productInfoOutputList); for(ProductInfoOutput productInfoOutput : productInfoOutputList)&#123; //储存到redis中 stringRedisTemplate.opsForValue().set(String.format(PRODUCT_STOCK_TEMPLATE,productInfoOutput.getProductId()), String.valueOf(productInfoOutput.getProductStock())); &#125; &#125;&#125; 在product服务中改造减库存的方法 1234567891011121314151617181920212223242526272829303132@Override public void decreaseStock(List&lt;DecreaseStockInput&gt; decreaseStockInputList) &#123; List&lt;ProductInfo&gt; productInfoList = decreaseStockProcess(decreaseStockInputList); //扣完库存发送mq消息 List&lt;ProductInfoOutput&gt; productInfoOutputList = productInfoList.stream().map(e -&gt;&#123; ProductInfoOutput output = new ProductInfoOutput(); BeanUtils.copyProperties(e,output); return output; &#125;).collect(Collectors.toList()); amqpTemplate.convertAndSend(&quot;productInfo&quot;, JsonUtil.toJson(productInfoOutputList)); &#125; @Transactional public List&lt;ProductInfo&gt; decreaseStockProcess(List&lt;DecreaseStockInput&gt; decreaseStockInputList) &#123; List&lt;ProductInfo&gt; productInfoList = new ArrayList&lt;&gt;(); for (DecreaseStockInput decreaseStockInput : decreaseStockInputList) &#123; Optional&lt;ProductInfo&gt; productInfoOptional = productInfoRepository.findById(decreaseStockInput.getProductId()); //判断商品是否存在 if (!productInfoOptional.isPresent()) &#123; throw new ProductException(ResultEnum.PRODUCT_NOT_EXIST); &#125; ProductInfo productInfo = productInfoOptional.get(); //库存是否足够 Integer result = productInfo.getProductStock() - decreaseStockInput.getProductQuantity(); if (result &lt; 0) &#123; throw new ProductException(ResultEnum.PRODUCT_STOCK_ERROR); &#125; productInfo.setProductStock(result); productInfoRepository.save(productInfo); productInfoList.add(productInfo); &#125; return productInfoList; &#125; 异步扣库存分析原始流程 查询商品信息（调用商品服务） 计算总价（生成订单详情） 商品服务扣库存（调用商品服务） 订单入库（生成订单） 改造成基于消息队列的异步事件驱动如果把订单入库这一步改造成异步的通过消息队列异步创建订单；如果第四步异步下单创失败了，解决办法 可以尝试重试生成订单，不处理成功mq的消息就一直存在 异步扣库存分析 如果商品服务扣库存也变成异步。如果订单服务生成订单成功，而商品扣库存失败又该如何回滚？ 方案一 订单创建成功后，订单的状态是排队中，发布一个order_create事件到mq上，由mq负责转发给订阅该消息的服务，如果商品服务收到创建订单消息后执行扣库存操作。 这里扣库存由于某些原因可能扣失败，商品服务会发送一个扣库存的消息给队列，消息里面的内容是扣库存的结果。订单服务来订阅扣库存的结果，接收到该消息后，如果扣库存成功将订单的状态改为已确认即下单成功，如果扣库存失败则把订单取消 以上需要可靠的消息投递。订单服务检测商品服务扣失败的情况，然后进行补偿 在这种情况下，用户体验的变化。用户是不能立刻马上知道下单的结果。像12306买票会得到排队中的结果。可以承受住很大的并发请求。适合秒杀类的业务场景 方案二 也可以订单创建后直接返回结果，发送创建订单的消息，让商品服务与订单服务订阅该消息并异步执行自己的操作，而创建订单写入数据库采用异步实现。但前提是若商品服务扣库存或订单服务下订单有一方操作失败要回滚，则异步写入数据库要实现相应错误处理或补偿机制】 异步扣库存分析汇总 订单服务实现复制一份库存副本，保存到Redis中 收到请求，Redis判断是否库存充足，减掉Redis中库存 订单服务创建订单写入数据库，并发送消息","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"},{"name":"Spring Cliud Stream","slug":"Spring-Cliud-Stream","permalink":"http://yoursite.com/tags/Spring-Cliud-Stream/"}]},{"title":"应用通信","slug":"应用通信","date":"2019-11-11T14:50:42.000Z","updated":"2020-03-14T03:21:43.993Z","comments":true,"path":"2019/11/11/应用通信/","link":"","permalink":"http://yoursite.com/2019/11/11/应用通信/","excerpt":"","text":"HTTP VS RPC Dubbo是一个RPC框架，服务治理集成非常完善，不仅提供了服务注册发现，负载均衡，路由等面向分布式集群，面向开发测试，服务治理和监控的可视化平台。 Spring Cloud，微服务架构下的一站式解决方案，HttpRestful:本身轻量易用，适用性强，可以很容易跨语言跨平台，或者与已有的系统交互。微服务之间使用Http Restful调用方式：RestTemplate 、Feign; RestTemplateorder服务访问product的三种方式，本质上都是使用RestTemplateorder服务的调用代码块 12345678910111213141516171819202122232425262728@RestController@Slf4jpublic class ClientController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private RestTemplate restTemplate; @GetMapping(\"/getProductMsg\") public String getProductMsg()&#123; //1.第一种方式 ,直接使用restTemplate，url写死 RestTemplate restTemplate = new RestTemplate(); String response = restTemplate.getForObject(\"http://localhost:8080/msg\",String.class); //2.第二种方式 利用loadBalancerClient通过应用名获取url，然后再使用restTemplate RestTemplate restTemplate = new RestTemplate(); ServiceInstance serviceInstance = loadBalancerClient.choose(\"PRODUCT\"); String url = String.format(\"http://%s:%s\",serviceInstance.getHost(),serviceInstance.getPort()+\"/msg\"); String response = restTemplate.getForObject(url,String.class); //3.第三种方式,利用 LoadBalanced，可在restTemplate里使用应用名字 String response = restTemplate.getForObject(\"http://PRODUCT/msg\",String.class); log.info(\"response=&#123;&#125;\",response); return response; &#125;&#125; 第三种方式还需要加个配置类把RestTemplate作为一个bean配置上去，其中@LoadBlanced注解其实是Ribbon的组件。会帮你用轮询或者随机连接等实现负载均衡。 12345678@Componentpublic class RestTemplateConfig &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 负载均衡器：Ribbon Eureka中是客户端这边做负载均衡的，而不是服务端 Ribbon实现软负载均衡核心有三点 服务发现:发现依赖服务的列表(依据服务的名字，把所有实例都找出来) 服务选择规则:依据规则策略如何从多个服务中选择一个有效的服务 服务监听: 检测失效的服务，做到高效剔除 客服端负载均衡器：Ribbon RestTemplate、Feign、Zuul都使用到了Ribbon 主要组件ServerList，IRule,ServerListFilter 主要流程：首先通过ServerList获取所有可用服务列表，然后通过ServerListFilter过滤掉一部分地址，通过IRule选择一个实例作为最终目标结果； 追踪源码自定义负载均衡策略默认使用轮询 如何改变负载均衡策略？application.yml. 1234users: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule Feign的使用 声明式REST客户端（伪RPC），Feign本质上是一个远程方法，http客户端发送http请求;通过Feign我们能把Http请求对开发者完全透明，得到与调用本地方法一致的编码体验 采用了基于接口的注解 内部使用的Ribbon做负载均衡 使用步骤 添加feign的依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.0.M3&lt;/version&gt;&lt;/dependency&gt; 在启动主类上添加@EnableFeignClients注解 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125;&#125; 创建一个Feign的客户端 接口声明你要调用哪个服务的哪些方法 ，@FeignClient表示你要调用服务的名称，@GetMapping(“/msg”)表示你要调用这个服务下的哪个方法 123456//调用product服务的msg@FeignClient(name=\"product\")public interface ProductClient &#123; @GetMapping(\"/product/msg\") String productMsg();&#125; 把上上声明的接口注入到controller，直接调用 1234567891011@RestController@Slf4jpublic class ClientController &#123; @Autowired private ProductClient productClient; public String getProductMsg()&#123; String response = productClient.productMsg(); log.info(\"response=&#123;&#125;\",response); return response; &#125;&#125; 业务流程中注意要点 controller方法中如果请求带参数必须使用 @RequestBody 结合@PostMapping 使用谷歌的Gson工具把json字符串转为list加入依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt;&lt;/dependency&gt; 12345678//使用谷歌的Gson工具try &#123; orderDetailList = gson.fromJson( orderForm.getItems(),new TypeToken&lt;List&lt;OrderDetail&gt;&gt;()&#123;&#125;.getType());&#125;catch (Exception e)&#123; log.error(\"【json转换】错误,string=&#123;&#125;\",orderForm.getItems()); throw new OrderException(ResultEnum.PARAM_ERROR); &#125; 整合接口打通下单流程 查询商品信息（调用商品服务） 计算总价 (遍历购物车的商品，单价*数量，累加 ) 扣库存（调用商品服务） 订单入库 核心业务代码 12345678910111213141516171819202122232425262728293031323334353637383940public OrderDTO cteate(OrderDTO orderDTO) &#123; String orderId = KeyUtil.getUniqueKey(); // 查询商品信息（调用商品服务） List&lt;String&gt; productIdList = orderDTO.getOrderDetailList().stream() .map(OrderDetail::getProductId) .collect(Collectors.toList()); List&lt;ProductInfo&gt; productInfoList = productClient.listForOrder(productIdList); // 计算总价 BigDecimal orderAmount = new BigDecimal(0); for(OrderDetail orderDetail :orderDTO.getOrderDetailList())&#123; for(ProductInfo productInfo : productInfoList)&#123; if(orderDetail.getProductId().equals(productInfo.getProductId()))&#123; //单价*数量 orderAmount = productInfo.getProductPrice() .multiply(new BigDecimal(orderDetail.getProductQuantity())) .add(orderAmount); BeanUtils.copyProperties(productInfo,orderDetail); orderDetail.setOrderId(orderId); orderDetail.setDetailId(KeyUtil.getUniqueKey()); //订单详情入库 orderDetailRepository.save(orderDetail); &#125; &#125; &#125; List&lt;CardDTO&gt;cardDTOList = orderDTO.getOrderDetailList().stream() .map(e -&gt; new CardDTO(e.getProductId(),e.getProductQuantity())) .collect(Collectors.toList()); //TODO 扣库存（调用商品服务） productClient.decreaseStock(cardDTOList); //订单入库 OrderMaster orderMaster = new OrderMaster(); orderDTO.setOrderId(KeyUtil.getUniqueKey()); BeanUtils.copyProperties(orderDTO,orderMaster); orderMaster.setOrderAmount(orderAmount); orderMaster.setOrderStatus(OrderStatusEnum.NEW.getCode()); orderMaster.setPayStatus(PayStatusEnum.WAIT.getCode()); orderMasterRepository.save(orderMaster); return orderDTO; &#125; BigDecimal 类型的值可使用multiply、add 进行相乘相加 项目改成多模块存在问题 Product服务像商品服务提供的商品信息查询接口，返回的是ProductInfo实体， 不能把自己数据表对应的实体类给暴露出去 商品服务和订单服务都定义了ProductInfo 同一个对象在多处定义 在订单服务中声明了一个FeignCilen客户端，定义了一些接口表明要调用商品服务下的哪些方法，在订单服务写商品服务的url显然是不合适的，自己定义自己的接口暴露给外部调用 如何解决上面上个问题？ 把原项目划分为三个模块 product-server :所有的业务逻辑，Controller,Service product-client ：对外暴露的接口,商品模块对外暴露了两个接口获取商品列表、扣库存 product-common :公用的对象，既会被外部服务调用，也会被内部其他模块使用 这三个模块之间是什么依赖关系？ 12product-server -&gt;&gt; product-common:调用product-client -&gt;&gt; product-common:调用 如何打包商品服务的jar包给订单服务调用？mvn -Dmaven.test.skip=true -U clean install (将jar包清理且安装到本地) 如何启动且调用？ 启动商品服务 启动订单服务postman访问接口即可。 同步or异步在多模块中订单服务和商品服务之间的通讯机制目前是同步，订单会调用商品服务的查询商品信息、扣库存的接口； 微服务中除了同步，有很多时候会在异步的场景下：通过队列和订阅主题实现消息的发布和订阅；一个微服务可以是消息的发布者，把消息通过异步的方式发送到队列或者订阅主题下。作为消费者的微服务可以从队列或者主题中获取消息，通过消息中间件把服务之间的直接调用解耦， 哪个场景下需要使用异步？ 比如用户服务在用户登录的时候 要给用户发短信 -&gt;调用短信服务 ,加积分-&gt;积分服务…如果都采用同步的通讯机制，服务间耦合过大，用户登录成功需要向多个服务同步响应后才能成功，会造成不好的用户体验。这个时候我们可以通过消息队列就能够很好的解决这个问题 再比如订单服务和商品服务，订单服务在扣库存前会先调用商品服务的查询商品信息的接口，再调用扣库存的接口。如果我们对其改造：商品服务在更改库存的时候发布库存变化的消息，订单服务来订阅这个消息可以获取到商品的部分信息：可购买的商品个数，商品ID .在下单的时候订单服务不需要再同步的查询商品服务获取商品的库存信息，而是直接查询自己服务中的数据。 再扣库存的时候订单服务发布一个扣库存的消息，商品服务要订阅这个消息，拿到消息后减库存。 如果订单支付成功或失败会有什么影响？比如可以设置30分钟后未支付，由支付服务发布消息，商品和订单服务同时订阅这个消息 来保证数据的最终一致性。 这样有什么好处？ 如果用户购买成功后还需要加积分，发短信，这个时候订单服务就不需要修改了，短信服务和积分服务只要也订阅了对应的消息就可以搞定。 通过消息中间件，解耦,服务间的交互变得更加灵活，如果都使用同步服务，开销太大， 可以通过消息队列解决同步的问题，使之变成异步","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[]},{"title":"Java的IO机制","slug":"Java的IO机制","date":"2019-11-10T14:29:14.000Z","updated":"2020-01-07T05:27:14.260Z","comments":true,"path":"2019/11/10/Java的IO机制/","link":"","permalink":"http://yoursite.com/2019/11/10/Java的IO机制/","excerpt":"","text":"Java文件模型：在硬盘上的文件是 byte数据的集合 可以分为IO流（输入流、输出流）也可以分为字节流、字符流 字节流InputStream、OutputStream 是字节流输入输出的抽象类，InputStream抽象了应用程序读取数据的方式，OutputStream抽象了应用程序写出数据的方式 EOF = END 代表读到-1就结束 输入流的基本方法 int b = in.read(); 读取一个字节无符号填充到int 低八位、-1是EOF in.read(byte[]buf) 读取数据填充到字节数组 buf in.read(byte[] buf,int start,int size) 读取数据到字节数组buf,从buf的start位置开始存放size长度的数据 FileInputStream 实现了在文件上读取数据 123456789101112131415161718192021222324252627282930313233343536373839404142 /** * 读取指定文件内容，按照16进制输出到控制台 */ public static void printHex(String fileName) throws IOException &#123; FileInputStream in = new FileInputStream(fileName); int b; while((b = in.read()) !=-1)&#123; System.out.print(Integer.toHexString(b)+ \" \"); &#125; in.close(); &#125; public static void printHexByByteArray(String fileName) throws IOException&#123; FileInputStream in = new FileInputStream(fileName); byte[] buf = new byte[20*1024]; /** * 从 in中批量读取字节，放入到buf这个字节数组中， * 从第0个位置开始放，最多放buf.length个 * 返回的是读到的字节的个数 */// int bytes = in.read(buf,0,buf.length);// int j =1;// for(int i =0;i&lt;bytes;i++)&#123;// if(buf[i] &lt;= 0xf)&#123;// System.out.print(\"0\");// &#125;// System.out.print(Integer.toHexString(buf[i]&amp; 0xff) +\" \");// if(j++ %10==0)&#123;// System.out.println();// &#125;// &#125; //当字节数组不够大，一次性读不完文件时怎么办？ int bytes = 0; while((bytes = in.read(buf,0,buf.length))!=-1)&#123; for(int i =0 ;i&lt;bytes;i++)&#123; //byte类型8位，int类型32位,为了避免转换错误，通过 &amp;0xff将高24位清零 System.out.print(Integer.toHexString(buf[i] &amp; 0xff)+\" \"); &#125; &#125; &#125; DataInputStream/DataOutputStream 对“流”功能的扩展，可以更加方便的读取int,long 字符等类型DataOutputStream: writeInt()/writeDouble/writeUTF() 1234567891011121314151617181920public static void testDataInputStrem() throws IOException&#123; String file = \"d:\\\\out.dat\"; DataInputStream dis = new DataInputStream(new FileInputStream(file)); int i =dis.readInt(); System.out.println(i); long l = dis.readLong(); System.out.println(l); String s = dis.readUTF(); System.out.println(s); dis.close(); &#125; public static void testDataOutputStream() throws IOException &#123; String file = \"d:\\\\out.dat\"; DataOutputStream dos = new DataOutputStream(new FileOutputStream(file)); dos.writeInt(10); dos.writeLong(10); dos.writeUTF(\"中国\"); dos.close(); IOUtil.printHex(file); &#125; 字节缓冲流:BufferedInputStresm 、BufferedOutputStream这两个流类为IO提供了带缓冲区的操作，一般打开文件进行写入或读取时都会加上缓冲，这种流模式提高了IO性能 1234567891011121314151617public static void copyFileByBuffer(File srcFile, File destFile) throws IOException&#123; if(!srcFile.exists())&#123; throw new IllegalArgumentException(\"文件\"+srcFile+\"不存在\"); &#125; if(!srcFile.isFile())&#123; throw new IllegalArgumentException(\"文件\"+srcFile+\"不是存在\"); &#125; BufferedInputStream bif = new BufferedInputStream(new FileInputStream(srcFile)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(destFile)); int b; while ((b=bif.read())!=-1)&#123; bos.write(b); &#125; bos.flush(); bif.close(); bos.close(); &#125; 从应用程序中把输入放进文件，相当于将一桶水倒进到另一个缸中：FileOutputStream -&gt;write()方法相当于一滴一滴地把水“转移过去”DataoutputStream -&gt;writeXX()方法相当于一瓢一瓢把水“转移过去”BufferedInputStresm -&gt;write()方法相当于一瓢一瓢先放入桶中，再从桶中倒入到缸里 输出流基本方法 out.write(int b); 写出一个byte到流，b的低8位 out.write(byte[]buuf) 将buf字符数组都写入到流 out.write(byte[] buf,int start,int size) 字节数组buf,从buf的start位置开始写size长度的字节到流 FileOutputStream 实现了向文件中写出byte数据的方法 123456789101112// 如果该文件不存在，则直接创建，如果存在，删除后创建FileOutputStream out = new FileOutputStream(\"d:\\\\out.dat\");out.write('A'); //写出 A的低八位out.write('B'); //写出 B的低八位int a = 10;//write只能写八位，那么写一个int需要写四次out.write(a &gt;&gt;&gt; 24);out.write(a &gt;&gt;&gt; 16);out.write(a &gt;&gt;&gt; 8);out.write(a );byte[]gbk = \"中国\".getBytes(\"gbk\");out.write(gbk);out.close(); 实现一个文件复制功能 1234567891011121314151617public static void copyFile(File srcFile, File destFile) throws IOException&#123; if(!srcFile.exists())&#123; throw new IllegalArgumentException(\"文件\"+srcFile+\"不存在\"); &#125; if(!srcFile.isFile())&#123; throw new IllegalArgumentException(\"文件\"+srcFile+\"不是存在\"); &#125; FileInputStream in = new FileInputStream(srcFile); FileOutputStream out = new FileOutputStream(destFile); byte[]buf = new byte[8*1024]; int b; while ((b=in.read(buf,0,buf.length))!=-1)&#123; out.write(buf,0,b); out.flush(); &#125; out.close();&#125; 字符流操作的是文本文件 注意编码问题 认识文本和文本文件： Java的文本(char)是16位无符号整数，是字符的unicode编码(双字节编码) 文件是 byte,byte,byte 的数据序列 文本文件是文本(char)序列按照某种编码方案(utf-8,gbk)序列化为byte存储结果 也分为Read、Writer 输入输出流，字符的底层也是字节序列 字符流的基本实现： InputStreamReader：完成byte流解析为char流，按照编码解析 OutputStreamWriter 提供char流到byte流，按照编码处理 123456789101112131415161718192021222324public class ReadAndWriterDemo &#123; public static void main(String[] args) throws IOException &#123; FileInputStream inputStream = new FileInputStream(\"d:\\\\job.txt\"); //如果不设置则是默认项目编码,要写文件本身的编码 InputStreamReader reader = new InputStreamReader(inputStream,\"gbk\"); OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(\"d:\\\\job2.txt\"),\"utf-8\");// int c;// while ((c=reader.read())!=-1)&#123;// System.out.print((char)c);// &#125; char[]buffer = new char[8+1024]; int c; //批量读取，放入buffe这个字符数组，从第0个位置开始，最多放buffer.lengtu个 //返回的是字符个数 while((c=reader.read(buffer,0,buffer.length))!=-1)&#123; String s = new String(buffer,0,c); System.out.print(s); writer.write(buffer,0,c); writer.flush(); &#125; inputStream.close(); writer.close(); reader.close(); &#125; 文件流：FileReader 和 FileWriter 对象的序列化，反序列化 对象的序列化，就是将Object转换成byte序列，反之叫对象的反序列化 序列化流是过滤流： ObjectOutputStream.writeObject / ObjectInputStream.readObject 序列化接口（Serializable） 对象必须实现序列化接口，才能进行序列化，否则将出现异常，这个接口没有任何方法，只是一个标识代表可序列化 使用对象流进行序列化和反序列化 123456789101112 public static void main(String[] args) throws IOException, ClassNotFoundException &#123; String file = \"d:\\\\Student.txt\"; //1.对象的序列化// ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(file));// Student stu = new Student(18,\"Tom\",\"man\");// out.writeObject(stu);// out.close(); ObjectInputStream input = new ObjectInputStream(new FileInputStream(file)); Student stu = (Student) input.readObject(); System.out.println(stu); &#125; 使用","categories":[{"name":"Java常用类库与技巧","slug":"Java常用类库与技巧","permalink":"http://yoursite.com/categories/Java常用类库与技巧/"}],"tags":[{"name":"IO机制","slug":"IO机制","permalink":"http://yoursite.com/tags/IO机制/"}]},{"title":"J.U.C包的梳理","slug":"J-U-C包的梳理","date":"2019-11-10T12:28:36.000Z","updated":"2020-02-28T14:14:13.567Z","comments":true,"path":"2019/11/10/J-U-C包的梳理/","link":"","permalink":"http://yoursite.com/2019/11/10/J-U-C包的梳理/","excerpt":"","text":"JUC包(java.util.concurrent)：提供了并发编程的解决方案，主要分为以下5类： 线程执行器executor 锁locks 原子变量类atomic 并发工具类tools 并发容器 Executor J.U.C的三个Executor接口 Executor:运行新任务的简单接口，将任务提交和任务执行细节解耦 123456//直接启动线程Thread t = new Thread();t.start();//交给executeThread t = new Thread();execute.execute(t); ExecutorService:具备管理执行器和任务生命周期的方法，提交任务机制更完善例如，其中submit方法传入了Callable,弥补了Runnable无法返回结果的短板，因此较Executor提供了更加完善的提交机制 1&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); ScheduledExecutorService:扩展了ExecutorService，同时支持Future和定期执行任务 Atomic 原子类 其中 CAS 是java.util.concurrent.atomic包的基础 基本类型 使用原子的方式更新基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 数组类型 使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型 使用原子的方式更新数组里的某个元素 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新引用类型里的字段原子类 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicInteger 的使用AtomicInteger 类常用方法 1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 AtomicInteger 类的使用示例使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。 1234567891011class AtomicIntegerTest &#123; private AtomicInteger count = new AtomicInteger(); //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。 public void increment() &#123; count.incrementAndSet(); &#125; public int getCount() &#123; return count.get(); &#125;&#125; AtomicInteger 类的原理AtomicInteger 线程安全原理简单分析 AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用） private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 并发工具类 AQS 是java.util.concurrent.locks包以及一些常用类比如：Semophore,ReentrantLock类的基础 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch （倒计时器）： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。 CyclicBarrier(循环栅栏)： CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 交换器 Exchanger 并发容器 JDK提供的这些容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap: 线程安全的HashMap CopyOnWriteArrayList: 线程安全的List，在读多写少的场合性能非常好，远远好于Vector. ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue: 这是一个接口，JDK内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap: 跳表的实现。这是一个Map，使用跳表的数据结构进行快速查找 ConcurrentHashMapConcurrentHashMap 的诞生。在ConcurrentHashMap中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。 以下两各问题在 ConcurrentHashMap 有专门的讲解 ConcurrentHashMap 和 Hashtable 的区别 ConcurrentHashMap线程安全的具体实现方式/底层具体实现 BlockingQueue提供可阻塞的入队和出队操作 主要用于生产者-消费者问题中，其原因是BlockingQueue提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。 在多线程场景时生产者线程在队列尾部添加元素，而消费者线程在队列头部消费元素，通过这种方式能够达到将任务的生产和消费进行隔离的目的 由以下七个实现类， 都是线程安全 下面主要介绍一下:ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue，这三个 BlockingQueue 的实现类。 ArrayBlockingQueueArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。ArrayBlockingQueue一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。 ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的 ArrayBlockingQueue，可采用如下代码： 1private static ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(10,true); LinkedBlockingQueueLinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足FIFO的特性，与ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于Integer.MAX_VALUE。 PriorityBlockingQueuePriorityBlockingQueue 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。","categories":[{"name":"Java多线程与并发","slug":"Java多线程与并发","permalink":"http://yoursite.com/categories/Java多线程与并发/"}],"tags":[{"name":"JUC包的梳理","slug":"JUC包的梳理","permalink":"http://yoursite.com/tags/JUC包的梳理/"},{"name":"Executor","slug":"Executor","permalink":"http://yoursite.com/tags/Executor/"},{"name":"并发容器","slug":"并发容器","permalink":"http://yoursite.com/tags/并发容器/"}]},{"title":"ConcurrentHashMap","slug":"ConcurrentHashMap","date":"2019-11-10T11:34:16.000Z","updated":"2020-02-28T13:03:30.388Z","comments":true,"path":"2019/11/10/ConcurrentHashMap/","link":"","permalink":"http://yoursite.com/2019/11/10/ConcurrentHashMap/","excerpt":"","text":"Hashtable 早期Java类提供的哈希表的实现 线程安全：涉及到修改Hashtable的方法，使用synchronized修饰 串行化的方式运行，性能较差 如何优化Hashtable? 通过锁细粒度化，将整锁拆解成多个锁进行优化 早期的ConcurrentHashMap：通过分段锁Segment来实现 当前的ConcurrentHashMap:CAS+synchronized使锁更细化 只是锁住每个 table 的首节点，所以只要 Hash 不冲突，就不会产生并发。 使用Collections.synchronizedMap(hashMap);将HashMap包装成线程安全的。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。 源码分析 出自JUC包 成员变量与HashMap相似；sizeCtl 是 ConcurrentHashMap 特有的成员变量，做大小控制的标识符12//用来初始化或扩容的控制位标示量 private transient volatile int sizeCtl; put方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public V put(K key, V value) &#123; return putVal(key, value, false);&#125; final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不能放入为null的key if (key == null || value == null) throw new NullPointerException(); //去计算key的hash值 int hash = spread(key.hashCode()); int binCount = 0; //多数组的元素更新是使用CAS机制，需要不断的去做失败重试 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //数组为空初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //不等于0我们就通过hash值来找到f(头结点),根据定位到的元素检查是否存在 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果没有则尝试使用CAS进行添加，添加失败则break，进入下一次循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //如果被别的线程正在移动，我们就协助其扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; //判断f是否是链表的头结点，fh代表的是头结点的hash值 if (tabAt(tab, i) == f) &#123; //如果是链表的头结点，初始化计数器binCount， 遍历链表。如果存在我们就去更新value，如果不存在就在链表尾部添加新的结点 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //如果头结点是红黑二叉树的结点，则以树的逻辑往树里面添加结点 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; ConcurrentHashMap：put逻辑 判断Node[]数组是否初始化，没有进行初始化操作 通过hash定位数组的索引坐标之后，判断是否有Node结点，如果没有则利用CAS进行添加（链表的头结点），添加失败进行下次循环 检查内部是否正在扩容，如果扩容，就帮他一块扩容 如果f!=null,则使用synchronized锁住f元素（链表/红黑二叉树的头元素） 使用syn锁住当前下标,如果是链表则执行链表插入，如果是树，则进行树的操作 如果是Node(链表结构)则执行链表的添加操作 如果是TreeNode(树形结构)则执行树添加操作 判断链表长度是否达到临界值8，当然这个8是默认值，也可以去做调整，当节点数超过这个值就需要把链表转换为树结构 ConcurrentHashMap总结：比起Segment，锁拆的更细 首先使用无锁操作CAS插入头结点，失败则循环重试 若头结点已存在，则尝试获取头结点的同步锁，再进行操作 HashMap、Hashtable、ConcurrentHashMap三者的区别 HashMap线程不安全，数组+链表+红黑树 Hashtable线程安全，锁住整个对象，效率低，数组+链表 ConcurrentHashMap线程安全，CAS+同步锁，数组+链表+红黑树 HashMap的key、value均可为null,而其他的两个类均不支持","categories":[{"name":"Java多线程与并发","slug":"Java多线程与并发","permalink":"http://yoursite.com/categories/Java多线程与并发/"}],"tags":[{"name":"Hashtable","slug":"Hashtable","permalink":"http://yoursite.com/tags/Hashtable/"},{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"http://yoursite.com/tags/ConcurrentHashMap/"}]},{"title":"HashMap","slug":"HashMap","date":"2019-11-10T08:17:26.000Z","updated":"2020-03-08T05:31:38.225Z","comments":true,"path":"2019/11/10/HashMap/","link":"","permalink":"http://yoursite.com/2019/11/10/HashMap/","excerpt":"","text":"Map的集合 HashMap(Java8以前)：数组+链表 HashMap的数组长度再没有给他赋任何初始值的时候默认16，一个长度为16的数组中每个元素存储的就是链表的头节点，通过hash(key.hashCode())%len 函数去取模获得要添加的元素存放的数组的位置 HashMap的hash算法是通过位运算来进行的相比取模运算效率更高 存在极端情况，通过hash散列运算总是得到相同的值，即分配到同一个桶中，会使得某个桶的链表很长 HashMap(Java8以后)：数组+链表+红黑树1.红黑树的算法和实现 HashMap相关源码解析HashMap的成员变量 Node1transient Node&lt;K,V&gt;[] table; Node的源码 123456789101112static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; HashMap可以看做通过数组Node&lt;K,V&gt;这个table，和链表组成的数据结构。Node是由hash值，键值对，以及指向的下一个节点来组成的； 而数组被分为一个个的bucket，通过hash值决定了键值对在这个数据的寻址，hash值相同的键值对则以链表的形式来存储，而如果链表的大小超过了 TREEIFY_THRESHOLD =8 就会被改造成红黑树。当某bucket上面的元素的总数因为删除而变得低于阈值 UNTREEIFY_THRESHOLD =6 了之后，红黑树又被转成链表以保持更高的性能！ HashMap的构造函数源码 1234567/*** Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity* (16) and the default load factor (0.75).*/public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 根据构造函数可以看出HashMap 中的table数组并没有在开始初始化好，只是给负载因子初始化默认值0.75 ，因为可以推断HashMap是按照lazyLoad去加载 HashMap的 put()方法源码分析加注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //根据源码可以看出如果数组为空就调用resize()方法给它初始化数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //做hash运算，算出键值对在table里面的具体位置，得到的运算还没有元素存储到里面则会直接new一个该键值对的node,放到该位置当中 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果发现同样的位置存在同样的已经存在键值对，且键和传入进来的键一致，则直接替换数组里面的元素 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //当前位置存储的是否是已经树化了之后的节点，如果是树化了的话则按照树的方式尝试存储键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果不是树化了，则按照链表的插入方式往链表后面添加元素，同时判断链表元素的总数，一旦超过TREEIFY_THRESHOLD，则将链表进行树化 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果插入的键位存在于HashMap中则对对应的键位进行值的更新操作 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //而当我们的HashMap的size大于阈值的时候也通用会调用resize()对HashMap进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 个人理解： 根据源码可以看出如果数组为空就给它初始化数组（调用resize()方法），而当我们的HashMap的size大于阈值的时候也通用会调用resize()对HashMap进行扩容,因此resize方法即具备初始化又具备扩容的功能。 put方法逻辑总结 若HashMap未被初始化，则进行初始化操作； 对key求Hash值，依据Hash值计算下标； 若未发生碰撞，则直接放入桶中； 若发生碰撞，则以链表的方式链接到后面； 若链表长度超过阈值，且HashMap匀速超过最低树化容量，则将链表转成红黑树； 若节点已经存在，则用新值替代旧值； 若桶满了（默认容量16*扩容因子0.75），就需要resize(扩容2倍后重排)； HashMap的 hash()方法源码 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 先获取key的hashCode,再将高位数移动16位，再与原先的数据异或运算 如上图：key的hashCode是返回int散列值，如果直接拿这个散列值作为下标去访问HashMap数组的话，考虑到二进制的三十二位int范围-2147483648到2147483648，只要hash函数映射的均匀一般很难出现碰撞，一个40亿长度的数组内存是放不下的，况且HashMap的最初始数组大小才16，所以直接拿散列值用不现实！ 直接将高半区向右移动16位再跟自己去做异或，可以混合原始hash码的高位和低位以此来加大低位的随机性，混合后后的低位掺杂了高位的特征，从速度功效考虑，也不会有太大的开销。 为什么HashMap的长度是2的n次方在上面的put方法里有这样两行代码，计算键值对在table里面的具体位置 123//做hash运算，算出键值对在table里面的具体位置，得到的运算还没有元素存储到里面则会直接new一个该键值对的node,放到该位置当中 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); HashMap为了存取高效，要尽量较少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就在把数据存到哪个链表中的算法； 这个算法实际就是取模，hash%length，计算机中直接求余效率不如位与运算，源码中做了优化hash&amp;(length-1)，hash%length==hash&amp;(length-1)的前提是length是2的n次方； 为什么这样能均匀分布减少碰撞呢？2的n次方实际就是1后面n个0，2的n次方-1 实际就是n个1；例如长度为9时候，3&amp;(9-1)=0 2&amp;(9-1)=0 ，都在0上，碰撞了；例如长度为8时候，3&amp;(8-1)=3 2&amp;(8-1)=2 ，不同位置上，不碰撞； 什么是位与运算？&nbsp;&nbsp;&nbsp;&nbsp;0000 0011 3 &amp; 0000 1000 8 = 0000 0000 0 &nbsp;&nbsp;&nbsp;&nbsp;0000 0010 2 &amp; 0000 1000 8 = 0000 0000 0 &nbsp;&nbsp;&nbsp;&nbsp;0000 0011 3 &amp; 0000 0111 7 = 0000 0011 3 &nbsp;&nbsp;&nbsp;&nbsp;0000 0010 2 &amp; 0000 0111 7 = 0000 0010 2 HashMap的 get()方法源码分析 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //使用键对象的hashCode,通过hash算法找到bucket的位置 if (first.hash == hash &amp;&amp; // always check first node //找到bucket位置后在通过key.equals找到正确节点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; get方法逻辑总结 使用键对象的hashCode 通过hash算法找到bucket的位置； 找到bucket位置之后调用 key.equals(k) 去找到链表中正确的节点最终找到要找的值，并返回； HashMap如何有效减少碰撞 扰动函数：促使元素位置分布均匀，减少碰撞机率；对于很多元素我们能够通过数组来直接去获取，hash算法内部实现目的是让不同的对象返回不同的hashCode 使用final对象，并采用合适的equals和hashCode()方法:final类建议作为key是利用了其不可变性，如果一个key可以随便修改，那么修改后在HashMap就找不到了；适合String,Integer这样的键 HashMap的 扩容方法当HashMap无法装载更多的元素时，对象就需要扩大数组的长度；使用一个新的较大的数组来代替老的数组；HashMap的默认负载因子是0.75；当一个HashMap填满了75%的bucket的时候，将会创建原来HashMap大小的两倍的bucket数组来重新调整map的大小，这个过程是 rehashing HashMap扩容问题 多线程环境下，调整大小会存在条件竞争，容易造成死锁 rehashing是一个比较耗时的过程","categories":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/categories/容器/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://yoursite.com/tags/HashMap/"}]},{"title":"Java集合框架基础","slug":"Java集合框架基础","date":"2019-11-10T07:50:41.000Z","updated":"2020-01-04T11:22:22.250Z","comments":true,"path":"2019/11/10/Java集合框架基础/","link":"","permalink":"http://yoursite.com/2019/11/10/Java集合框架基础/","excerpt":"","text":"优秀的算法和数据结构被封装到了Java的集合框架 数据结构重点： 数组和链表的区别； 链表的操作，如反转，链表环路检测，双向链表，循环链表相关操作 队列，栈的应用 二叉树的遍历方式及其递归和非递归的实现 红黑树的旋转 算法重点： 内部排序：如递归排序、交换排序（冒泡、快排）、插入排序、选择排序 外部排序：掌握如何利用有限的内存配合海量的外部存储来处理超大数据集，写不出来有思路 Java集合框架图 List,Set,Map三者的区别 List(对付顺序的好帮手)： List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 Set(注重独一无二的性质): 不允许重复的集合。不会有多个元素引用相同的对象。 Map(用Key来搜索的专家): 使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。 集合之List和Set Arraylist 与 LinkedList 区别? 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6之前为循环链表，JDK1.7取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！） 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e) 方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element) ）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以插入，删除元素时间复杂度不受元素位置的影响，都是近似 O（1）而数组为近似 O（n）。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index) 方法)。 内存空间占用： ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。 补充内容:RandomAccess接口12public interface RandomAccess &#123;&#125; 查看源码我们发现实际上 RandomAccess 接口中什么都没有定义。所以，在我看来 RandomAccess 接口不过是一个标识罢了。标识什么？ 标识实现这个接口的类具有随机访问功能。 在 Collections.binarySearch()方法中，它要判断传入的list 是否 RamdomAccess 的实例，如果是，调用indexedBinarySearch()方法，如果不是，那么调用iteratorBinarySearch()方法 1234567public static &lt;T&gt; int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key) &#123; if (list instanceof RandomAccess || list.size()&lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key); &#125; ArrayList 实现了 RandomAccess 接口， 而 LinkedList 没有实现。为什么呢？我觉得还是和底层数据结构有关！ArrayList 底层是数组，而 LinkedList 底层是链表。数组天然支持随机访问，时间复杂度为 O（1），所以称为快速随机访问。链表需要遍历到特定位置才能访问特定位置的元素，时间复杂度为 O（n），所以不支持快速随机访问。，ArrayList 实现了 RandomAccess 接口，就表明了他具有快速随机访问功能。 RandomAccess 接口只是标识，并不是说 ArrayList 实现 RandomAccess 接口才具有快速随机访问功能的！ 下面再总结一下 list 的遍历方式选择： 实现了 RandomAccess 接口的list，优先选择普通 for 循环 ，其次 foreach, 未实现 RandomAccess接口的list，优先选择iterator遍历（foreach遍历底层也是通过iterator实现的,），大size的数据，千万不要使用普通for循环 补充内容:双向链表和双向循环链表双向链表： 包含两个指针，一个prev指向前一个节点，一个next指向后一个节点。 双向循环链表： 最后一个节点的 next 指向head，而 head 的prev指向最后一个节点，构成一个环。 ArrayList 与 Vector 区别呢?为什么要用Arraylist取代Vector呢？Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时建议使用Arraylist。 HashMap 和 Hashtable 的区别 线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 HashMap 和 HashSet区别如果你看过 HashSet 源码的话就应该知道：HashSet 底层就是基于 HashMap 实现的。（HashSet 的源码非常非常少，因为除了 clone()、writeObject()、readObject()是 HashSet 自己不得不实现之外，其他方法都是直接调用 HashMap 中的方法。 HashMap HashSet 实现了Map接口 实现Set接口 存储键值对 仅存储对象 调用 put（）向map中添加元素 调用 add（）方法向Set中添加元素 HashMap使用键（Key）计算Hashcode HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性， HashSet如何检查重复当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。（摘自我的Java启蒙书《Head fist java》第二版） hashCode（）与equals（）的相关规定： 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 ==与equals的区别 ==是判断两个变量或实例是不是指向同一个内存空间 equals是判断两个变量或实例所指向的内存空间的值是不是相同 ==是指对内存地址进行比较 equals()是对字符串的内容进行比较 ==指引用是否相同 equals()指的是值是否相同 HashMap的底层实现在HashMap中有详细分析，这里不再累述； 集合框架底层数据结构总结Collection1. List Arraylist： Object数组 Vector： Object数组 LinkedList： 双向链表(JDK1.6之前为循环链表，JDK1.7取消了循环) 2. Set HashSet（无序，唯一）: 基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现一样，不过还是有一点点区别的。 TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树。) Map HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间 LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。详细可以查看：《LinkedHashMap 源码详细分析（JDK1.8）》 Hashtable： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap： 红黑树（自平衡的排序二叉树） 如何选用集合?主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用Map接口下的集合，需要排序时选择TreeMap,不需要排序时就选择HashMap,需要保证线程安全就选用ConcurrentHashMap.当我们只需要存放元素值时，就选择实现Collection接口的集合，需要保证元素唯一时选择实现Set接口的集合比如TreeSet或HashSet，不需要就选择实现List接口的比如ArrayList或LinkedList，然后再根据实现这些接口的集合的特点来选用。","categories":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/categories/容器/"}],"tags":[{"name":"List","slug":"List","permalink":"http://yoursite.com/tags/List/"},{"name":"Set","slug":"Set","permalink":"http://yoursite.com/tags/Set/"}]},{"title":"服务拆分","slug":"服务拆分","date":"2019-11-08T09:00:20.000Z","updated":"2020-03-07T05:45:53.845Z","comments":true,"path":"2019/11/08/服务拆分/","link":"","permalink":"http://yoursite.com/2019/11/08/服务拆分/","excerpt":"","text":"微服务拆分的起点和重点微服务如何拆分： 先明白起点和终点 起点：既有的架构形态（老项目、新项目） 终点：好的架构不是设计出来的，而是进化而来的。进化一直在演进 需要考虑的因素与坚持的原则 不适合用微服务的业务场景 系统中包含很多很多强事务场景的 业务相对稳定，迭代周期长 访问压力不大，可用性要求不高 除了业务上的不匹配，还涉及到团队的运作和管理。传统人员架构是项目模式，项目启动时从资源池抽取不能技能的人员组成团队，项目结束资源被释放掉。 而微服务架构下人员组织是产品模式，让团队负责整个服务的生命周期。 康威定律：沟通的问题会影响系统的设计， 点餐业务服务拆分扩展立方模型 x轴：水平复制，通过副本扩展，将应用程序水平复制，通过负载均衡运行程序的多个完全一样的副本方式，来实现应用程序的伸缩性，提高应用程序的容量和可用度。 Z轴：数据分区，每个服务器负责一个数据子集。每个服务器运行的代码是一样的。 Y轴：功能解耦，将不同职责的模块，分成不同的服务如何拆分功能 单一职责，松耦合、高内聚 ：每个服务只负责业务功能的一个单独部分。服务之间耦合度低，修改一个服务不用导致另外一个服务跟着修改，高内聚指的是服务内部相关的行为聚集在一个服务内，而不是分散在不同的服务中，需要修改一个行为时，只需要修改一个服务就行） 关注点分离 按职责（给我们的服务进行分类，明显按照业务领域可以划分出来的服务，职责比较单一：订单，商品，前端服务 按通用性（一些基础组件，与具体的业务无关的可以划分成单独的服务：消息、用户 按粒度级别：并不是越小越好 服务和数据的关系 先考虑拆分业务功能，在考虑拆分业务功能对应的数据 无状态服务 一个数据需要被多个服务共享才能完成一个请求，这个数据就是有状态 把数据迁移到分布式缓存中存储，让业务服务变成无状态计算结点，后端服务能做到按需动态伸缩，在运行时动态增删结点不用考虑缓存同步问题 点餐业务拆分分析 服务拆分的方法论：&lt;可扩展的艺术&gt; 扩展立方模型： x轴：水平复制，通过副本扩展，将应用程序水平复制，通过负载均衡运行程序的多个完全一样的副本方式，来实现应用程序的伸缩性，提高应用程序的容量和可用度。 Z轴：数据分区，每个服务器负责一个数据子集。每个服务器运行的代码是一样的。 Y轴：功能解耦，将不同职责的模块，分成不同的服务 业务流程 开发商品服务和订单服务作为服务注册到 注册中心Eureka Server 每个服务的开发流程大致 连接数据库-&gt;创建所需对象-&gt;dao层-&gt;分析Controller中方法的业务流程-&gt;写出需要的Service方法-&gt;写Controller ,注意每个方法写完后都及时单元测试 返回给前端的数据自定义VO对象 前端请求过来的数据使用Form对象封装，Controller传给Service的数据使用DTO封装 如何拆数据 每个微服务都有单独的数据存储，达到松耦合，其它服务避免访问别的服务的数据库。一个服务的数据，只能通过这个服务提供的API来访问，服务之间都是有隔离的。 依据服务特点选择不同结构的数据库类型。依据功能特点选择合适的数据库。mongodb（前端服务，对事物要求低）、Elasticsearch(ES搜索)、mysql 难点在确定边界","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[]},{"title":"服务注册与发现","slug":"服务注册与发现","date":"2019-11-08T03:15:32.000Z","updated":"2020-03-07T04:34:12.084Z","comments":true,"path":"2019/11/08/服务注册与发现/","link":"","permalink":"http://yoursite.com/2019/11/08/服务注册与发现/","excerpt":"","text":"微服务的注册与发现 （Spring Cloud Eureka）： 基于Netflix Eureka做了二次封装,主要负责完成微服务架构中的服务治理功能。 两个组件： Eureka Server(注册中心） Eureka Client(服务注册) Eureka Server作为服务注册功能的服务器，它是服务注册中心，而系统中其他微服务使用Eureka Client客户端，连接到Eureka Server并维持心跳连接，这样就能监控系统中各个微服务是否正常运行 Eureka Server 注册中心Eureka Server的配置 新建项目 Cloud Discovery -&gt; Eureka Server 修改pom文件中spring boot 2.0.0.M3 和 spring cloud Finchley.M2的版本 启动主类EurekaApplication 添加注解 @EnableEurekaServer，表明这个项目有注册中心的功能 配置application.yml,内容如下： 12345678910111213141516eureka: client: service-url: # 配置的注册地址，Eureka Server既是服务端又是客户端，自己注册到自己的地址 defaultZone: http://localhost:8761/eureka/ # 本身就是注册中心，取消注册 register-with-eureka: false server: #Server端配置，关闭自我保护，开发环境 enable-self-preservation: false# 配置应用的名字spring: application: name: eurekaserver: port: 8761 mvn打包,后台启动 1234mvn clean package 使用nohup让程序在后台运行nohup java -jar target/eureka-0.0.1-SNAPSHOT.jar &gt; /dev/null 2&gt;&amp;1 &amp; Eureka Client的配置 新建项目 Cloud Discovery -&gt; Eureka Discovery Client 修改pom文件中spring boot 2.0.0.M3 和 spring cloud Finchley.M2的版本 启动主类 ClientApplication 添加注解 @EnableDiscoveryClient，表明这个有注册中心的功能 配置application.yml,内容如下：123456789101112eureka: client: service-url: # 配置的注册地址 defaultZone: http://localhost:8761/eureka/ # 自定义连接跳转地址# instance:# hostname: clientName# 配置应用的名字spring: application: name: client EurekaClient的使用 引入依赖 配置上注册中心的地址 defaultZone 在启动的主类上加@EnableDiscoveryClient Eureka 的高可用eureka server实现高可用，可以将他集群，然后互相注册。client端注册所有集群eureka 单个server且没有client的时候，自己注册自己，会显示自己，加一个参数register-with-eureka: false会取消显示； 3个server相互注册instances栏也不显示注册的另外的server（client）实例和自己本身，registered-replicas栏里倒是可以看另外的server；改动register-with-eureka: true后，另外两个server实例和自己本身将都会显示。 总结Eureka Server的高可用，通过多个Eureka相互注册实现。 @EnableEurekaServer @EnableEurekaClient 心跳检测，健康检查，负载均衡等功能 Eureka的高可用，生产上建议至少两台以上 分布式系统中，服务注册中心是最重要的基础部分 分布式下服务注册的地位和原理微服务中为什么需要服务发现？最简单的情况下：只有A，B两个服务，他们都有自己的IP地址，如果A调用B，那么需要在A中配置B的地址就可以了。 但是如果B的服务有多个，在分布式系统中，多个自治的B并不共享主内存。因此B的服务不仅多，而且会根据具体情况动态变化。因此数量也是不固定的。例如在流量小的时候B的数量会变小，当大流量时B的数量可以增多。因此在A中的配置写B的IP是不现实的。 这时就需要注册中心了，B在启动时就会把自己的信息上报到注册中心 这时如果A要调用B就需要从注册中心获取B的信息 A如何向注册中心拿到B的信息？方法一：客户端发现A直接找注册中心，注册中心把B的所有信息都发送给A，这时A只需要选择一个B的地址就可以了。可以通过某种机制来选择，比如轮训、hash、随机等机制来从众多的B地址中选择一个。这种方式就是客户端发现，这是由A发起的。常用的有：Eureka 方法一：服务端发现出现了一个新的角色—-代理。代理从众多的B地址中选一个给A。这种方式就是服务端发现。常用的有：Nginx，zookeeper，kubernetes。 客户端发现与服务端发现的优缺点 客户端发现的优点：简单直接，不需要代理的介入，同时可以知道所有可以使用的服务地址。缺点是需要自己实现一套逻辑来挑选B。服务端发现的优点：对于A来说是透明的。A服务只需要向代理发请求就可以了。 微服务的特点：异构 不同语言 不同类型的数据库 SpringCloud的调用方式：Eureka提供了较为晚上的REST API，其他语言可实现Eureka的客户端","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[{"name":"Eureka","slug":"Eureka","permalink":"http://yoursite.com/tags/Eureka/"}]},{"title":"微服务介绍","slug":"微服务介绍","date":"2019-11-08T02:50:52.000Z","updated":"2020-01-11T05:10:33.729Z","comments":true,"path":"2019/11/08/微服务介绍/","link":"","permalink":"http://yoursite.com/2019/11/08/微服务介绍/","excerpt":"","text":"单体架构单体架构的优点:容易测试（本地启动完整的测试，不需要外部依赖）容易部署（直接打成war包，放在tomcat下面就可以了） 单体架构的缺点：开发效率低（容易提交代码的时候造成冲突）代码维护难（尤其是新人来的时候业务代码写在一块，不知从何下手）部署不够灵活（任何小修改都要重新构建，构建时间特别长）稳定性不够 （任何一个小问题容易让整个系统挂掉）扩展性不够（无法满足高并发下的业务需求） 微服务和分布式是什么关系？微服务和分布式在概念上比较相似，分布式属于微服务 微服务 微服务是一种架构风格，不是组件不是框架。由一系列微小的服务共同组成，每个服务为独立的业务开发，可以独立部署,跑在自己的进程,分布式的管理 分布式？ 分布式的定义是旨在支持应用程序和服务的开发，可以利用物理架构由多个自治的处理元素（多节点），不共享内存，但通过网络发送消息合作(分布式各个节点是通过发送消息来通信的，比如Http Rest接口，RPC)。分布式是一个业务拆分成多个子业务，每个子业务分别部署到不同的服务器上； 分布式是多节点的，集群也是多节点的，可以这样理解，如果一个厨房里有两个厨师，一个切菜一个炒菜做的事情互不干扰就是分布式，如果同时切菜同时炒菜就是集群; 好的设计应该是分布式和集群的设计，先分布式再集群，具体实现就是将业务拆分成很多子业务，然后针对每个子业务进行集群部署，如果子业务出了问题，整个系统不会受影响 微服务和分布式区别 ：简单来说微服务是架构设计方式，分布式和系统部署方式，概念不同；微服务相比分布式来说它的粒度更小，服务之间耦合度更低 微服务架构的基础框架或组件： 服务注册发现 服务网关（路由、监控、限流、容错、容器、日志、授权、反爬虫） 后端通用服务（请求时将地址信息放在服务注册表中） 前端服务（通过查询注册表发现并调用后端服务，主要是聚合后端服务和暴露外部接口） Spring Cloud 是什么？ Spring Cloud 是一个开发工具集，包含多个子项目主要是基于对 Netflix 开源组件的进一步封装 继承了了Spring Boot 的开发便利，简化了分布式开发 不仅需要掌握如何使用，更要理解分布式架构的特点","categories":[{"name":"微服务实战","slug":"微服务实战","permalink":"http://yoursite.com/categories/微服务实战/"}],"tags":[]},{"title":"Java异常","slug":"Java异常","date":"2019-11-07T13:33:15.000Z","updated":"2019-12-24T07:58:17.095Z","comments":true,"path":"2019/11/07/Java异常/","link":"","permalink":"http://yoursite.com/2019/11/07/Java异常/","excerpt":"","text":"异常机制主要回答了三个问题 what：异常类型回答了什么被抛出 where：异常堆栈跟踪回答了在哪抛出 why：异常信息回答了为什么被抛出 Java的异常体系 RuntimeException：不可预知的，程序应当自行避免（NullPointerException，IndexOutOfBoundsException ….. ） 非RuntimeExceptin：可预知的，从编译器校验的异常（IOException，SqlException…）任 error和exceptin的区别从概念角度解析Java的异常处理机制 error：程序无法处理的系统错误，编译器不做检查（StackOverFlowError,OutOfMemoryError） exception：程序可以处理的异常，捕获后可能恢复总结：前者是程序无法处理的错误，后者是可以处理的异常 从责任角度看 Error属于jvm需要承担的责任 RuntimeException是程序应该承当的责任 Checked Exception可检查异常是Java编译器应该负担的责 12345678910111213public class ErrorAndException&#123; private void throwError()&#123; throw new StackOverflowError(); &#125; private void throwRuntimeException()&#123; throw new RuntimeExeption &#125; private void throwCheckedException () throws FileNotFoundExcpetion&#123; //此处编译器会报错，checkedException是必须要追踪处理的异常，要么此处加try()catch&#123;&#125;在catch中增加处理逻辑，理解这种Exception的成因结合实际业务去处理 //最好通过throw方式把异常抛出去，让调用模块去处理 throw new FileNotFoundExcpetion(); &#125;&#125; 常见Error以及ExceptionRuntimeException NullPointerException-空指针异常 ClassCastException-类型强制转换异常 IllegalArguementException-传递非法参数异常 IndexOutOfBoundsException-下标越界异常 NumberFormatException-数字格式异常非RuntimeException ClassNotFoundException -找不到指定class的异常 IOExceptin-IO操作异常 Error NotClassDefFoundError-找不到class定义的异常： NotClassDefFondError的成因： 类依赖的class或者jar不存在 类文件存在，但是存在不同域中：对应的class在Java的classpath中不可用，又或者有多个不同的类加载器重复加载了同一个class 大小写问题，javac编译的时候无视大小写，很肯能编译出来的class文件就与想要的不一样 StackOverflowError-深递归导致栈被耗尽而抛出的异常 OutOfMemeryError-内存溢出异常 Java的异常处理机制 抛出异常：创建异常对象，交由运行时系统处理 捕获异常：寻找合适的异常处理器处理异常，否则终止运行 Java异常的处理原则 具体明确：抛出的异常应该能通过异常类名和message准确说明异常的类型和产出异常的愿意； 提早抛出：应尽可能早的发现并抛出异常，便于精确定位问题； 延迟捕获异常的捕获和处理应可能延迟，让掌握更多信息的作用域来处理 高效主流的异常处理框架 设计一个通用的继承自RuntimeExceptin的异常来统一处理 其余异常都统一转译为上述异常AppException 在catch之后，抛出上述异常的子类，并提供足以定位的信息 由前端接受AppExcception做统一处理 try-catch的性能Java异常处理消耗性能的地方 try-catch块影响JVM的优化 异常对象实例需要保存栈快照等信息，开销较大","categories":[{"name":"Java常用类库与技巧","slug":"Java常用类库与技巧","permalink":"http://yoursite.com/categories/Java常用类库与技巧/"}],"tags":[{"name":"异常","slug":"异常","permalink":"http://yoursite.com/tags/异常/"}]},{"title":"Java多线程与并发-原理","slug":"Java多线程与并发-原理","date":"2019-11-06T09:26:44.000Z","updated":"2020-02-22T01:18:53.488Z","comments":true,"path":"2019/11/06/Java多线程与并发-原理/","link":"","permalink":"http://yoursite.com/2019/11/06/Java多线程与并发-原理/","excerpt":"","text":"synchronized 关键字 对于 synchronized 关键字的了解synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（Monitor Lock）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 互斥锁的特性 互斥性：即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程的协调机制，这样在同一时间只有一个线程对需要同步的代码块（复合操作）进行访问。互斥性也称为操作的原子性。 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值），否则另一个线程可能是在本地缓存的某个副本上继续操作，从而引起不一致 怎么使用 synchronized 关键字？获取对象锁 同步代码块(synchronized(this)，synchronized(类实例对象))，锁是小括号()中的实例对象 同步非静态方法(synchronized method)，锁的是当前对象的实例对象 123456789101112131415/** *方法中有 synchronized(this|object) &#123;&#125; 同步代码块 */private void syncObjectBlock1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectBlock1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); synchronized (this) &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectBlock1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectBlock1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 12345678910111213/** *synchronized 修饰非静态方法 */private synchronized void syncObjectMethod1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectMethod1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectMethod1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectMethod1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 获取类锁的两种用法 ，给Class类上锁 同步代码块（synchronized（类.class），锁是小括号（）中的类对象（Class对象） 同步静态方法（synchronized static method），锁是当前对象的类对象（Class对象） 123456789101112private void syncClassBlock1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassBlock1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); synchronized (SyncThread.class) &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassBlock1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncClassBlock1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 1234567891011//同步静态方法private synchronized static void syncClassMethod1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassMethod1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassMethod1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncClassMethod1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 类锁和对象锁的总结 有线程访问对象的同步代码块时，另外的线程可以访问该对象的非同步代码块； 若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个访问对象的同步代码块的线程会被阻塞； 若锁住的是同一个对象，一个线程在访问对象的同步方法时，另一个访问对象同步方法的线程会被阻塞； 若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个访问对象同步方法的线程会被阻塞，反之亦然 同一个类的不同对象的对象锁互不干扰 类锁由于也是一种特殊的对象锁，因此表现和上述1，2，3，4一致，而由于一个类只有一把对象锁，所以同一个类的不同对象使用类锁将会是同步的 类锁和对象锁互不干扰 synchronized底层实现原理 synchronized 关键字底层原理属于 JVM 层面。 每个Java对象都可以用做一个实现同步的锁这些锁被称为监视器锁（Monitor Lock）或内置锁（Intrinsic Lock）线程在进入同步代码块之前会自动获得锁，在退出同步代码块时释放锁。 ① synchronized 同步语句块的情况 1234567public class SynchronizedDemo &#123; public void method() &#123; synchronized (this) &#123; System.out.println(&quot;synchronized 代码块&quot;); &#125; &#125;&#125; 通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -verbose SynchronizedDemo.class。 从上面我们可以看出： synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 ② synchronized 修饰方法的的情况 12345public class SynchronizedDemo2 &#123; public synchronized void method() &#123; System.out.println(&quot;synchronized 方法&quot;); &#125;&#125; synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 ObjectMonitor源码 Monitor是由ObjectMonitor实现的，位于JVM源码即ObjectMonitor.hpp文件里面，它是通过c++来实现的，EntryList(锁池)，waitSet（等待池）。他们就是用来保存Objectwaiter的对象列表，每个对象锁的线程都会被封装成Objectwaiter来保存到里面，owner是指向指向持有ObjectMonitor的线程，当多个线程同时访问同一段同步代码的时候，首先会进如到EntryList集合里面，当线程获取到对象的Monitor后进入_Owner区域并把monitor中的_owner变量设置为当前线程，同时monitor中的计数器_count加1。即获得对象锁。若持有monitor的线程调用wait()方法，将释放当前持有的monitor，_owner变量恢复为null，_count自减1，同时该线程进入_WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。monitor对象存在于每个java对象的对象头中，monitor也是class,其实例会存储在堆中,MarkWord中保存的是它的指针 https://blog.csdn.net/uftjtt/article/details/80250182 有类似的讲解 在上面的源码我们可以看到ObjectMonitor中有几个关键属性： _owner：指向持有ObjectMonitor对象的线程 _WaitSet：存放处于wait状态的线程队列 _EntryList：存放处于等待锁block状态的线程队列 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗 JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四中状态，依次是：无锁状态&gt;偏向锁状态&gt;轻量级锁状态&gt;重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 ①偏向锁 引入偏向锁的目的和引入轻量级锁的目的很像，他们都是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。 核心思想：如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变成了偏向锁结构，如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步，即获取锁的过程只需要检查Mark Word的锁标记为偏向锁，以及当前线程Id等于Mark Word的ThreadID即可，这样就省去了大量有关锁申请的操作 但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，而是先升级为轻量级锁。 ② 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段 ;轻量级锁的加锁和解锁都用到了CAS操作。轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁会升级为轻量级锁适应的场景：线程交替执行同步块如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！ ③ 自旋锁与自适应自旋锁 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进自旋锁的优化手段。 一般线程持有锁的时间都不是太长，切换线程不值得,通过让线程执行忙循环等待锁的释放，不让出CPU,这项技术就叫做自旋。缺点：若锁被其他线程长时间占用，会带来许多性能上的开销 需要注意的是：自旋等待不能完全替代阻塞，因为它还是要占用处理器时间。如果锁被占用的时间短，那么效果当然就很好了！反之，相反！自旋等待的时间必须要有限度。如果自旋超过了限定次数任然没有获得锁，就应该挂起线程 在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。 （如果在同一个锁对象上自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，JVM会认位该锁自旋获取到锁的可能性很大，会自动增加等待时间，相反，如果对于某个锁 ，自旋很少成功获取到锁，那在以后要获取这个锁时，可能会省略掉自旋过程，以避免浪费处理器资源） ④ 锁消除如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。 123456public void add(String str1, String str2) &#123; //StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用 //因此sb属于不可能共享的资源,JVM会自动消除内部的锁 StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2);&#125; ⑤ 锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，那么会带来很多不必要的性能消耗。 12345678public static String copyString100Times(String target)&#123; int i = 0; StringBuffer sb = new StringBuffer(); while (i&lt;100)&#123; sb.append(target); &#125; return sb.toString();&#125; 锁的内存语义 偏向锁、轻量级锁、重量级锁的汇总 synchronized和ReentrantLock的对比 synchronized是关键字，ReentrantLock是类 ① 两者都是可重入锁 重入:从互斥的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入 ② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成） ③ ReenTrantLock 比 synchronized 增加了一些高级功能 主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件） ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。 synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 公平锁和非公平锁的代码实现 1234567891011121314151617181920212223242526public class ReentrantLockDemo implements Runnable&#123; //参数为true时，倾向于将锁赋予等待时间最久的线程 private static ReentrantLock lock = new ReentrantLock(true); @Override public void run()&#123; while (true)&#123; try&#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot; get lock&quot;); Thread.sleep(1000); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) &#123; ReentrantLockDemo rtld = new ReentrantLockDemo(); Thread thread1 = new Thread(rtld); Thread thread2 = new Thread(rtld); thread1.start(); thread2.start(); &#125;&#125; 公平锁和非公平锁的性能差异，差别在哪里？ReentrantLock的内部类Sync继承了AQS，分为公平锁FairSync和非公平锁NonfairSync 非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。 公平锁要维护一个队列，线程获取锁的顺序和调用lock的顺序一样 ，后来的线程要加锁，即使锁空闲也要先检查有没有其他线程在 wait，如果有自己要挂起，加到队列后面，然后唤醒队列最前面的线程。这种情况下相比较非公平锁多了一次挂起和唤醒 因此线程切换的开销，其实就是非公平锁效率高于公平锁的原因，因为非公平锁减少了线程挂起的几率，后来的线程有一定几率逃离被挂起的开销。 volatile 关键字 讲一下Java内存模型 Java内存模型JMM （Java Memory Model,简称JMM）是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（实例字段、静态字段、构成数组对象的元素）的访问方式 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方称为栈空间），用于存储线程私有的数据，而Java内存模型中规定所有变量都存储在主内存中，主内存是共享内存区域所有线程都可以访问，但线程对变量的操作（读取、赋值等）必须在工作内存中进行。 首先将变量从主内存copy到自己的工作内存空间当中，然后对变量进行操作，操作完成后，再将变量写回主内存，不能直接操作主内存中的变量； 工作内存中存储着主内存中变量的副本拷贝，工作内存是每个线程的私有区域，因此不同的线程间无法访问对方的工作内存，线程间的通信传值必须通过主内存完成 JMM中的主内存 存储Java实例对象 包括成员变量、类变量、常量、静态变量等 属于数据共享的区域，多线程并发操作时会引发线程安全问题 JMM中的工作内存 存储当前方法的所有本地变量信息，本地变量对其他线程不可见 字节码行号指示器、Native方法信息 属于线程私有数据区域，不存在线程安全问题 JMM与JVM内存区域划分是不同的层次概念 JMM描述的是一组规则，围绕原子性，有序性，可见性展开 相似点：存在共享区域和私有区域 主内存与工作内存的数据存储类型以及操作方式归纳 方法里的基本数据类型本地变量将直接存储在工作内存的栈帧结构中 引用类型的本地变量：引用存储在工作内存中，实例存储在主内存中 成员变量，static变量、类信息均会被存储在主内存中 主内存共享的方式是线程各拷贝一份数据到工作内存，操作完成后刷新到主内存中 JMM如何解决可见性问题指令重排序需要满足的条件 在单线程环境下不能改变程序运行的结果 存在数据依赖关系的不允许重排序 无法通过happends-before原则推导出来的，才能进行指令的重排序 A操作的结果需要对B操作可见，则A与B存在happends-before关系是判断数据是否存在竞争，线程是否安全的主要依据；依靠这个原则我们便能解决在并发环境下两个操作之间存在冲突的问题。 12i = 1；//线程A执行j = i; //线程B执行 happends-before的八大原则 单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。 volatile的happen-before原则：对一个volatile变量的写操作happen-before对此变量的任意操作(当然也包括写操作了)。 happen-before的传递性原则：如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。 线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。 线程中断的happen-before原则：对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的代码。 线程终结的happen-before原则：线程中的所有操作都happen-before线程的终止检测。 对象创建的happen-before原则：一个对象的初始化完成先于他的finalize方法调用 happends-before的概念 如果两个操作不满足上述任意一个happends-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序 如果操作A happends-before操作B,那么操作A在内存上所做的操作对操作B都是可见的 1234567private int value = 0public void write(int input)&#123; value = input;&#125;public int read()&#123; return value;&#125; 假设线程A执行write方法，线程B执行read方法，此代码块块不满足happends-before的八大原则，所以这段代码不是线程安全的；解决办法： 加入synchronized锁 对value加入volatile修饰符即可 volatile:JVM提供的轻量级同步机制把变量声明为volatile，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。 说白了， volatile 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。 volatile变量为何立即可见？ 当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量刷新到主内存中； 当读取一个volatile变量时，JMM会把该线程对应的工作内存置为无效 volatile如何禁止重排优化 通过插入内存屏障指令,禁止在内存屏障前后的指令执行重排序优化 强制刷出各种CPU的缓存数据，因此任何cpu上的线程都能读取到这些数据的最新版本 内存屏障（Memory Barrier）是一个CPU指令，1：保证特定操作的执行顺序 2：保证某些变量的内存可见性;volatile就是通过内存屏障实现其内存语义（可见性，禁止重排优化）。 volatile的可见性 1234567public class VolatileViasibility&#123; public static volatile int value =0; public static void increase()&#123; value++; &#125;&#125; 此段代码中 value变量的任何变化都会反映到线程中，如果多个线程同时调用increase()会出现线程安全问题，因为value++操作不具备原子性（先读再写两步操作） 解决办法：incarease()使用synchronized修饰保证线程安全，synchronized解决的是执行控制的问题，阻止其他线程获取当前对象的监控锁，当前被synchronized修饰的代码块无法被其他线程访问 代码修改后： 1234567public class VolatileViasibility&#123; public static int value =0; public synchronized static void increase()&#123; value++; &#125;&#125; synchronized 会创建一个内存屏障，保证所有cpu结果都会刷到主存中，从而保证操作的内存可见性。 另外一种使volatile达到线程安全的场景 12345678910111213//对shutdown值的修改属于原子性操作public class VolatileSage( volatile boolean shutdown; public void close()&#123; shutdown=true; &#125; public void doWork()&#123; while(!shutdown)&#123; System.out.println(\"sage...\"); &#125; &#125;) 单例的双重检测实现（线程安全）123456789101112131415161718192021public class Singleton&#123; //禁止指令重排优化 private volatile static Singleton instance; private Singleton()&#123;&#125; public static Singleton getIntance()&#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if(instance==null)&#123; //类对象加锁 synchronized(Singleton.class)&#123; if (instance == null)&#123; //多线程环境下可能会出现问题的地方 instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 需要注意 instance 采用 volatile 关键字修饰也是很有必要。 instance 采用 volatile 关键字修饰也是很有必要的， instance = new Singleton(); 这段代码其实是分为三步执行： 为instance分配内存空间 初始化对象 设置instance指向刚分配的内存地址，此时instance!=null 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getIntance() 后发现 为instance分配内存空间 不为空，因此返回 为instance分配内存空间，但此时 为instance分配内存空间 还未被初始化 volatile和synchronized的区别 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞 volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。 volatile标记的变量不会被编译器优化；synchronnized标记的变量可以被编译器优化 Java线程池 前言：在web开发中，服务器需要接受并处理请求，所以会为一个请求来分配一个线程进行处理，如果并发的请求数量非常多，但每个线程执行的时间很短，这样就会频繁的创建和销毁线程，如此一来会大大降低系统的效率，可能出现服务器在为每个请求创建新线程和销毁线程上花费的时间和消耗的系统资源要比处理实际的用户请求的时间和资源更多。 为什么要用线程池&gt;《Java并发编程的艺术》提到使用线程池的好处： 降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 实现Runnable接口和Callable接口的区别如果想让线程池执行任务的话需要实现的Runnable接口或Callable接口。 Runnable接口或Callable接口实现类都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。两者的区别在于 Runnable 接口不会返回结果但是 Callable 接口可以返回结果。 执行execute()方法和submit()方法的区别是什么呢？ execute() 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit() 方法用于提交需要返回值的任务。线程池会返回一个Future类型的对象，通过这个Future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成 如何创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。 方式一：通过构造方法实现 线程池的工作原理： 线程池会有一个工作队列WorkQueue接客，存储用户提交的各个任务 队列接到任务后就会排队交给线程池 即工作线程的集合WorkerThread，该集合需要在运行的过程中管理线程的创建和销毁。线程池的线程被抽象为Worker静态内部类，ThreadPool其实维护的就是一组Worker对象。 ThreadPoolExecutor的构造函数： corePoolSize:核心线程数量； maximumPoolSize:线程不够用的时候能够创建最大线程数 workQueue:任务等待队列：当任务提交时如果线程池中的线程数量&gt;=corePoolSize的时候，把该任务封装成一个worker对象放入到等待队列中； keepAliveTime:线程池允许线程维护的空闲时间； threadFactory:创建新线程，默认使用的是Executors.defaultThreadFactory() handler:线程池的饱和策略： AborPolicy:直接抛出异常，这是默认策略； CallerRUnsPolicy:用调用者所在的线程来执行任务； DiscardOldersPolicy:丢弃队列中靠最前的任务，并执行当前任务； DiscardPolicy:直接丢弃任务； 实现RejectedExecutionHander接口的自定义hander 新任务提交execute执行后的判断 如果运行的线程少于 corePoolSize,则创建新线程来处理任务，即使线程池中的其他线程是空闲的； 如果线程池中的线程数量大于等于 corePoolSize切小于maximumPoolSize,则只有当workQueue满时才创建新的线程去处理任务； 如果设置的corePoolSize 和 maximumPoolSize相同，则创建线程池的大小是固定的，这使如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理; 如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务； 方式二：通过Executors创建不同的线程池满足不同场景的需求 位于JUC包下Executors.java newFixedThreadPool(int nThreads):该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 newSingleThreadExecutor()：方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 newCachedThreadPool()处理大量短时间工作任务的线程池 试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程 如果线程闲置的时候超过阈值，则会被终止并移出缓存 系统长时间闲置的时候，不会消耗什么资源 newSingleThreadScheduledExecutor() 与 newScheduledThreadPool(int corePoolSize)定时或周期性的工作调度，两者区别在于单一工作线程还是多个线程 newWorkStealingPool()内部会构建ForkJoinPool,利用working-stealing算法，并行地处理任务，不保证处理顺序 Fork/Join框架：把大任务分割成若干小任务并行执行，最终汇总每个小任务结果后得到大任务结果的框架 Work-Stealing算法：某个线程从其他队列里窃取任务来执行 线程池的状态 RUNNING:能接受新提交的任务，并且也能处理阻塞队列中的任务 SHUTDOWN:不再接受新提交的任务，但可以处理存量任务 STOP:不再接受新提交的任务，也不处理存量任务 TIDYING:所有的任务都已经终止 TERMINATED:terminated()方法执行完后进入该状态 状态转换图 shutdown 会关闭提交任务到队列 但是队列中的任务还是会执行完 shutsownnow 会关闭提交任务到队列 且 不会执行队列中的任务 并且正在执行任务的线程也会被interrupt 工作线程的生命周期 线程池的大小如何选定 CPU密集型：线程数=按照核数或者核数+1设定 I/0密集型：线程数=CPU核数*(1+平均等待时间/平均工作时间)","categories":[{"name":"Java多线程与并发","slug":"Java多线程与并发","permalink":"http://yoursite.com/categories/Java多线程与并发/"}],"tags":[]},{"title":"Java框架-Spring","slug":"Java框架-Spring","date":"2019-11-05T14:46:40.000Z","updated":"2020-02-29T03:50:37.129Z","comments":true,"path":"2019/11/05/Java框架-Spring/","link":"","permalink":"http://yoursite.com/2019/11/05/Java框架-Spring/","excerpt":"","text":"此篇文章帮助自己 从Spring 的源码角度了解Spring的原理 IOC原理IOC（Inversion of Control）：控制反转；Spring Core最核心部分；IOC是一种思想。 实现手段：依赖注入（Dependency Injection）把底层类作为参数传递给上层类，实现上层对下层的“控制” 依赖注入的方式 Setter Setter注入 Interface 接口注入 Constructor 构造器注入 Annotation 注解注入 依赖倒置原则、IOC、DI、IOC容器的关系 依赖倒置原则是一种思想，高层模块不应该依赖底层模块； 有了依赖倒置原则才有了IOC的思路； 实现IOC的思路又需要依赖注入的支撑； Spring的框架基于IOC提出了容器的概念，对于IOC来说最重要的就是容器了，容器管理着bean的生命周期，控制着bean的依赖注入。 IOC容器的优势 避免在各处使用new来创建类，并且可以做到统一维护 创建实例的时候不需要了解其中的细节当使用的时候，IOC容器在内部已经完成对象，调用者只需要调用即可！如图蓝色部分全部是由IOC容器完成！ 因为采用了依赖注入在初始化的过程中就不可避免的写大量的new,这里IOC容器就解决了这个问题，这个容器可以自动对代码初始化，你需要维护一个configuration,可以是XML或者可以是一段代码，而不用每次初始化一个行李箱，写一大堆的初始化代码 IOC容器可以隐藏具体创建实例的细节，上图中蓝色部分就像一个工厂，我们只需要向工厂请求一个Luggage实例，然后它就会按照config创建一个Luggage实例，我们不用管Luggage实例是怎么一步一步创建的；实例项目中有些Service是很多年以前写的，有几百个类作为它的底层，假设我们新写了一个API需要实例化这个service,总不可能回头去搞清楚这几百个类的构造函数吧；IOC Container就很完美的解决了这类问题；因为这个架构在要求你写Class的时候需要编写相的config文件，所以你要初始化很久以前的service的时候呢前人都已经写好了config文件了，你直接在用的地方注入这个service就可以了，这大大增加了项目的可维护性降低开发难度 IOC的应用Bean生成的简要步骤 Spring启动时读取应用程序提供的Bean配置信息，并在Spring容器中生成一份相应的Bean注册表。 根据生成的Bean注册表通过反射机制实例化Bean，并装配好Bean之间的依赖关系，为上层提供准备就绪的运行环境。Spring提供一个配置文件描述bean和bean之间的依赖关系，利用Java语言的反射功能实例化bean,并建立bean之间的依赖关系 将生成的Bean实例对象放入Spring容器中。 Spring IOC支持的功能： 依赖注入 依赖检查 自动装配 支持集合 指定初始化方法和销毁方法 支持回调方法 Spring IOC容器的核心接口BeanDefinition 主要是用来描述Bean的定义，Spring容器在启动的时候会将xml或者注解里的bean的定义解析成内部的BeanDefinition BeanDefinitionRegistry 提供向IOC容器注册BeanDefinition对象的方法 ； BeanDefinitionRegistry接口提供了 registerBeanDefinition 用来将我们的BeanDefinition注册到BeanFactory 接口的实现类 DefaultListableBeanFactory中的 beanDefinitionMap里，Spring将bean的定义解析成BeanDefinition之后会通过BeanDefinitionRegistry 以BeanName 为key,BeanDefinition为value存储到beanDefinitionMap里，同时还将BeanName存入到beanDefinitionNames里以便后续Bean的实例化 相关源码： 123public interface BeanDefinitionRegistry extends AliasRegistry &#123; void registerBeanDefinition(String var1, BeanDefinition var2) throws BeanDefinitionStoreException;&#125; 1234public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap(256); private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList(256);&#125; BeanFactory：Spring框架最核心的接口 提供IOC的配置机制 包含Bean的各种定义，便于实例化Bean 建立Bean之间的依赖关系 Bean生命周期的控制 ApplicationContext（继承多个接口） 继承BeanFactory:能够管理、装配Bean 继承ResourcePatternResolver:能够加载资源文件 继承MessageSource:能够实现国际化功能 继承ApplicationEventPublisher:能够注册监听器，实现监听机制 BeanFactory和ApplicationContext有什么区别？BeanFactory是Spring框架的基础设施，面向Spring,ApplicationContext面向使用Spring框架的开发者BeanFactory采用了工厂设计模式，负责读取bean配置文档，管理bean的加载，实例化，维护bean之间的依赖关系，负责bean的生命周期。而ApplicationContext除了提供上述BeanFactory所能提供的功能之外，还提供了更完整的框架功能：国际化支持、aop、事务等。同时BeanFactory在解析配置文件时并不会初始化对象,只有在使用对象getBean()才会对该对象进行初始化，而ApplicationContext在解析配置文件时对配置文件中的所有对象都初始化了,getBean()方法只是获取对象的过程。因此我们一般在使用的时候尽量使用ApplicationContext。 Spring中几个重要方法refresh 方法Spring容器在创建好了之后会调用refresh()方法SpringApplication.class 中 refresh的源码 1234protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext)applicationContext).refresh();｝ AbstractApplicationContext.class 123456789101112131415161718192021222324252627282930313233343536373839404142public void refresh() throws BeansException, IllegalStateException &#123; Object var1 = this.startupShutdownMonitor; synchronized(this.startupShutdownMonitor) &#123; //设置Spring容器的启动时间，开启活跃状态，初始化属性与信息，验证环境信息里面必须存在的属性 this.prepareRefresh(); //获取beanFactory ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); //设置beanFactory this.prepareBeanFactory(beanFactory); try &#123; this.postProcessBeanFactory(beanFactory); // 处理bean标签扫描bean文件，解析成一个个的bean this.invokeBeanFactoryPostProcessors(beanFactory); //bean的后置处理器 this.registerBeanPostProcessors(beanFactory); //初始化一些国际化相关的属性 this.initMessageSource(); //初始化事件的广播器，用于事件发布 this.initApplicationEventMulticaster(); //模板方法，方法体为空，不同的Spring容器去重写 this.onRefresh(); //注册监听器 this.registerListeners(); //实例化BeanFactory中已经被注册未被实例化的所有实例 this.finishBeanFactoryInitialization(beanFactory); //初始化生命周期管理器 this.finishRefresh(); &#125; catch (BeansException var9) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt: &quot; + var9); &#125; this.destroyBeans(); this.cancelRefresh(var9); throw var9; &#125; finally &#123; this.resetCommonCaches(); &#125; &#125; &#125; 为IOC容器以及Bean的生命周期管理提供条件 刷新Spring上下文信息，定义Spring上下文加载流程 getBean 方法通过AbstractBeanFactoryFactory.class 实现可以按类型获取bean的，也有按名称获取bean的getBean方法的代码逻辑 转换beanName 从工厂或者缓存中加载实例 实例化Bean 检测parentBeanFactory 检查初始化Bean的相关的依赖 创建Bean 常见问题1.Spring的五个作用域 singleton:Spring的默认作用域，容器里拥有唯一的Bean实例 prototype:针对每个getBean请求，容器都会创建一个Bean实例 request:为每个Httpp请求创建一个Bean实例 session：会为每个session创建一个Bean实例 globlaSession:会为每个全局Http Session创建一个Bean实例，该作用域仅对Portlet有效 2.SpringBean的生命周期 创建过程 销毁过程 若实现了DisposableBean接口，则会调用destroy方法 若配置了destry-method属性，则会调用其配置的销毁方法 bean如何装载到IOC容器中和依赖注入的用法第一种方式： 手动装配bean,简单粗暴，但是如果bean多的话是一件非常痛苦的事情 创建一个class Person 12345public class person&#123; private Long id; private String name; //get,set省略&#125; 定义一个Java的配置文件 ApplicationConfig,主要作用是告诉IOC容器如何装配这个bean 12345678910@Configuretionpublic class ApplicationConfig&#123; @Bean(name=&quot;person&quot;) public Person initPerson()&#123; Person user = new Person(); user.setId(1L); user.setName(&quot;jack&quot;); return user; &#125;&#125; 通过ApplicationContext来获取bean实例1234ApplicationContext ctx = SpringApplication.run(ProductApplication.class, args);Person person = ctx.getBean(&quot;Peroson.class&quot;);//通过类型来获取System.out.println(&quot;Name is &quot;+person.getName);person.call(); 第二种方式： 以SpringBoot方式扫描装配Bean到IOC容器中 对Person进行改动 加入@Component 注解，表明哪个类要被扫描进入到SpringIOC容器中 12345678@Component(&quot;Person&quot;)public class person&#123; @Value(&quot;1&quot;) private Long id; @Value(&quot;Jack&quot;) private String name; //get,set省略&#125; 实现依赖注入 新建 Pet.class 123public inteface Pet&#123; void move();&#125; 创建Pet实现类 Dog 1234567@Componentpublic class Dog implements Pet&#123; @Override public void move()&#123; System.out.println(&quot;running&quot;); &#125;&#125; Person中注入 12345678910111213@Component(&quot;Person&quot;)public class person&#123; @Value(&quot;1&quot;) private Long id; @Value(&quot;Jack&quot;) private String name; @Autowired private Pet pet; public void call()&#123; pet.move(); &#125;&#125; 如果新增一个再增加一个Pet的实现类 Bird ,person.call()调用会报错，不知道该调用哪个实现方法，可以加@Primary 或 @Qualifier 告诉Spring该选择谁 12345678@Component@Primarypublic class Bird implements Pet&#123; @Override public void move()&#123; System.out.println(&quot;flying&quot;); &#125;&#125; 再次调用person.call() 就会正常输出 flying Spring AOP关注点分离：不同的问题交给不同的部分去解决 面向切面编程AOP正是此种技术的体现 通用代码的实现，对应的就是所谓的切面（Aspect） 业务功能代码和切面代码分开后，架构将变得高内聚低耦合 确保功能的完整性：切面最终需要被合并到业务中（Weave） AOP的三种织入方式 编译时织入：需要特殊的Java编译器，AspectJ 类加载时织入：需要特殊的Java编译器，如AspectJ和AspectWerkz 运行时织入：Spring采用的方式，通过动态代理的方式，实现简单 一个简单的代码实现：记录请求的信息 123456789@RestControllerpublic class HelloController &#123; @GetMapping(&quot;/hello&quot;) public String hello()&#123; String sentence = &quot;Hello World&quot;; System.out.println(sentence); return sentence; &#125;&#125; 新建切面类： 12345678910111213141516171819202122232425@Aspect@Componentpublic class RequestLogAspect &#123; private static final Logger logger = LoggerFactory.getLogger(RequestLogAspect.class); @Pointcut(&quot;execution(public * com.imooc.framework.controller..*.*(..))&quot;) public void webLog()&#123;&#125; @Before(&quot;webLog()&quot;) public void doBefore(JoinPoint joinPoint)&#123; //接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); //记录下请求内容 logger.info(&quot;URL: &quot;+ request.getRequestURI().toString()); logger.info(&quot;IP: &quot; + request.getRemoteAddr()); &#125; @AfterReturning(returning = &quot;ret&quot; ,pointcut = &quot;webLog()&quot;) public void doAfterReturning(Object ret)&#123; //处理完请求，返回内容 logger.info(&quot;RESPONSE: &quot; + ret); &#125;&#125; AOP主要名词概念 Aspect:通用功能代码的实现，切面 普通的java类RequestLogAspect Target:被织入Aspect的对象 HelloController Join Point：可以作为切入点的机会，所有的方法都可以作为切入点 所有方法的执行处，如前面的hello方法 Pointcut:Aspect实际被应用在的Join Point，支持正则 1@Pointcut(&quot;execution(public * com.imooc.framework.controller..*.*(..))&quot;) Advice:类里的方法以及这个方法如何织入到目标方法的方式 前置通知（Before） 后置通知（AfterReturning） 异常通知（AfterThrowing） 最终通知（After） 环绕通知（Around） Weaving:Aop的实现过程,将切面应用到实际对象从而创建一个新的代理对象的过程 AOP的实现：JdkProxy和Cglib 由AopProxyFactory根据AdvisedSupport对象配置来决定 默认策略如果目标是接口，则用JDKProxy来实现，否则用后者 JDKProxy的核心：InvocationHandler接口和Proxy类 Cglib:以继承的方式动态生成目标类的代理（如果某个类被标记成final它是无法使用Cglib做动态代理的） JDKProxy:通过Java的内部反射机制实现 Cglib:借助ASM实现，一种能够操作字节码的框架 反射机制在生成类的过程中比较高效 ASM在生成类之后的执行过程中比较高效 代理模式：接口+真实实现类+代理类简单代码实现： 新建一个接口实现pay方法 真实实现类和代理类都要实现该方法 在代理类中注入真实实现类，在代理类的实现方法pay()中调用真实实现类的pay()方法，然后增加做自己的业务逻辑 123public interface Payment&#123; void pay();&#125; 1234567public RealPayment implements Payment&#123; @Override public void pay()&#123; System.out.println(&quot;作为用户我只关心支付&quot;) &#125;&#125; 1234567891011121314151617public AliPay implements Payment&#123; private Payment payment; public AliPay(Payment payment) public void beforePay()&#123; System.out.println(&quot;从招行取款&quot;) &#125; @Override public void pay()&#123; beforePay()； payment.pay(); afterPay(); &#125; public void afterPay()&#123; System.out.println(&quot;支付给慕课网&quot;) &#125;&#125; 12Payment proxy = new AliPay(new RealPayment);proxy.pay(); Spring里的代理模式的实现 真实实现类的逻辑包含在了getBean方法里 getBean方法返回的实际上是Proxy实例 Proxy实例是Spring采用JDK Proxy或CGLIB动态生成的 底层逻辑代码实现：AbstractAutoProxyCreator.postProcessAfterInitialization() -&gt; wrapIfNecessary() -&gt;createProxy()-&gt;ProxyFactory.getProxy()-&gt;ProxyCreatorSupport.createAopProxy()-&gt;ProxyCreatorSupport.DefaultAopProxyFactory-&gt;DefaultAopProxyFactory.createAopProxy() 最终看到生成代理的最底层方法，这里只能说Spring的结构真实太复杂了，层层调用 0.0 123456789101112public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (!config.isOptimize() &amp;&amp; !config.isProxyTargetClass() &amp;&amp; !this.hasNoUserSuppliedProxyInterfaces(config)) &#123; return new JdkDynamicAopProxy(config); &#125; else &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: Either an interface or a target is required for proxy creation.&quot;); &#125; else &#123; return (AopProxy)(!targetClass.isInterface() &amp;&amp; !Proxy.isProxyClass(targetClass) ? new ObjenesisCglibAopProxy(config) : new JdkDynamicAopProxy(config)); &#125; &#125;&#125; Spring事务的相关问题 ACID 隔离级别 事务传播 可参考 什么是事务传播行为 可参考 spring的4种事务特性，5种隔离级别，7种传播行为","categories":[{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/categories/Spring/"}],"tags":[{"name":"IOC","slug":"IOC","permalink":"http://yoursite.com/tags/IOC/"},{"name":"AOP","slug":"AOP","permalink":"http://yoursite.com/tags/AOP/"}]},{"title":"Java多线程与并发","slug":"Java多线程与并发","date":"2019-11-05T03:19:48.000Z","updated":"2020-03-15T11:37:12.132Z","comments":true,"path":"2019/11/05/Java多线程与并发/","link":"","permalink":"http://yoursite.com/2019/11/05/Java多线程与并发/","excerpt":"","text":"什么是线程和进程? 何为进程?进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 何为线程?线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 请简要描述线程与进程的关系,区别？一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈 进程是资源分配的最小单位，线程是CPU调度的最小单位线程不能看做独立应用，而进程可以看做独立应用， 进程有独立的地址空间，相互不影响，线程只是进程不同的执行路径，线程没有独立的地址空间，线程执行开销小，但不利于资源的管理和保护；而进程正相反； 线程的状态 六个状态 新建（New）：创建后尚未启动的线程的状态 运行（Runnable）：包含系统的Ready和Running，处于Ready状态的线程位于线程池中，等待被线程调度选中，获取CPU的使用权，Ready状态的线程在获取CPU时间后，就会变成Running状态的线程 无限期等待（Waiting）：不会被分配CPU执行时间，需要显示被唤醒，即： 1）没有设置Timeout参数的Object.wait方法。 2）没有设置Timeout参数的Thread.join方法。 3）LockSupport方法。 限期等待（Timed Waiting）：在一定时间后会由系统自动唤醒。以下情况会造成限期等待： 1）Thread.sleep()方法 2）设置了Timeout参数的Object.wait()方法 3）设置了Timeout参数的Thread.join()方法 4）LockSupport.parkNanos()方法 5）LockSupport.parkUntil()方法 阻塞状态（Blocked）：等待获取排它锁,在另外一个线程放弃锁的时候发生 结束（Terminated）：已终止线程的状态，线程已经结束执行 由上图可以看出：线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。 当线程执行 wait()方法之后，线程进入 WAITING（等待） 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。 什么是线程死锁?如何避免死锁? 认识线程死锁多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》) 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo &#123; private static Object resource1 = new Object();//资源 1 private static Object resource2 = new Object();//资源 2 public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + \"get resource1\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + \"waiting get resource2\"); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + \"get resource2\"); &#125; &#125; &#125;, \"线程 1\").start(); new Thread(() -&gt; &#123; synchronized (resource2) &#123; System.out.println(Thread.currentThread() + \"get resource2\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + \"waiting get resource1\"); synchronized (resource1) &#123; System.out.println(Thread.currentThread() + \"get resource1\"); &#125; &#125; &#125;, \"线程 2\").start(); &#125;&#125; Output 1234Thread[线程 1,5,main]get resource1Thread[线程 2,5,main]get resource2Thread[线程 1,5,main]waiting get resource2Thread[线程 2,5,main]waiting get resource1 线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000);让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。 产生死锁必须具备以下四个条件： 互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件：线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 如何避免线程死锁?破坏请求与保持条件 一次性申请所有的资源。 破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 如何排查死锁？ jstack:JDK自带线程堆栈分析工具，用来查看java线程堆栈信息 使用jstack可以生成java虚拟机当前时刻的线程快照，定位线程长时间停顿的原因：线程间死锁、死循环、请求外部资源导致的长时间等待等 通过上面的死锁demo制造线程间的死锁 然后在服务器上使用 jps 命令查看当前运行的java线程 1238665 jps8652 DeadLockDemo8653 .... 使用 jstack + 进程号 生成 DeadLockDemo 进程的线程快照 &gt; jstack 8652 线程start和run方法的区别 new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用start方法会创建一个新的子线程，启动线程并使线程进入就绪状态， run方法只是Thread的一个普通方法的调用 Thread和Runnable是什么关系 Thread是实现了Runnable接口的类，使得run支持多线程 不同的是实现Runnable类中没有start()方法，所以需要Thread构造个方法开启线程 ,因类的单一继承原则，为了提升系统可扩展性推荐业务类实现Runnable接口，将业务逻辑封装在run()方法里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//Thread的使用public class MyThread extends Thread &#123; private String name; public MyThread(String name)&#123; this.name = name; &#125; @Override public void run()&#123; for(int i = 0 ; i &lt; 10 ; i ++)&#123; System.out.println(\"Thread start : \" + this.name + \",i= \" + i); &#125; &#125;&#125;//测试类 public static void main(String[] args) &#123; MyThread mt1 = new MyThread(\"Thread1\"); MyThread mt2 = new MyThread(\"Thread2\"); MyThread mt3 = new MyThread(\"Thread3\"); mt1.start(); mt2.start(); mt3.start(); &#125;``` ```java//Runable的使用public class MyRunnable implements Runnable &#123; private String name; public MyRunnable(String name)&#123; this.name = name; &#125; @Override public void run()&#123; for(int i = 0 ; i &lt; 10 ; i ++)&#123; System.out.println(\"Thread start : \" + this.name + \",i= \" + i); &#125; &#125;//测试类 public static void main(String[] args) throws InterruptedException &#123; MyRunnable mr1 = new MyRunnable(\"Runnable1\"); MyRunnable mr2 = new MyRunnable(\"Runnable2\"); MyRunnable mr3 = new MyRunnable(\"Runnable3\"); Thread t1 = new Thread(mr1); Thread t2 = new Thread(mr2); Thread t3 = new Thread(mr3); t1.start(); t2.start(); t3.start(); &#125; sleep() 和 wait()的区别 基本的差别 sleep是Thread的方法，wait是Object类中定义的方法 sleep()方法在任何地方都可以使用 ，wait()方法只能在synchronized方法或synchronized块中使用 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。 最本质的区别Thread.sleep不会释放锁，只会让出CPU，Object.wait不仅让出CPU,也释放锁已经占有的同步资源锁，所以wait在synchronized中使用才有意义 例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class WaitSleepDemo &#123; public static void main(String[] args) &#123; final Object lock = new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"thread A is waiting to get lock\"); synchronized (lock)&#123; try &#123; System.out.println(\"thread A get lock\"); Thread.sleep(20); System.out.println(\"thread A do wait method\"); lock.wait(); System.out.println(\"thread A is done\"); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); try&#123; Thread.sleep(10); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"thread B is waiting to get lock\"); synchronized (lock)&#123; try &#123; System.out.println(\"thread B get lock\"); System.out.println(\"thread B is sleeping 10 ms\"); Thread.sleep(10); Thread.sleep(2000); System.out.println(\"thread B is done\"); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125; &#125; notify和notifyall的区别 锁池 entryList ： 假设线程A已经拥有了某个对象（不是类）的锁，而其它线程B、C想要调用这个对象的synchronized方法（或者块），由于B、C线程在进入对象的synchronized方法（或者块）之前必须先获得该对象锁的拥有权，而该对象的锁目前被线程A锁占有，此时B、C线程就会被阻塞，进入一个地方去等待锁的释放，这个地方便是该对象的锁池 等待池 WaitList： 假设线程A调用了某个对象的wait方法，线程A就会释放该对象的锁，同时线程A就进入到了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的锁 notifyAll 会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会notify 只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 yield函数 当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意让出CPU使用的暗示，但是线程调度器可能会忽略这个暗示 关于 Thread.yield() 提示线程调度器表示当前线程可以让出 CPU， 但是调度器可能选择忽略 yield 不会改变当前同步锁的状态 1234567891011121314151617public static void main(String[] args) &#123; Runnable yieldTask = new Runnable() &#123; @Override public void run() &#123; for (int i = 1; i &lt;= 10; i++) &#123; System.out.println(Thread.currentThread().getName() + i); if (i == 5) &#123; Thread.yield(); &#125; &#125; &#125; &#125;; Thread t1 = new Thread(yieldTask, \"A\"); Thread t2 = new Thread(yieldTask, \"B\"); t1.start(); t2.start();&#125; 如何实现处理线程的返回值 如何给run方法传参 构造函数传参 成员变量传参 回调函数传参 如何实现处理线程的返回值 主线程等待法：让主线程循环等待，直到目标子线程返回值 使用Thread类的join()阻塞当前线程以等待子线程处理完毕 通过Callable接口实现：通过FutureTask Or 线程池获取 实现Callable接口和Future创建线程 首先创建Callable接口的实现类CallableThread，实现call()方法，并且有返回值。Callable接口是一个带泛型的接口，泛型的类型就是线程返回值的类型。实现Callable接口中的call()方法，方法的返回类型与泛型的类型相同。Callable不能直接获取返回值，需要用FutureTask在外部封装一下再获取返回值代码实现：FutureTask获取返回值 123456789101112131415161718192021222324public class MyCallable implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception&#123; String value=\"test\"; System.out.println(\"Ready to work\"); Thread.currentThread().sleep(5000); System.out.println(\"task done\"); return value; &#125;&#125;public class FutureTaskDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; FutureTask&lt;String&gt; task = new FutureTask&lt;String&gt;(new MyCallable()); new Thread(task).start(); if(!task.isDone())&#123; System.out.println(\"task has not finished, please wait!\"); &#125; System.out.println(\"task return: \" + task.get()); &#125;&#125; 代码实现：通过线程池获取返回值 1234567891011121314151617//定义一个线程池ExecutorService newCacheThreadPool = Executors.newCachedThreadPool();//提交到线程池Future&lt;String&gt; feture = newCacheThreadPool.submit(new MyCallable());if(feture.isDone())&#123; System.out.println(\"task has not finished,wait\");&#125;try &#123; System.out.println( feture.get() );&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;finally &#123; //关闭线程池 newCacheThreadPool.shutdown();&#125; 使用线程池的好处：提交多个实现Callable的类，让线程池并发的执行结果，方便对实现Callable的类做统一管理 interrupt 函数 已经被抛弃的方法 stop（） suspend（）和resunme（）原因：暴力中断线程，如A调用B的stop去终止B线程，由于A不知道B的运行状态，突然停止将可能导致B的一些清理工作无法完成，stop（）方法执行后会马上释放锁，这可能引发数据不同步的问题 目前使用的方法 调用interrupt（），通知线程应该中断了1）如果线程处于阻塞状态，那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常2）如果线程处于正常活动状态，那么会将该线程的中断标记设置为true。被设置中断标志的线程将继续正常运行，不受影响 需要被调用的线程配合中断1）在正常运行任务时，进程检查本线程的中断标志位，如果被设置了中断标志就自行停止线程2）如果线程处于正常活动状态，那么会将该线程的终端标记设置为true。被设置中断标志的线程将继续正常运行，不受影响","categories":[{"name":"Java多线程与并发","slug":"Java多线程与并发","permalink":"http://yoursite.com/categories/Java多线程与并发/"}],"tags":[{"name":"进程和线程","slug":"进程和线程","permalink":"http://yoursite.com/tags/进程和线程/"},{"name":"start和run","slug":"start和run","permalink":"http://yoursite.com/tags/start和run/"},{"name":"Thread和Runnable","slug":"Thread和Runnable","permalink":"http://yoursite.com/tags/Thread和Runnable/"},{"name":"notify","slug":"notify","permalink":"http://yoursite.com/tags/notify/"},{"name":"yield","slug":"yield","permalink":"http://yoursite.com/tags/yield/"},{"name":"interrupt","slug":"interrupt","permalink":"http://yoursite.com/tags/interrupt/"}]},{"title":"Java垃圾回收之垃圾回收器","slug":"Java垃圾回收之垃圾回收器","date":"2019-11-02T15:25:09.000Z","updated":"2019-12-30T13:10:50.477Z","comments":true,"path":"2019/11/02/Java垃圾回收之垃圾回收器/","link":"","permalink":"http://yoursite.com/2019/11/02/Java垃圾回收之垃圾回收器/","excerpt":"","text":"如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现 前置概念 Stop-the-World： JVM由于要执行GC而停止了应用程序的执行 任何一种GC算法中都会发生 多数GC优化通过减少Stop-the-world发生的时间来提高程序性能 Safepoint 垃圾收集器的安全点 分析过程中对象引用关系不会发生变化的点 产生Safepoint的地方：方法调用；循环跳转；异常跳转 安全点数量得适中 常见的垃圾收集器 JVM的运行模式 Server:启动较慢,采用的重量级虚拟机，对程序采用了更多的优化；启动稳定后运行速度比Client快 Client:启动较快 垃圾搜集器之间的联系 年轻代垃圾收集器Serial收集器（-XX:UseSerialGC,复制算法） 单线程收集，进行垃圾收集时必须暂停所有工作线程 简单高效，Client模式下默认的年轻代收集器 尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间短适合与用户交互的程序，良好的响应速度能提升用户体验 ParNew收集器（-XX:+UseParNewGC,复制算法） 多线程收集，其余行为、特点和Serial收集器一样 单核执行效率不如Serial,在多核下执行才有优势；默认开启的收集线程数和CPU数量相同 它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 Parallel Scavenge收集器（-XX:+UseParallelGC,复制算法） 比起管住用户线程停顿时间，更关注系统的吞吐量，高吞吐量可以高效的利用cpu时间尽可能快完成任务，适合在后台运算而不需要太多交互任务的情况 在多核模式下执行才有优势，Server模式下默认的年轻代收集器 配合自适应调节策略 -XX:+UseAdaptiveSizePolicy 把内存管理的调优任务交给虚拟机完成 吞吐量 = 运行用户代码时间/(运行用户代码时间+垃圾收集时间) 老年代垃圾收集器Serial Old收集器（-XX:UseSerialOldGC,标记-整理算法） 单线程收集，进行垃圾收集时必须暂停所有工作线程 简单高效，Client模式下默认的老年代收集器 Parllel Old收集器（-XX:+UseParallelOldGC,标记-整理算法） 多线程收集，吞吐量优先 进行垃圾收集时必须暂停所有工作线程 单核执行效率不如Serial,在多核下执行才有优势 CMS收集器（-XX:+UseConcMarkSweepGC,标记-清除算法）CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 初始标记：stop-the-world 并发标记： 同时开启 GC 和用户线程 并发追溯标记，程序不会停顿 并发预清理：查找执行并发标记阶段从年轻代晋升到老年代的对象 重新标记：暂停虚拟机，扫描CMS堆中剩余对象 并发清理：清理垃圾对象，程序不会停顿 并发重置：重置CMS收集器的数据结构 由于是标记清除算法，会带来内存空间碎片化的问题 G1收集器（-XX:+UseG1GC,复制+标记-整理算法）G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征. Garbage Firlst收集器的特点： 并发和并行，使用多个cup缩短stop-the-world的时间，与用户线程并发执行 分代收集，虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿 Garbage First收集器： 将整个堆内存划分为多个大小相等的Region 年轻代和老年代不再物理隔离 问题整理：Object的finalize()方法的作用是否与C++的解析函数作用相同 与C++的析构函数不同，析构函数调用确定，而它的是不确定的 将未被引用的对象放置于F-Queue队列 方法执行随时可能被终止 给予对象最后一次重生机会 一个例子： 12345678910111213141516171819202122public class Finalization &#123; public static Finalization finalization; @Override protected void finalize()&#123; System.out.println(&quot;Finalized&quot;); finalization = this; &#125; public static void main(String[] args) &#123; Finalization f = new Finalization(); System.out.println(&quot;First print: &quot; + f); f = null; System.gc(); try &#123;// 休息一段时间，让上面的垃圾回收线程执行完成 Thread.currentThread().sleep(1000); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; System.out.println(&quot;Second print: &quot; + f); System.out.println(f.finalization); &#125;&#125; Java中的强引用，软引用，弱引用，虚引用有什么用？ 强引用（Strong Reference） 最普遍的引用：Object obj = new Object() 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象 通过将对象设置为null来弱化引用，使其被回收 软引用（Soft Reference）: 对象处在有用但非必须的状态 ; 只有当内存空间不足时，GC会回收该引用的内存 ; 可以用来实现高速缓存 一个例子： 12Stirng str = new String(&quot;abc&quot;);//强引用SoftRefence&lt;String&gt;softRef = new SoftRefence&lt;String&gt;(str);//弱引用 弱引用（Weak Reference） 非必须的对象，比软引用更弱一些 GC时会被回收 被回收的概率也不大，因为GC线程优先级比较低 适用于引用偶尔被使用且不影响垃圾收集的对象 虚引用（Phantom Reference） 不会决定对象的生命周期 任何时候都可能被垃圾收集器回收 跟踪对象被垃圾收集器回收的活动，起哨兵作用 必须和引用队列ReferenceQueue联合使用 123String str = new String(&quot;abc&quot;);ReferenceQuence queue = new ReferenceQuence();PhantomReference ref = new PhantomReference(str,queue) 引用队列（ReferenceQueue） 无实际存储结构，存储逻辑依赖于内部节点之间的关系来表达 存储关联的企鹅杯GC的软引用，弱引用以及虚引用","categories":[{"name":"GC相关","slug":"GC相关","permalink":"http://yoursite.com/categories/GC相关/"}],"tags":[{"name":"新生代垃圾收集器","slug":"新生代垃圾收集器","permalink":"http://yoursite.com/tags/新生代垃圾收集器/"},{"name":"老年代垃圾收集器","slug":"老年代垃圾收集器","permalink":"http://yoursite.com/tags/老年代垃圾收集器/"}]},{"title":"Java垃圾回收之回收算法","slug":"Java垃圾回收之回收算法","date":"2019-11-02T07:57:27.000Z","updated":"2019-12-30T11:38:59.818Z","comments":true,"path":"2019/11/02/Java垃圾回收之回收算法/","link":"","permalink":"http://yoursite.com/2019/11/02/Java垃圾回收之回收算法/","excerpt":"","text":"复制算法（Copying） 分为对象面和空闲面 对象在对象面上创建 对象面上的内存不足时，存活的对象被从对象面复制到空闲面 将对象面所有对象内存清除 标记-清除算法（Mark and Sweep） 标记：从根集合进行扫描，对存活的对象进行标记 清除：对堆内存从头到尾进行线性遍历，回收不可达对象内存 缺点：由于标记清除不需要进行对象的移动，并且仅对不存活的对象进行处理。会产生大量不连续的内存碎片。 优点 解决碎片化问题 顺序分配内存，简单高效 适用于对象存活率低的场景（年轻代） 标记-整理算法（Compacting） 标记：从根集合进行扫描，对存活的对象进行标记 清除：移动所有存活的对象，切按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收 优点 避免内存的不连续行 不用设置两块内存互换 适用于对象存活率高的场景（老年代） 分代收集算法（Generational Collector） 垃圾回收算法的组合拳 按照对象生命周期的不同划分区域以采取不同的垃圾回收算法 目的：提高JVM的回收效率 GC的分类 Minor GC:发生在年轻中的垃圾收集动作，采用复制算法；年轻代是所有Java对象出生的地方 Full GC:与老年代相关 年轻代：尽可能快速地收集掉那些生命周期短的对象 Eden区（刚创建的对象） 两个Survivor区（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to）新生代占用1/3堆空间，其中Eden 8/10, from1/10 ,to 1/10老年代 2/3堆空间 年轻代垃圾回收的过程： 对象创建在Eden区，当Eden区满了之后会触发一次Minor GC，把标记为存活的对象复制到Survivor0中，清理所有使用过的Eden区域，存活对象年龄+1； 当Eden区再次被填满，触发回Minor GC，会把Eden区和survivor0区中标记为存活的对象都复制到survivor1中，Eden和Survivor0区域将会被清空，周而复始 当对象达到一定年龄（默认15岁），会成为老年代；对于一些较大的对象，年轻代无法装下，会直接进入老年代 对象如何晋升到老年代？ 经历一定Minor次数依然存活的对象 Survivor区中或Eden区中存放不下的对象，对象优先在Eden区中分配 新生成的大对象 比如：字符串、数组（-XX:+PretenuerSizeThreshold） 动态对象年龄判定 为了更好的适应不同程序的内存情况，虚拟机不是永远要求对象年龄必须达到了某个值才能进入老年代，如果 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需达到要求的年龄。 常用的调优参数 XX:SurvivorRatio:Eden和Survivor的比值，默认8：1 XX:NewRatio:老年代和年轻代大小的比例 XX:MaxTenuringThreshold:对象从年轻代晋升到老年代经过GC次数的最大阈值 老年代:存放生命周期较长的对象 标记-清理算法 标记-整理算法 当触发老年代的垃圾回收的时候，会伴随着新生代堆内存的回收，即对整个堆的垃圾回收。 Full GC和Major GC Full GC比Minor GC慢，但执行效率低 触发Full GC的条件 老年代空间不足 永久代空间不足（JDK8以前的版本） CMS GC时出现promotion failed,concurrent mode failure Minor GC晋升到老年代的平均大小大于老年代的剩余空间 调用System.gc() 使用RMI来进行RPC或管的JDK应用，每小时执行1次Full GC","categories":[{"name":"GC相关","slug":"GC相关","permalink":"http://yoursite.com/categories/GC相关/"}],"tags":[{"name":"回收算法","slug":"回收算法","permalink":"http://yoursite.com/tags/回收算法/"}]},{"title":"Java垃圾回收之标记算法","slug":"Java垃圾回收之标记算法","date":"2019-11-02T06:51:55.000Z","updated":"2019-12-30T11:32:51.792Z","comments":true,"path":"2019/11/02/Java垃圾回收之标记算法/","link":"","permalink":"http://yoursite.com/2019/11/02/Java垃圾回收之标记算法/","excerpt":"","text":"堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 引用计数算法：判断对象的引用数量通过判断对象的引用数量来决定对象是否可以被回收,每个对象实例都有一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1, 任何引用计数为0的对象实例可以被当做垃圾收集 优点：执行效率高，程序执行受影响较小缺点：但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。 123456789101112public class ReferenceCountingGc &#123; Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; &#125;&#125; 可达性分析算法这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 比如方法区中的类静态属性引用的对象，是可以作为GC Root的， 123public class House &#123; public static Area area = new Area(new Street());&#125; 而Area里面有一个复合对象Street 123456public class Area &#123; private Street street; public Area(Street street)&#123; this.street = street; &#125;;&#125; 那么area 这个静态变量实例就是GC Roots，而Street就类似于Object1 2这些，所以通过Area能找到Street那么它就是可达的。 可作为GC Root的对象 虚拟机栈中引用的对象（栈帧中的本地变量表） 方法区中的常量引用的对象 方法区中的类静态属性引用的对象 本地方法栈中JNI(Natie方法)的引用对象 活跃线程的引用对象","categories":[{"name":"GC相关","slug":"GC相关","permalink":"http://yoursite.com/categories/GC相关/"}],"tags":[{"name":"标记算法","slug":"标记算法","permalink":"http://yoursite.com/tags/标记算法/"}]},{"title":"Java的内存模型常见问题","slug":"Java的内存模型常见问题","date":"2019-10-30T14:57:48.000Z","updated":"2019-11-02T04:08:10.939Z","comments":true,"path":"2019/10/30/Java的内存模型常见问题/","link":"","permalink":"http://yoursite.com/2019/10/30/Java的内存模型常见问题/","excerpt":"","text":"JVM三大性能调优参数-Xms -Xmx -Xss的含义 -Xss：规定的每个虚拟机栈（堆栈）的大小。一般情况下，256K足够。此配置将会影响此进程中并发线程数的大小 -Xms：初始java堆的大小，即该进程刚创建出来的时候java堆的大小。 -Xmx：一旦对象容量超过-Xms大小，则将java堆大小扩容至改参数。为防止heap扩容导致内存抖动，影响程序运行稳定性，一般设置成与Xms一样大小 Java内存模型中堆和栈的区别内存分配策略静态存储：编译时确定每个数据目标在运行时的存储空间需求栈式存储：数据区需求在编译时未知，运行时模块入口前确定堆时存储：编译时或运行时模块入口都无法确定，动态分配 Java内存模型中堆和栈的区别联系：引用对象、数组时，栈里定义变量保存堆中目标的首地址管理方式：栈自动释放，堆需要GC空间大小：栈比堆小碎片相关：栈产生的碎片远小于堆分配方式：栈支持静态和动态分配，而堆仅支持动态分配效率：栈的效率比堆高 元空间、堆、线程独占部分间的联系-内存角度 不同JDK版本之间的intern()方法的区别——JDK6 VS JDK6+12Stirng s = new String (&quot;a&quot;);s.intern(); JDK6: 当调用intern 方法时，如果字符串常量池先前已创建出该字符串对象，则返回池中的该字符串的引用。否则，将此字符串对象添加到字符串常量池中，并且返回该字符串对象的引用JDK6+: 当调用intern 方法时，如果字符串常量池先前已创建出该字符串对象，则返回池中的该字符串的引用。否则，如果该字符串对象已经存在于java堆中，则将堆中对此对象的引用添加到字符串常量池中，并且返回该引用；如果堆中不存在，则在池中创建该字符串并返回其引用","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[]},{"title":"JVM内存模型","slug":"JVM内存模型","date":"2019-10-30T06:01:08.000Z","updated":"2020-02-14T09:16:44.834Z","comments":true,"path":"2019/10/30/JVM内存模型/","link":"","permalink":"http://yoursite.com/2019/10/30/JVM内存模型/","excerpt":"","text":"Java 内存区域详解 如果没有特殊说明，都是针对的是 HotSpot 虚拟机。 常见面试题基本问题 介绍下 Java 内存区域（运行时数据区） Java 对象的创建过程（五步，建议能默写出来并且要知道每一步虚拟机做了什么） 对象的访问定位的两种方式（句柄和直接指针两种方式） 一 运行时数据区域(JVM内存模型) Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同， 内存简介计算机所有程序都是内存中运行的。在程序执行过程中，需要不断的将内存的逻辑地址和物理地址相互映射，找到相关的指令以及数据去执行。作为操作系统进程，java运行时受限于操作系统架构提供的可寻址空间。操作系统架构的可寻址空间由系统位数决定。 32位处理器：2^32的可寻址范围 64位处理器：2^64的可寻址范围 地址空间的划分 内核空间 用户空间 线程私有：程序计数器、虚拟机栈、本地方法栈 线程共享：MetaSpace、Java堆、直接内存 (非运行时数据区的一部分) 程序计数器（Program Counter Register）程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。 另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 从上面的介绍中我们知道程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 Java虚拟机栈（Stack）与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的 每个方法执行时都会创建一个栈，包含多个栈帧。Java 虚拟机栈用来存储栈帧，栈帧持有:局部变量表、操作数栈、动态链接、方法出口信息，方法调用结束时栈帧才会被销毁 局部变量表：包含方法执行过程中的所有变量 操作数栈：入栈、出栈、复制、交换、产生消费变量 Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。 StackOverflowError: 由于我们每个线程虚拟机栈深度是固定的 ;由于递归层数过多，当线程执行一个方法时就随之创建一个对应的栈帧，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。 例如： 12345678910public void stackLeakByThread()&#123; while(true)&#123; new Thread()&#123; public void run()&#123; while(true)&#123; &#125; &#125; &#125;.start() &#125;&#125; 扩展：那么方法/函数如何调用？ Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。 本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 方法区元空间（MetaSpace）和永久代都是用来存储class的相关信息包括class对象的method和field等 ; JDK 1.8 的时候 使用元空间（使用本地内存）替代永久代（使用JVM内存）,原先位于方法区的字符串常量池被移到堆中;元空间和永久代均是方法区的实现，方法区只是JVM的规范 元空间（MetaSpace）与永久代（PermGen）的区别 元空间使用本地内存，而永久代使用的是JVM的内存 MetaSpace相比PermGen的优势 字符串常量池存在永久代中，容易出现性能问题和内存溢出 类和方法的信息大小难以确定，给永久代的大小指定带来困难 永久代会为GC带来不必要的复杂性 方便HotSpot与其它JVM如Jrockit的集成,永久代是HotSpot VM特有的，别的VM没有永久代 Java堆（Heap）Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 永久代(Permanent Generation) 上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如： OutOfMemoryError: GC Overhead Limit Exceeded ： 当JVM花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发java.lang.OutOfMemoryError: Java heap space 错误。(和本机物理内存无关，和你配置的对内存大小有关！) HotSpot 虚拟机对象探秘 HotSpot 虚拟机在 Java 堆中对象分配、布局和访问的全过程。 对象的创建Step1:类加载检查虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 Step2:分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 Step3:初始化零值内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 Step4:执行 init 方法在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt; init &gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt; init &gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充。 Hotspot 虚拟机的对象头包括两部分信息: 用于存储对象自身的自身运行时数据（Mark Work：默认存储对象的hashCode,分代年龄，锁类型，锁标志位等信息 非固定的数据结构，以便效率）， 另一部分是类型指针，Class Metadata Address：类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的数据 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[{"name":"线程独占","slug":"线程独占","permalink":"http://yoursite.com/tags/线程独占/"},{"name":"线程共享","slug":"线程共享","permalink":"http://yoursite.com/tags/线程共享/"}]},{"title":"谈谈ClassLoader","slug":"谈谈ClassLoader","date":"2019-10-26T03:40:31.000Z","updated":"2019-12-08T10:03:18.657Z","comments":true,"path":"2019/10/26/谈谈ClassLoader/","link":"","permalink":"http://yoursite.com/2019/10/26/谈谈ClassLoader/","excerpt":"","text":"类从编译到执行的过程 编译器将Robot.java源文件编译为Robot.class字节码文件 ClassLoader将字节码转化为JVM中的 Class&lt; Robot &gt;对象 JVM利用Class&lt; Robot &gt;对象实例化为Robot对象 谈谈ClassLoaderClassLoader主要工作在Class装载的加载阶段，主要作用是从系统外部获取Class二进制数据流。它是Java的核心组件，所有的Class都是由ClassLoader进行加载的，负责通过将Class文件里的二进制数据流装载进系统，然后交给Java虚拟机进行连接，初始化等操作。 ClassLoader 的种类 BootStrapClassLoader：C++编写，加载核心库 java.* ExtClassLoader：Java编写，加载扩展库javaa.* AppClassLoader：Java编写，加载程序所在目录 自定义ClassLoader：Java编写，定制化加载 可能不在系统classpath范围内 ClassLoader双亲委派机制 自底而上检查类是否已经加载Custom ClassLoader–App ClassLoader–Extension ClassLoader–BootStrap ClassLoader 自上而下尝试加载类BootStrap:加载 jre\\lib\\rt.jar 或者 Xbootclasspath选项指定的jar包Extension:加载 jre\\lib\\ext*.jar 或者 Djava.ext.dirs指定目录下的jar包App: 加载ClassPath 或者 Djava.class.path所指定的目录下的类和jar包 为什么使用双亲委派机制 避免多份同样字节码的加载 类的装载过程 加载：通过ClassLoader加载class文件字节码生成Class对象 链接： 校验：检查加载的class的正确性和安全性 准备：为类变量分配存储空间并设置类变量初始值 解析：JVM将常量池内的符号引用转换为直接引用 初始化：执行类变量赋值和静态代码块 loadClass和forName的区别Class.forName是类加载到初始化的步骤Classloader.loadClass是刚执行完加载class Class.forName已完成初始化，那为什么还要用LoadClass呢？存在即合理；LoadClass在springIOC中资源加载器获取要读入的资源的时候，即读取一些bean的配置文件的时候，如果是以classPath方式来加载的话 就需要使用Classload.loadClass来加载，之所以这样做是和springIOC的lazy-loading（懒加载）有关，springIOC为了加快初始化速度因此大量使用延迟加载技术而使用ClassLoad不需要执行类中的初始化代码（static）步骤和链接步骤，这样子做可以加快加载速度 ，把类的初始化工作留到实际使用到这个类的时候才去做.","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[{"name":"ClassLoader","slug":"ClassLoader","permalink":"http://yoursite.com/tags/ClassLoader/"},{"name":"类的装载","slug":"类的装载","permalink":"http://yoursite.com/tags/类的装载/"}]},{"title":"JVM如何加载class文件","slug":"JVM如何加载class文件","date":"2019-10-26T01:53:49.000Z","updated":"2019-12-30T04:58:18.111Z","comments":true,"path":"2019/10/26/JVM如何加载class文件/","link":"","permalink":"http://yoursite.com/2019/10/26/JVM如何加载class文件/","excerpt":"","text":"Java虚拟机Java虚拟机：抽象化的计算机，通过在实际的计算机上个仿真模拟计算机功能来实现的，有自己完善的硬件架构：处理器，堆栈，寄存器等，还具有相应的指令系统，jvm 屏蔽了与具体操作系统平台相关的信息，使得java程序只需要生成在java虚拟机上运行的字节码，就可以在不同平台上不加修改的运行。其中最重要的两点：JVM内存结构模型，GC JVM是内存中的虚拟机，JVM的存储就是内存，所有写的 类，常量，变量，方法都在内存中这决定着程序的健壮和高效 Class Loader ： 依据特定格式，加载class文件到内存 Runtime Data Area ：JVM内存空间结构模型 Native Interface: 融合不同开发语言的原生库为Java所用 Execution Engine ：对命令进行解析 JVM结构： Class Loader, Runtime Data Area, Execution Engine, Native Interface Java反射机制JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为Java语言的反射机制。 写一个反射的例子Robot.java 1234567891011package com.interview.javabasic.reflectpublic class Robot&#123; private String name; public void sayHi(String helloSentence)&#123; System.out.println(helloSentence + &quot;&quot; + name) &#125; private String throwHello(String tag)&#123; return &quot;Hello&quot; + tag; &#125;&#125; ReflectSample.java 1234567891011121314151617181920public static void main(String[] args)&#123; //先获取Robot类，需要全路径 Class rc = Class.forNam(&quot;com.interview.javabasic.reflect.Robot&quot;) //创建实例,需要强转，newInstance返回的是泛型 Robot r = (Robot)rc.newInstance(); System.out.println(&quot;Class name is &quot; + rc.getName()); //通过反射获取私有方法,throwHello接收一个String类型的参数 Method getHello = rc.getDeclaredMethod( name: &quot;throwHello&quot;,String.class)； getHello.setAccessible(true); //需要传入对象实例，和方法参数 Object str = getHello.invoke(r,&quot;Bob&quot;); System.out.println(&quot;getHello result is &quot; + str); //第二种获取方法获取方法 Method sayHi = rc.getMethod( name: &quot;sayHi&quot;,String.class)； sayHi.invoke(r,&quot;Welcome&quot;); //获取私有类型的Filed Filed name = rc.getDeclaredField(name: &quot;name&quot;); name.setAccessible(true); name.set(r,&quot;Alice&quot;)&#125; Metohd:newInstance()方法返回的是泛型。getDeclaredMethod可以获得该类所有的方法，除去继承和实现了接口的方法。如果是私有的方法，必须使用setAccessible(true)方法。getMethod可以获得该类所有的公有方法，还有所继承的以及实现了接口的方法。 Field:getDeclaredField获取属性如果是私有属性也要设置setAccessible(true)","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[{"name":"JVM内存结构模型","slug":"JVM内存结构模型","permalink":"http://yoursite.com/tags/JVM内存结构模型/"},{"name":"反射","slug":"反射","permalink":"http://yoursite.com/tags/反射/"}]},{"title":"谈谈我对Java的理解","slug":"谈谈我对Java的理解","date":"2019-10-25T08:23:12.000Z","updated":"2019-12-08T08:17:01.318Z","comments":true,"path":"2019/10/25/谈谈我对Java的理解/","link":"","permalink":"http://yoursite.com/2019/10/25/谈谈我对Java的理解/","excerpt":"","text":"谈谈我对Java的理解从以下几个点进行扩展 平台无关性：一次编译到处运行GC垃圾回收：不用手动释放内存语言特性：泛型、lamda、反射面向对象：封装、继承、多态类库：自带的集合和并发库异常处理 Compile Once,Run Anywhere如何实现（如何实现平台无关的）？编译时：javac (查看字节码 javac -p)运行时：java.java文件首先经过javac编译生成字节码。将字节码保存在.class文件中。.class文件是跨平台的基础。再由不同平台的JVM进行解析，java语言在不同的平台上运行时不需要进行重新编译，java虚拟机在执行字节码的时候，把字节码转换成具体平台上的机器指令。 为什么jvm不直接执行源码，而是将字节码解析成机器码才去执行 每次执行都需要各种检查（语法，句法，语义的检查，每次执行的时候，这些语义分析结果不会被保留下来。因此引入字节码，在每次执行程序是不需要各种校验和补全的） 兼容性，可以将别的语言（groovy,scala）解析成字节码","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/categories/JVM/"}],"tags":[{"name":"Java特性","slug":"Java特性","permalink":"http://yoursite.com/tags/Java特性/"},{"name":"平台无关性","slug":"平台无关性","permalink":"http://yoursite.com/tags/平台无关性/"}]},{"title":"Linux体系结构","slug":"Linux体系结构","date":"2019-10-21T14:29:34.000Z","updated":"2020-03-15T12:06:49.009Z","comments":true,"path":"2019/10/21/Linux体系结构/","link":"","permalink":"http://yoursite.com/2019/10/21/Linux体系结构/","excerpt":"","text":"Linux 体系结构 体系结构主要分为用户态（用户上层活动）和内核态 内核：本质是一段管理计算机硬件设备的程序 系统调用：内核的访问接口，是一种不能再简化的操作 公用函数库：系统调用的组合拳 Shell：命令解释器，可编程 查看指定端口是否被占用1netstat -anp |grep 3306 -a，显示所有 -n，不用别名显示，只用数字显示 -p，显示进程号和进程名 Linux 使用 top 命令查看系统的运行情况 使用 top 命令查看系统的运行情况 远程登录终端利用ssh登录远程服务器 安装ssh： 1yum install ssh 启动ssh： 1service sshd start 登录远程服务器： 123ssh -p 50022 my@127.0.0.1输入密码：my@127.0.0.1: -p 后面是端口 my 是服务器用户名 127.0.0.1 是服务器 ip 回车输入密码即可登录 如何查找特定的文件find1语法：find path 【options】 params 作用：在指定目录下查找文件 常用的方式~表示当前用户的目录 1234 find ~ -name &quot;target1.java&quot; :查找精确文件 find ~ -name &quot;target*&quot; :查找精确文件 find ~ -iname &quot;target*&quot; :不区分文件名大小写去查找文件 man find : 更多关于find指令的使用说明 检索文件内容1语法：grep 【options】 pattern file 全称：Global Regular Expression Print作用：在指定目录下查找文件 12例如：查找包含内容&quot;moo&quot; 以target开头的文件grep &quot;moo&quot; target* 管道操作符|可将指令连接起来，前一个指令的输出作为后一个指令的输入 12例如：查找当前用户下以target开头的文件find ~ | grep &quot;target*&quot; 常用的方式123456781.在内容（文件）里面查找包含某字段的文件，并展示出对应行内容grep &apos;partial\\[true\\]&apos; bac-plat-al-data.info.log 2.-o 筛选出符合正则表达式的内容grep -o &apos;engine\\[[0-9a-z]*\\]&apos; 3.-v 过滤掉包含相关字符串的内容grep -v &apos;grep&apos; 对文件内容做统计场景：我想筛选出 partial为true的引擎，并统计日志里出现的次数。当我们发现某个检索引擎的partial为true超过一定次数后，说明该引擎需要从集群中摘掉进行修复； awk1语法：awk [options] &apos;cmd&apos; file 一次读取一行文本，按输入分隔符进行切片，切成多个组成部分 将切片直接保存在内建的变量中，$1,$2,..($0表示行的全部) 支持对单个切片的判断，支持循环判断，默认分隔符为空格 常用的方式12345678打印出第一列和第四列的内容：awk &apos;&#123;print $1,$4&#125;&apos; 文件名筛选出列指定字符的行：awk &apos;$1==&quot;tcp&quot; &amp;&amp; $2==1&#123;print $0&#125;&apos; 文件名打印出表头：awk &apos;($1==&quot;tcp&quot; &amp;&amp; $2==1) || NR==1 &#123;print $0&#125;&apos; 文件名以指定分隔符分割内容：awk -F &quot;,&quot; &apos;&#123;print $2&#125;&apos; 文件名 12Linux 命令 awk 统计：awk &apos;&#123;enginearr[$1]++&#125;END&#123;for (i in enginearr) print i &quot;\\t&quot; enginearr[i]&#125;&apos; enginearr ：自定义的数组，如果第一列$1出现重复就自增1END ：扫描统计结束{for(i in enginearr)}：循环自定义的数组，定义变量 iprint i : 打印 i“\\t” 拼接回车符enginearr[i] : 指定自定义数组 批量替换文本内容sed1语法：sed [option] &apos;sed command&apos; filenae 全名stream editor,流编辑器适合用于对文本的行内容进行处理 常用的方式12345678910111213141.将文件中以Str开头的字符串替换成 String：sed -i &apos;s/^Str/String/&apos; replace.txt2.将末尾的点号转为分号：sed -i &apos;s/\\.$/\\;/&apos; replace.txt3.将所有的&quot;Jack&quot;替换成&quot;me&quot;sed -i &apos;s/Jack/me/g&apos; replace.txt4.删除空行命令sed -i &apos;/^ *$/d&apos; replace.txt5.删除包含特定字符的行：sed -i &apos;/Integer/d&apos; replace.txt 特别指出： 指令中加入 -i 表示修改保存到文件中 替换语法后加入 /g 表示将文件中所有符合条件的内容全部替换，否则只替换一行中第一次匹配到的字符 总结：经常用到的Shell命令 find grep 管道操作符| awk sed","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[]},{"title":"Redis集群","slug":"Redis集群","date":"2019-10-21T14:27:28.000Z","updated":"2019-10-21T14:27:28.170Z","comments":true,"path":"2019/10/21/Redis集群/","link":"","permalink":"http://yoursite.com/2019/10/21/Redis集群/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Pipeline及主从同步","slug":"Pipeline及主从同步","date":"2019-10-21T14:27:10.000Z","updated":"2019-10-21T14:27:10.138Z","comments":true,"path":"2019/10/21/Pipeline及主从同步/","link":"","permalink":"http://yoursite.com/2019/10/21/Pipeline及主从同步/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Redis持久化方式","slug":"Redis持久化方式","date":"2019-10-21T14:23:15.000Z","updated":"2019-10-21T14:25:32.283Z","comments":true,"path":"2019/10/21/Redis持久化方式/","link":"","permalink":"http://yoursite.com/2019/10/21/Redis持久化方式/","excerpt":"","text":"RDB(快照)持久化：保存某个时间点的全量数据快照","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"RDB","slug":"RDB","permalink":"http://yoursite.com/tags/RDB/"},{"name":"AOF","slug":"AOF","permalink":"http://yoursite.com/tags/AOF/"}]},{"title":"如何实现异步队列","slug":"如何实现异步队列","date":"2019-10-20T06:55:22.000Z","updated":"2019-10-21T00:51:10.064Z","comments":true,"path":"2019/10/20/如何实现异步队列/","link":"","permalink":"http://yoursite.com/2019/10/20/如何实现异步队列/","excerpt":"","text":"用list作为队列rpush 作为生产者生产消息， lpop 作为消费者消费消息缺点： 没有等待 队列里有值就直接消费弥补：可以通过在应用层引入sleep机制去调用lpop重试； 如果不用 sleep机制 ，可以使用 blpop key[key..] timeout 阻塞直到队列有消息或者超时缺点：一个生产者对应一个消费者 pub/sub 主题订阅模式发送者 pub 发送消息，订阅者 sub 接受消息订阅者可以订阅任意数量的频道缺点： 消息无状态，无法保证可达","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"异步队列","slug":"异步队列","permalink":"http://yoursite.com/tags/异步队列/"}]},{"title":"如何通过Redis实现分布式锁","slug":"如何实现分布式锁","date":"2019-10-18T05:47:11.000Z","updated":"2019-10-18T06:52:06.874Z","comments":true,"path":"2019/10/18/如何实现分布式锁/","link":"","permalink":"http://yoursite.com/2019/10/18/如何实现分布式锁/","excerpt":"","text":"什么是分布式锁分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁的实现 分布式锁需要解决的问题 互斥性：任意时刻只能有一个客户端获取到锁 安全性：锁只能被持有该锁的客户端删除 死锁：获取锁的客户端因为某些原因宕机而未能释放锁，其他客户端再也无法获取到该锁而导致的死锁 容错：当部分Redis节点宕机了之后客户端仍然能够获取锁和释放锁SENTNX key value:如果key不存在，则创建并赋值 时间复杂度 O(1) 返回值：设置成功，返回1；设置失败，返回0 1234get locknx(nil)setnx locknx test(integer)1 setnx 操作是原子性的，初期被用来实现分布式锁；在执行某段代码逻辑的时候先尝试使用setnx对某个key设值，如果设置成功则证明此时没有别的线程在执行该段代码（占用该独占资源），这个时候线程就可以顺利的执行该段代码逻辑，如果设置失败则证明有别的程序或线程占用该资源。当前线程需要等待直至setnx成功 如何解决SETNX长期有效的问题EXPIRE key seconds 设置key的生存时间，当key过期时（生存时间为0），会被自动删除 缺点：原子性得不到满足 12//设置过期时间2秒钟expire locknx 2 伪代码示例： 12345678RedisService redisService = SpringUtils.getBean(RedisService.class)long status = redisService.setnx(key,&quot;1&quot;)if(status == 1)&#123; redisService.expire(key,expire); //执行独占资源逻辑 doOcuppiedWord()&#125; 潜在问题，在setnx后线程挂掉，key将会被一直占用 SET key value [EX seconds][PX milliseconds][NX|XX]ex:设置键的过期时间为单位妙px:设置键的过期时间为单位毫秒NX:只在键不存在时，才对键进行设置操作XX:只在键已经存在时，才对键进行设置操作设置成功返回ok,否则返回nil 1set locktarget 12345 ex 10 nx 大量的key同时过期的注意事项集中过期，由于清除大量的key很耗时，会出现短暂的卡顿现象解决方案：在设置key的过期时间的时候，给每个key加上随机值","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"http://yoursite.com/tags/分布式锁/"}]},{"title":"Redis简介","slug":"Redis简介","date":"2019-10-16T13:13:26.000Z","updated":"2019-11-25T03:14:40.116Z","comments":true,"path":"2019/10/16/Redis简介/","link":"","permalink":"http://yoursite.com/2019/10/16/Redis简介/","excerpt":"","text":"缓存中间件——Memcache和Redis的区别Mecache：代码层次类似Hash 支持简单数据类型 不支持数据持久化存储 不支持主从 不支持分片Redis 数据类型丰富 支持数据磁盘持久化存储 支持主从 支持分片 为什么Redis能这么快100000+QPS(QPS既query per second 每秒内查询次数) 完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高 数据结构简单，对数据操作也简单 采用单线程，单线程也能处理高并发请求，想多核也可启动多实例 使用多路I/O 复用模型，非阻塞IO redis 是跑在单线程中的，所有的操作又是按照线性顺序执行的，但是由于读写操作等待用户输入或者输出都是阻塞的，所以io操作在一般情况下往往不能直接返回，这会导致某一文件的io阻塞，进而导致整个进程无法对其他客户端提供服务而io多路复用就是为了解决这个问题的 多路I/O复用模型FD：File Descriptor,文件描述符一个打开的文件通过唯一的描述符进行引用，该描述符是打开文件的元数据到文件本身的映射 Redis采用的I/O多路复用函数：epoll/kqueue/evport/select? 因地制宜 优先选择时间复杂度为O(1)的I/O多路复用函数作为底层实现 以时间复杂度为O(n)的select作为保底 基于react设计模式监听I/O事件 Redis常用的数据类型 String:最基本的数据类型，二进制安全 Hash:String 元素组成的字典，适合用于存储对象 List:列表，按照String元素插入顺序排序 Set:String元素组成的无序集合，通过哈希表实现，不允许重复 Sorted-Set:通过分数来为集合中的成员进行从小到大的排序 用于计数的HyperLogLog ,用于支持存储地理信息位置的Geo 从海量数据查询某一固定的前缀key使用keys对线上的业务的影响KEYS pattern：查找所有符合给定模式pattern的key KEYS指令一次性返回所有匹配的key 键的数量过大会使服务器卡顿 KEYS CURSOR [MATCH pattern][COUNT count] 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次游历 不保证每次执行都返回某个给定数量的元素，支持模糊查询 一次返回的数量不可控，只能是大概率符合count参数 12//开始迭代返回以k1开始的key,希望一次返回10个scan 0 match k1* count 10","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"多路I/O复用模型","slug":"多路I-O复用模型","permalink":"http://yoursite.com/tags/多路I-O复用模型/"}]},{"title":"数据库关键语法","slug":"数据库关键语法","date":"2019-10-16T08:29:26.000Z","updated":"2019-12-29T10:50:07.156Z","comments":true,"path":"2019/10/16/数据库关键语法/","link":"","permalink":"http://yoursite.com/2019/10/16/数据库关键语法/","excerpt":"","text":"关键语法 GROUP BY HAVING 统计相关：COUNT,SUM,MAX,MIN,AVG GROUP BY 满足 SELECT子句中列名必须为分组列或者列函数 列函数对于group by子句定义的每个组各返回一个结果 HAVING 通常与GRPUP BY子句一起使用 WHERE过滤行，HAVING过滤组 出现在同一sql的顺序：WHERE&gt;GROUP BY&gt;HAVING MySQL高性能优化规范建议 MySQL高性能优化规范建议 一条SQL语句执行得很慢的原因有哪些？ 一条SQL语句执行得很慢的原因有哪些？","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"语法","slug":"语法","permalink":"http://yoursite.com/tags/语法/"}]},{"title":"InnoDB可重复读隔离级别下如何避免幻读","slug":"InnoDB可重复读隔离级别下如何避免幻读","date":"2019-10-16T07:15:06.000Z","updated":"2019-12-29T10:26:23.521Z","comments":true,"path":"2019/10/16/InnoDB可重复读隔离级别下如何避免幻读/","link":"","permalink":"http://yoursite.com/2019/10/16/InnoDB可重复读隔离级别下如何避免幻读/","excerpt":"","text":"InnoDB存储引擎的锁的算法有三种： Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 相关知识点： innodb对于行的查询使用next-key lock Next-locking keying为了解决幻读(Phantom Problem)问题 当查询的索引含有唯一属性时，将next-key lock降级为record key Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1 InnoDB可重复读隔离级别下如何避免幻读表象：快照读（非堵塞读） –伪MVCC内在：InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEAaTABLE-READ（可重读） 并不会有任何性能损失。 Gap锁Gap锁主要出现在非唯一索引和不走索引的当前读当中；如果表里面有一个非唯一索引列，索引字段排序结果的左开右闭区间，例如：1，3，5，7 的 则Gap为（-∞,1] (1,3] (2,7] (7,+∞) Gap锁的触发条件：使用主键/唯一索引的当前读: 如果where条件精确每一行，只触发行锁，不会加Gap锁 12select * from table where id in (1,3,5) id为 1,3,5的数据都在表里面存在成为全部命中 如果where条件命中部分行或全不命中，触发Gap锁where条件全不命中的情况:事务1删除id为7的列（7不存在），7周围的间隙会被锁住，则另一个事务无法id为8或6的记录 1delete * from table where id =7 where条件部分命中的条件：session1以当前读的方式查询（id为7的行不存在） 1select * from table where id in (5,7,9) in share mode; 则在session1未提交前session2不能对id (5，9] 的范围内进行插入 使用非唯一索引的当前读: 对于普通非唯一索引来说，并不是所有的gap都会上锁，只会对要修改的周边上Gap锁如上图所示，session1删除id=9未提交之前，session2无法对(6,11]的区间进行插入行数据非唯一索引的gap锁会锁住相邻索引的值 ，左开右闭 不使用索引： 触发Gap锁，并且锁定所有的Gap，相当于锁表","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[]},{"title":"锁模块之当前读和快照读","slug":"锁模块之当前读和快照读","date":"2019-10-16T06:37:29.000Z","updated":"2019-10-16T07:12:33.216Z","comments":true,"path":"2019/10/16/锁模块之当前读和快照读/","link":"","permalink":"http://yoursite.com/2019/10/16/锁模块之当前读和快照读/","excerpt":"","text":"当前读和快照读 当前读：就是加了锁的增删改查语句。读取的是记录的最新版本。读取的时候保证其他事务不能对数据进行修改。 12select ... lock in share mode ,select ... for update update,delete,insert 快照读：不加锁的非阻塞读 ，select RC、RR级别下的InnoDB的非堵塞读（快照读）如何实现 数据行里的DB_TRX_ID、DB_ROLL_PTR、DB_ROW_ID字段 DB_TRX_ID：事务ID，标识对本行数据最近一次的更新(增删改) DB_ROLL_PTR：回滚指针， 指向回滚日志undo log的一条记录，一次更新对应一条undo log记录 DB_ROW_ID：新行插入，产生一个自增ID undo日志undo log：回滚日志，存储各个老版本的数据，由undo链串起来 含insert undo log和 update undo log read view：决定当前数据看到的是哪个版本。用来做可见性判断,即我们做快照读select的时候，会针对我们查询的数据，创建出一个read view来决定当前事务能看到那个版本的数据，可能当前最新，也可能是undo log 中某个版本的数据。它遵循一个可见性算法，主要是将要修该的数据的DB_TRX_ID取出来与系统其他活跃事务id作对比，如果大于或等于就通过DB_ROLL_PTR指针取出undo log 上一层的的DB_TRX_ID直到小于这些活跃事务为止。这样保证了我们获取的数据版本是当前可见的最稳定版本。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"锁模块","slug":"锁模块","permalink":"http://yoursite.com/tags/锁模块/"},{"name":"当前读","slug":"当前读","permalink":"http://yoursite.com/tags/当前读/"},{"name":"快照读","slug":"快照读","permalink":"http://yoursite.com/tags/快照读/"}]},{"title":"锁模块之数据事务","slug":"锁模块之数据事务","date":"2019-10-12T08:25:36.000Z","updated":"2019-11-03T08:24:15.578Z","comments":true,"path":"2019/10/12/锁模块之数据事务/","link":"","permalink":"http://yoursite.com/2019/10/12/锁模块之数据事务/","excerpt":"","text":"数据库事务的四大特性ACID 原子性(Athomic) : 事务包含的全部操作要么全部执行，要么全部失败回滚 一致性(Consistency) : 事务应确保数据库的状态从一个一致状态到另一个一致状态(eg:转账问题，A和B一共2000，无论来回怎么转总和还是2000) 隔离性(Isolaton)：一个事务的执行不应该影响其它事务的执行 持久性(Durability)：一个事务的提交代表了它对数据库的修改永久保存在数据库中，当系统发生故障时确保已提交事务的更新不能丢失，确保已提交事务的更新能恢复 事务隔离级别以及各级别下的并发访问问题更新丢失（MySQL所有事务隔离级别在数据库层面上均可避免）事务A对数据进行操作时，事务B也在对同一数据更新操作并完成了提交，然后事务A遇到异常进行回滚导致事务B的更新丢失。 脏读一个事务读到另一个事务未提交的数据。 不可重复读事务A在多次读取同一数据的过程中，事务B对数据进行更新并提交，导致事务A多次读取同一数据时结果不一致。 幻读事务A读取若干行数据，事务B以插入或删除行的方式来修改事务A的结果集。 其中不可重复读与幻读比较相似，不可重复读侧重对同一数据的修改，幻读侧重插入增加或删除数据。事务隔离级别越高，对性能的影响也越大。 事务并发访问引起的问题以及如何避免 更新丢失——mysql所有事务隔离级别在数据库层面上均可避免 脏读——READ-COMMITTED事务隔离级别以上避免 不可重复读——REPEATABLE-READ事务隔离级别以上可避免 幻读——SERIALIZABLE事务隔离级别避免 事务隔离级别 更新丢失 脏读 不可重复度 幻读 未提交读 避免 发生 发生 发生 已提交读 避免 避免 发生 发生 可重复读 避免 避免 避免 发生 串行化 避免 避免 避免 避免","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"锁模块","slug":"锁模块","permalink":"http://yoursite.com/tags/锁模块/"},{"name":"数据库事务","slug":"数据库事务","permalink":"http://yoursite.com/tags/数据库事务/"},{"name":"ACID","slug":"ACID","permalink":"http://yoursite.com/tags/ACID/"}]},{"title":"锁模块MyISAM与InooDB关于锁方面的区别","slug":"锁模块MyISAM与InooDB关于锁方面的区别","date":"2019-10-11T10:42:44.000Z","updated":"2019-11-03T08:12:37.813Z","comments":true,"path":"2019/10/11/锁模块MyISAM与InooDB关于锁方面的区别/","link":"","permalink":"http://yoursite.com/2019/10/11/锁模块MyISAM与InooDB关于锁方面的区别/","excerpt":"","text":"常见问题 MyISAM与InnoDB关于锁方面的区别是什么 数据库事务的四大特性 事务隔离级别以及各级别下的并发访问问题 InnoDB可重复度隔离级别下如何变幻读 RC、RB级别下的InnoDB的非阻塞读如何实现MyISAM与InnoDB关于锁方面的区别 MyISAM默认用的是表级锁，不支持行级锁 ，MyISAM不支持事务 InnoDB默认用的是行级锁 ，也支持表级锁，InnoDB在不走索引的时候用的是表级锁，而sql用到索引的时候用的是行级锁 值得注意的是： MyISAM默认会给select语句上共享锁(读锁) InnoDB默认不会给select语句上共享锁(读锁) 上了共享锁的可以再上共享锁但是不能上排他锁 上了排他锁的不可以再上共享锁和排他锁共享锁和排斥锁的兼容性 X S X 冲突 冲突 S 冲突 兼容 1234#查看session是否为自动提交show variables like &apos;autocommit&apos;;#将session设置为自动提交set autocommit = 1; MyISAM适合的场景 频繁执行全表count语句（有个变量保存了表的行数，可直接读该变量） 对数据进行增删改的频率不高，查询非常频繁（增删改会涉及到锁表操作） 没有事务 InnoDB适合的场景 数据增删改查相当频繁（增删改的时候只是某些行被锁，大多数情况下，避免阻塞） 可靠性要求比较高，要求支持事务 数据库锁的分类 按锁的粒度划分，表级锁，行级锁，页级锁 按锁级别划分，共享锁，排他锁 按加锁方式划分，自动锁（意向锁），显式锁（手工加锁） 按操作划分，DML锁，DDL锁 按使用方式划分，乐观锁，悲观锁","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"锁模块","slug":"锁模块","permalink":"http://yoursite.com/tags/锁模块/"}]},{"title":"索引额外问题之如何调优sql","slug":"索引额外问题之如何调优sql","date":"2019-10-11T06:37:24.000Z","updated":"2019-11-03T07:53:15.459Z","comments":true,"path":"2019/10/11/索引额外问题之如何调优sql/","link":"","permalink":"http://yoursite.com/2019/10/11/索引额外问题之如何调优sql/","excerpt":"","text":"常见问题总结 如何定位并优化慢查询sql 联合索引的最左匹配原则的成因 索引建立的越多越好吗如何定位并优化慢sql大致思路 根据慢日志定位慢sql 12345SHOW VARIABLES LIKE &apos;%quer%&apos;; 查看慢查询是否打开set global slow_query_log =on; 打开慢查询:set global long_query_time=1; 设置慢查询最大时间超过一秒就记录为慢查询 SHOW STATUS LIKE &apos;%slow_queries%&apos;; 查看慢sql条数sudo vim /usr/local/mysql/data/VM_33_68_centos-slow.log; 查看被记录到慢日志里面的日志 使用explain等工具分析sql explain字段 type ： mysql找到数据行的方式index 和 all 是全表扫描 extra：有很多值 Using filesort ，Using temporary 最常的慢的， 修改sql或者尽量让sql走索引 具体走那个索引是mysql查询优化器决定， 要强制制定走某个索引 要加上 force index（primary/其他） 联合索引的最左匹配原则 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询（&gt; , &lt; , between, like ）就停止匹配，比如a=3 and b = 4 and c &gt; 5 and d =6 如果建立（a，b，c，d）顺序的索引，d是用不到索引的，如果建立（a，b，d，c）的索引则可以用到，a、b、d的顺序可以任意调整 =和in可以乱序，比如a=1 and b=2 and c=3建立（a,b,c）索引可以任意顺序，mysql查询优化器会帮你优化成索引可以识别的形式 索引是建立得越多越好吗 数据量小的表不需要建立索引，建立索引会增加额外的索引开销 数据变更需要维护索引，因此更多的索引意味着更多的维护成本 更多的索引也意味着更多的空间","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"sql调优","slug":"sql调优","permalink":"http://yoursite.com/tags/sql调优/"}]},{"title":"密集索引和稀疏索引","slug":"密集索引和稀疏索引","date":"2019-10-11T03:52:34.000Z","updated":"2019-12-29T05:50:24.687Z","comments":true,"path":"2019/10/11/密集索引和稀疏索引/","link":"","permalink":"http://yoursite.com/2019/10/11/密集索引和稀疏索引/","excerpt":"","text":"密集索引和稀疏索引的区别 索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。 在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。 InnoDB 和 MyISAM InnoDB 采用密集索引+稀疏索引,根据主键索引搜索时可以直接找到key所在的叶子节点取出数据,辅助键索引需要先找到主键的值再通过主键B+树找到数据 ,即InnoDB数据和索引是存放在一个文件里的 MyISam 全部采用稀疏索引(“非聚簇索引”),根据主键和辅助键的索引都只能找到一个地址信息,要再根据这个地址信息去另外一个文件中寻找数据,即MyISam的索引和数据是分开存放的 表结构都存储在*.frm中MyISAM索引和数据是分开存储的.MYI存储索引.MYD存储数据InnoDB索引和数据是存在一起的.ibd","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"索引","slug":"索引","permalink":"http://yoursite.com/tags/索引/"},{"name":"密集索引","slug":"密集索引","permalink":"http://yoursite.com/tags/密集索引/"},{"name":"稀疏索引","slug":"稀疏索引","permalink":"http://yoursite.com/tags/稀疏索引/"},{"name":"InnoDB","slug":"InnoDB","permalink":"http://yoursite.com/tags/InnoDB/"},{"name":"MyISAM","slug":"MyISAM","permalink":"http://yoursite.com/tags/MyISAM/"}]},{"title":"优化你的索引","slug":"优化你的索引","date":"2019-10-10T10:26:36.000Z","updated":"2019-10-11T06:39:33.192Z","comments":true,"path":"2019/10/10/优化你的索引/","link":"","permalink":"http://yoursite.com/2019/10/10/优化你的索引/","excerpt":"","text":"二叉查找树二叉树,(有明显缺陷的数据结构): 如果添加的数据一直在某一侧的时候,就会变成线性而二叉树,查询复杂度会上升,查找效率会大幅度降低 影响数据检索最根本的原因是IO,即数据库文件的读写，也就是将硬盘的数据读到内存中而我们的二叉树在检索深度每次加1后都需要读取一个节点,执行一次IO,效率很低 B-TreeB-TREEB树的定义： 根节点至少包含两个孩子 树中每个节点最多含有m个孩子（ m &gt;= 2） 除根节点和叶节点外，其他每个节点至少有 ceil(m/2)个孩子 所有叶子节点都位于同一层 假设每个非终端节点包含有n个关键字信息，其中 Ki(i=1,…n)为关键字，关键字按顺序排序K(i-1)&lt;Ki 关键字个数n必须满足 : [cell(m/2)-1]&lt;=n&lt;=m-1 非叶子节点的指针：P[1],p[2],….,p[M];其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1],K[i])的子树 B+-TreeB+树定义： 非叶子节点的子树指针和关键字个数相同 非叶子节点的子树指针P[i],指向关键字值[K[i],K[i+1])的子树, 大于等于 K[i] 小于 K[i+1] 非叶子节点仅用来做索引，数据都保存在叶子节点中 所有叶子节点均有一个链指针指向下一个叶子节点 B+Tree更适合用来存储索引 B+ 树的磁盘读写代价更低（程序运行，往往最耗时的操作就是IO，如果IO的次数越少，那么运行也就越快，代价也就越低，非叶子节点结构没有指向关键字对应表记录的指针，只存放索引，因此节点比B树更小） B+ 树的查询效率更加稳定，数据存放在叶节点中，也就意味着每次查询都需要经过从根节点到叶节点的查询路径，时间复杂度味为O(logn)，比较稳定 B+ 树更有利于对数据库的扫描（因为数据只存放在叶节点中，而且有顺序，所以更好的查询数据范围） Hash 索引 hash 命中key 直接定位数据，理论上高于 b-tree b+tree 只能用 = 和 in ，不能范围查询，不能排序，不能组合索引(比较hash值是否相等来查询数据,并不能代表hash值的实际大小) hash值命中同一个存放位置， 效率不稳定，有可能还不如b+ tree（想想线性二叉树）bitmap 索引bitmap位图，适用于字段值只是固定的几个，如男、女，颜色；便于高效统计。Oracle支持位图索引，数据结构了类似B+树。锁很严重，可能因为某行修改都会锁。适合并发较少，统计较多的情况","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"索引","slug":"索引","permalink":"http://yoursite.com/tags/索引/"},{"name":"索引数据结构","slug":"索引数据结构","permalink":"http://yoursite.com/tags/索引数据结构/"}]},{"title":"数据库架构","slug":"数据库架构","date":"2019-10-08T14:24:35.000Z","updated":"2019-12-28T08:22:05.838Z","comments":true,"path":"2019/10/08/数据库架构/","link":"","permalink":"http://yoursite.com/2019/10/08/数据库架构/","excerpt":"","text":"如何去设计一个关系型数据库第一部分为存储部分，相当于文件系统，将数据持久化到存储设备中 第二部分为程序实例，对存储进行逻辑上的管理。 程序实例分为8个模块： 存储管理：将数据的逻辑关系转化为物理存储关系。 缓存机制：优化执行效率。 SQL解析：解析SQL语句。 日志管理：记录操作。 权限划分：进行多用户管理。 容灾机制：灾难恢复。 索引管理：优化数据查询效率。 锁管理：使数据库支持高并发。 常见问题 什么是索引 为什么要使用索引 什么样的信息能成为索引 索引的数据结构 密集索引和稀疏索引的区别 什么是索引索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。 为什么要使用索引先说不使用索引情况下的全表扫描: 数据库存储的最小单位是块或者页,是由多行记录组成的。(一个表就是多个块或者多个页)我们把这些块或者页加载进来,然后对每个块或页进行轮询,找到目标返回,类似:要从一本字典的第一页开始查找数据,一页一页的查,如果数据量小还好,数据量大就很慢 所以我们推出索引的概念:也就是引入字典中目录的概念,我们可以通过字典的拼音,部首,进行一层又一层的有条理的查询而这些被另外定义出来的例如:拼音,部首,就可以叫做索引 简单讲就是:为了避免全表扫描加快检索表中数据,大幅提高查询数据的效率 什么样的信息能成为索引主键、唯一键、普通键 索引的数据结构 生成索引，建立二叉查找树进行二分查找 生成索引，建立B-Tree结构进行查找 生成索引，建立B+-Tree结构进行查找 生成索引，建立Hash结构进行查找","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"数据库架构","slug":"数据库架构","permalink":"http://yoursite.com/tags/数据库架构/"}]},{"title":"HTTP与HTTPS的区别","slug":"HTTP与HTTPS的区别","date":"2019-10-08T06:08:59.000Z","updated":"2020-01-04T07:15:34.559Z","comments":true,"path":"2019/10/08/HTTP与HTTPS的区别/","link":"","permalink":"http://yoursite.com/2019/10/08/HTTP与HTTPS的区别/","excerpt":"","text":"HTTP（Hypertext Transfer Protocol）超文本传输协议是用来在 Internet 上传送超文本的传送协议，它可以使浏览器更加高效，使网络传输减少。但 HTTP 协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险。 HTTPS(Secure Hypertext Transfer Protocol) 安全超文本传输协议是一个安全的通信通道，它基于 HTTP 开发，用于在客户计算机和服务器之间交换信息。HTTPS 使用安全套接字层(SSL)进行信息交换，简单来说 HTTPS 是 HTTP 的安全版，是使用 TLS/SSL 加密的 HTTP 协议。 HTTPS 简介 HTTP HTTPS HTTP HTTP SSL OR TLS TCP TCP IP IP SSL(Security Sockets Layer,安全套接层)位于 HTTP 和 TCP 之间的协议，其内部有 TLS握手协议、TLS记录协议 为网络通信提供安全及数据完整性一种安全协议 是操作系统对外API ,SSL3.0 后更名为TLS 采用身份验证和数据加密保证网络通信安全和数据完整性 HTTP数据传输流程 浏览器将支持的加密算法发送给服务器 服务器选择一套浏览器支持的加密算法，以证书形式回发给浏览器 浏览器验证证书合法性，结合证书公钥加密信息发送给服务器 服务器使用私钥解密，验证哈希加密响应消息回发浏览器 浏览器解密响应消息，对消息进行验真，之后进行加密交换数据 HTTPS 和 HTTP 的区别主要为以下四点： 连接方式不同，用的端口也不一样 HTTPS默认使用443端口，HTTP使用80端口 HTTPS需要到CA申请证书，目前市面上的免费证书也不少，收费的也都比较贵。HTTP不需要 HTTP超文本传输协议明文传输，HTTPS密文传输，HTTPS基于具有安全性的SSL加密 http 的连接很简单，是无状态的 ，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/categories/计算机网络/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://yoursite.com/tags/HTTP/"}]},{"title":"HTTP相关","slug":"HTTP相关","date":"2019-10-06T08:59:45.000Z","updated":"2020-01-04T06:38:43.012Z","comments":true,"path":"2019/10/06/HTTP相关/","link":"","permalink":"http://yoursite.com/2019/10/06/HTTP相关/","excerpt":"","text":"超文本传输协议HTTP主要特点 支持客户/服务器模式 简单快速 灵活 无连接 无状态 请求/响应的步骤 客户端连接到web服务器 发送HTTP请求 服务器接受请求并返回HTTP响应 释放连接TCP连接 客户端浏览器解析HTML内容 在浏览器地址键入URL，按下回车之后经历的流程 DNS解析 浏览器依据URL逐层查询DNS服务器缓存，解析URL中的域名所对应的的IP TCP连接 找到IP地址后根据IP和对应端口和服务器建立TCP连接，结合三次握手讲解 浏览器发送HTTP请求 服务器处理请求并返回HTTP响应报文 浏览器解析渲染页面 连接结束 结合四次挥手 HTTP状态码五种可能的取值 1XX : 指示信息 – 表示请求已接收，继续处理 2XX : 成功–表示请求已被成功接收、理解、接受 3XX : 重定向 – 要完成请求必须进行更进一步的操作 4xx : 客户端错误 – 请求有语法错误或请求无法实现 5XX : 服务器端错误–服务器未能实现合法的请求常见状态码 200 OK : 正常返回信息 400 Bad Request : 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized : 请求未经授权，这个状态码必须和WWW-Authenticate 报头域一起使用 403 Forbidden : 服务器收到请求，但是拒绝提供服务 404 Not Found : 请求资源不存在,eg,输入错误的URL 500 Internal Server Error : 服务器发生了不可预期的错误 503 Server Unavailable : 服务器当前不能处理客户端的请求，一段时间后可能恢复正常 GET请求和POST请求的区别 Http报文层面：GET将信息放在URL，POST放在报文体中 ；get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?”连接，而各个变量之间使用”&amp;”连接；post是将表单中的数据放在HTTP协议的请求头或消息体中 get传输的数据要受到URL长度限制（最大长度是 2048 个字符）；而post可以传输大量的数据，上传文件通常要使用post方式； 数据库层面：GET符合幂等性和安全性，POST不符合 （幂等性：对数据库多次操作获得结果是一样的。安全性：没有改变数据库中的数据） 其他层面：GET可以被缓存、被储存，而POST不行 GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。所以HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 Cookie和Session的区别Cookie简介 由服务器发给客户端的特殊信息，以文本的形式存放在客户端 客户端再次请求的时候，会把Cookie回发 服务器接收到后，会解析Cookie生成与客户端相对应的内容 Cookie 的设置以及发送过程 客户端发送HTTP Request 到服务端 服务端发送HTTP Response + Set-Cookie 客户端发送HTTP Request + Cookie 服务器发送HTTP Response Session 简介 服务器端的机制，在服务器上保存的信息 解析客户端请求并操作session id,按需保存状态信息 Session的实现方式方式 使用Cookie来实现 服务器给每个session分配一个JSESSIONID,并通过Cookie发送给客户端，当客户端发起新的请求的时候，将在Cookie头中携带这个JSESSIONID，这样服务器能够找到客户端对应的session 使用URL回写来实现 URL回写指服务器在发送给浏览器页面的所有链接中都携带JSSESSIONID的参数，点击任何一个链接都会把JSESSIONID带回服务器。 Tomcat对session的实现一开始同时实现的，使用Cookie和URL回写机制，如果发现客户端支持cookie,就继续使用cookie停止使用URL回写，如果发现Cookie被禁用，就一直使用URL回写 Cookie和Session的区别 Cookie数据存放在客户的浏览器上，Session数据放在服务器上 Session相对Cookie更安全 若考虑减轻服务器负担，应当使用Cookie","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/categories/计算机网络/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://yoursite.com/tags/HTTP/"}]},{"title":"TCP的滑动窗口","slug":"TCP的滑动窗口","date":"2019-10-06T08:59:45.000Z","updated":"2019-11-24T13:32:04.570Z","comments":true,"path":"2019/10/06/TCP的滑动窗口/","link":"","permalink":"http://yoursite.com/2019/10/06/TCP的滑动窗口/","excerpt":"","text":"RTT和RTO RTT:发送一个数据包到接受对应ACK所花费的时间 RTO:重传时间间隔；RTT是根据RTO计算出来的 我们要实现对数据的批量发送，TCP要解决可靠传输和包乱序的问题，所以TCP需要知道网络实际的数据处理带宽或是数据处理速度才不会引起网络拥塞导致丢包 TCP使用滑动窗口做流量控制与乱序重排 保证TCP可靠性 保证TCP的流控特性。（流量控制：window，用于接收方通知发送方自己还有多少缓冲区可以接收数据，发送方根据接收方的处理能力发送数据，不会导致接受不过来） TCP的传输可靠性来源于确认重传机制，TCP的滑动窗口可靠性也是建立在确认重传基础上。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/categories/计算机网络/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://yoursite.com/tags/滑动窗口/"},{"name":"RTT","slug":"RTT","permalink":"http://yoursite.com/tags/RTT/"},{"name":"RTO","slug":"RTO","permalink":"http://yoursite.com/tags/RTO/"}]},{"title":"TCP和UDP的区别","slug":"TCP和UDP的区别","date":"2019-10-06T08:55:45.000Z","updated":"2019-12-27T12:27:09.721Z","comments":true,"path":"2019/10/06/TCP和UDP的区别/","link":"","permalink":"http://yoursite.com/2019/10/06/TCP和UDP的区别/","excerpt":"","text":"UDP简介 面向非连接 不维护连接状态，支持同时向多个客户端传输相同消息 数据包报头只有8个字节，额外开销较小 吞吐量只受限于数据生成速率，传输速率及机器性能 尽最大努力交付，不保证可靠交付，不需要维护复杂链接状态表 面向报文，不对应用程序提交的报文信息进行拆分或合并 TCP和UDP的区别 面向连接 VS 无连接 TCP有三次握手的连接过程，UDP适合消息的多播发布 可靠性：TCP比较可靠，利用握手确认和重传机制提供了可靠性保证，UDP可能会丢失 有序性：TCP利用序列号保证了消息报文顺序交互到达可能无序，但最终会排序，UDP不具备有序性 速度：TCP速度较慢，因为要创建连接保证消息的可靠性和有序性需要做额外的很多事情，UDP更合适对速度比较敏感的应用比如在线视频媒体，广播，多人在线游戏 量级：TCP属于重量级的，UDP属于轻量级的；体现在源数据的头部大小；TCP20个字节，UDP8个字节","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/categories/计算机网络/"}],"tags":[{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"微信点餐系统-service层设计","slug":"微信点餐系统-service层设计","date":"2019-09-20T05:40:03.000Z","updated":"2020-01-08T14:17:52.738Z","comments":true,"path":"2019/09/20/微信点餐系统-service层设计/","link":"","permalink":"http://yoursite.com/2019/09/20/微信点餐系统-service层设计/","excerpt":"","text":"常用注解@Entity 表明该类为一个实体类,类名和表明要一致。@Table 当实体类映射的数据表名不同名时使用，与@Entity并列使用 @Table(name=”XXXXX”)。@DynamicUpdate 自动更新updateTime@Data 自动生成getter和setter方法以及构造方法@Transational 在测试方法中使用测试完自动回滚，数据不保存数据库 如何自动生成getter/setter,toString的方法、1.引入lombok依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt; &lt;/dependency&gt; 2.安装lombok插件3.使用注解@Data 如何根据categoryType 查询返回List 对象方法命名规则： 123List&lt;ProductCategory&gt; findByCategoryTypeIn(List&lt;Integer&gt; list)List&lt;Integer&gt; list = Arrays.asList(1,2,3,4);repository.findByCategoryTypeIn(list); Java8特性把List里的属性封装进另一个List 1List&lt;Integer&gt; categoryTypeList = productInfoList.strem().map(e -&gt; e.getCategoryType()).collect(Collectors.toList()) VO ViewObject 返回给前端的对象 应根据前端需要的字段重新定义一个 VO，不要有多余字段 VO字段应该和对象的字段名称保持一致，方便Copy属性 @JsonProperty 注解的使用，123//返回给前台的JSON字段 转成自定义的名称@JsonProperty(&quot;id&quot;)private String productId 写代码中的注意事项1.不要在 for循环里有查询2.不要在代码里直接写数字，应该使用枚举","categories":[{"name":"Spring Boot 实战","slug":"Spring-Boot-实战","permalink":"http://yoursite.com/categories/Spring-Boot-实战/"}],"tags":[{"name":"lombok","slug":"lombok","permalink":"http://yoursite.com/tags/lombok/"}]},{"title":"微信点餐系统-日志框架","slug":"微信点餐系统-日志框架","date":"2019-09-18T06:22:17.000Z","updated":"2019-11-04T12:04:35.774Z","comments":true,"path":"2019/09/18/微信点餐系统-日志框架/","link":"","permalink":"http://yoursite.com/2019/09/18/微信点餐系统-日志框架/","excerpt":"","text":"使用的日志框架日志门面：SLF4J日志实现：Logback 使用slf4j 打印日志的两种方式1.手动初始化Log4j的一个实例 12Logger logger = LoggerFactory.getLogger(this.class)logger.info(&quot;info...&quot;); 2.使用注解 @Slf4j ,可以直接使用log添加依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 1log.info(&quot;info...&quot;); 使用占位符可直接打印变量123String name = &quot;root&quot;;String password = &quot;123455&quot;;log.info(&quot;name: &#123;&#125;, password: &#123;&#125;&quot; , name,password) Logback配置1.创建 logback-spring.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;configuration&gt; &lt;appender name=&quot;consoleLog&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt; %d - %msg%n &lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=&quot;fileInfoLog&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!--滚动策略,每天一个日志--&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--路径--&gt; &lt;fileNamePattern&gt; F:\\log\\tomcat\\info.%d.log &lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name=&quot;fileErrorLog&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!--滚动策略--&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--路径--&gt; &lt;fileNamePattern&gt; F:\\log\\tomcat\\error.%d.log &lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;consoleLog&quot;/&gt; &lt;appender-ref ref=&quot;fileInfoLog&quot;/&gt; &lt;appender-ref ref=&quot;fileErrorLog&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt;","categories":[{"name":"Spring Boot 实战","slug":"Spring-Boot-实战","permalink":"http://yoursite.com/categories/Spring-Boot-实战/"}],"tags":[{"name":"日志框架","slug":"日志框架","permalink":"http://yoursite.com/tags/日志框架/"}]},{"title":"微信点餐系统-数据库设计","slug":"微信点餐系统-数据库设计","date":"2019-09-18T01:36:50.000Z","updated":"2019-11-04T12:04:24.970Z","comments":true,"path":"2019/09/18/微信点餐系统-数据库设计/","link":"","permalink":"http://yoursite.com/2019/09/18/微信点餐系统-数据库设计/","excerpt":"","text":"数据库设计表的的构成类目表，商品表，订单主表，订单详情表 日期时间类型设置默认时间，DEFAULT CURRENT_TIMESTAMP时间类型字段自动更新数据，ON UPDATE CURRENT_TIMESTAMP SQL UNIQUE 约束UNIQUE约束唯一标识数据库表中的每条记录。UNIQUE和PRIMARY KEY 约束均为列或列激活提供了唯一性的保证。PRIMARY KEY 拥有自动定义的 UNIQUE约束。请注意，每个表可以有多个UNIQUE约束，但是每个表只能有一个 PRIMARY KEY 约束。 数据库编码使用 UTF-8 unicode(uftf8mb4)可以存表情","categories":[{"name":"Spring Boot 实战","slug":"Spring-Boot-实战","permalink":"http://yoursite.com/categories/Spring-Boot-实战/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"TCP的三次握手和四次挥手","slug":"TCP的三次握手和四次挥手","date":"2019-05-22T07:51:17.000Z","updated":"2019-12-27T08:54:52.080Z","comments":true,"path":"2019/05/22/TCP的三次握手和四次挥手/","link":"","permalink":"http://yoursite.com/2019/05/22/TCP的三次握手和四次挥手/","excerpt":"","text":"TCP的三次握手TCP报文头source port （源端口）destination（目标端口）Sequence Number（同步序号）Acknowledgement Number（确认序号）Offset（偏移量）Reserved（保留域）TCP Flags（标志位）Window（滑动窗口）CheckSum（检验和）Urgent Pointer（紧急指针）TCP Options（定义一些可选参数） TCP报文头包含源端口及目的端口，IP地址可以唯一标识主机，TCP协议加端口可以唯一标识主机中的一个进程。可以使用IP+协议+端口来唯一标识网络中的一个进程。在一些场景下也把这种模式称为“套接字”即Socket。 TCP FlagsURG: 紧急指针是否有效ACK: 表示确认标志，携带 ACK 标志的报文也称为确认报文PSH: 提示接收端收到报文之后应该立即将数据推送给应用程序，而不是放在缓冲区排队RET: 表示要求对方重新建立连接。SYN: 同步序列号，用于建立连接过程FIN: 传输结束标志，告知对方自己即将关闭连接。 TCP三次握手流程（“握手是为了建立连接”） 在TPC/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接 第一次握手： 建立连接时，客户端发送SYN包（seq=x）到服务器，并进入SYN_SENT状态，等待服务器确认 第二次握手：服务器收到SYN包，必须确认客户的SYN(ack=x+1),同时自己也发送一个SYN包（sql=y）,即SYN+ACK包，此时服务器进入SYN_RECV状态 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1) ,此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手各个状态的意义如下： LISTEN - 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； 为什么需要三次握手才能建立连接为了初始化Sequence Number的初始值 首次握手隐患——SYN超时 Server收到Client的SYN，回复SYN-ACK的时候未收到ACK确认 Server不断重试直至超时，Linux默认5次，总共需要63秒断开连接。 针对SYN Flood的防护措施客户端给服务器发送一个SYN报文，下线，服务器需要默认等63秒才会断开。通过这个方法可以耗尽服务器的SYN连接队列。 SYN队列满后，通过tcp_syncookies参数回发SYN Cookie 若为正常连接则Client会回发SYN Cookie，直接建立连接 建立连接后，Client出现故障怎么办保活机制：建立TCP连接后，TCP有保活机制，以应对其中一端出现故障。若连接处于非活动状态，则开启保活功能的一方将向另一方发送保活探测报文，达到keepalive time时间间隔仍未收到响应则重试，若尝试次数达到保活探测数仍未收到对方的响应，则连接断开。 TCP的四次挥手TCP四次挥手流程（挥手是为了终止连接）第一次挥手： Client发送一个FIN,用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态； 第二次挥手： Server收到FIN后，发送ACK给Client,确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态； 第三次握手： Server发送一个FIN,用来关闭Server到Client的数据传送，Server进入LAST_ACK状态； 第四次挥手： Clien收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server,确认序号为收到的序号+1，Server进入CLOSED状态，完成四次挥手； TCP连接必须经过时间2MSL后才真正释放掉？ 保证有足够时间让对方收到ACK包 避免新旧连接混淆 为什么四次挥手才能断开连接因为TCP是全双工的，发送方和接收方都需要FIN报文和ACK报文 服务器出现大量CLOSE_WAIT状态的原因对方关闭socket连接，我方忙于读或写，没有及时关闭 检查代码，特别是释放资源的代码 检查配置，特别是处理请求的线程配置 netstat查看机器网络状态的指令12查看服务器处于各个状态下的连接数 netstat -n | awk &apos;/^tcp/&#123;++S[$NF]&#125;END(FOR(a in S) print a,S[a])&apos;","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/categories/计算机网络/"}],"tags":[{"name":"TCP的三次握手","slug":"TCP的三次握手","permalink":"http://yoursite.com/tags/TCP的三次握手/"},{"name":"TCP的四次挥手","slug":"TCP的四次挥手","permalink":"http://yoursite.com/tags/TCP的四次挥手/"}]},{"title":"网络基础知识","slug":"网络基础知识讲解","date":"2019-04-25T10:40:12.000Z","updated":"2019-10-11T04:09:00.540Z","comments":true,"path":"2019/04/25/网络基础知识讲解/","link":"","permalink":"http://yoursite.com/2019/04/25/网络基础知识讲解/","excerpt":"","text":"OSI开放式互联参考模型 物理层： 定义物理设备标准（网线类型、光纤接口类型、各种传输介质的传输速率）,主要作用：传输比特流0101二进制数据 —&gt; 转化为电流强弱 —&gt; 0101 数模转换和模数转换 单位:比特 （网卡） 数据链路层： 定义了如何格式化数据以进行传输，和控制对物理介质的访问。主要作用：提供错误检测和纠正，确保数据传输可靠性。该层将比特数据组成为帧。（交换机） 网络层： 将网络地址翻译成对应的物理地址，决定数据从发送方路由到接收方，单位是数据包。有IP协议）路由器 传输层： 解决主机间的数据传输。（传输协议，流量控制，接收方接收数据快慢程度，规定发送速率；还可以分割大的数据包；TCP和UDP协议） 会话层： 定义不同机器上的用户之间建立及管理回话，解决应用程序之间的通信，自动收发包和寻址的功能 表示层： 解决不同操作系统之间的通信语法问题。信息的语法语义，加密解密，转换翻译 应用层： 规定接收方发送方必须使用一个固定长度的消息头，消息头必须使用固定的组成继续消息体的长度，关注TCP/IP协议中的http协议 OSI 参考模型并不是一个标准，概念性框架。事实的标准是 TCP/IP 四层架构参考模型 OSI的“实现” TCP/IP协议 TCP/IP四层模型（从下到上）：链路层：获取以太网首部网络层：获取IP首部传输层：获取TCP首部应用层：HTTP数据","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/categories/计算机网络/"}],"tags":[{"name":"OSI七层模型","slug":"OSI七层模型","permalink":"http://yoursite.com/tags/OSI七层模型/"}]}]}