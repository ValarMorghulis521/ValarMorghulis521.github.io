<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2019%2F12%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[总结一下之前的项目中出现的设计模式 单例模式单例模式是Java最简单的模式之一；这种类型的设计模式属于创建型模式，它提供一种创建对象的最佳方式。 注意： 单例类只能有一个实例 单例类必须自己创建自己的唯一实例 单例类给所有其他对象提供这一实例 主要解决：一个全局使用的类频繁的创建与销毁。所以需要控制实例数目，节省系统资源 ； 如何实现：系统判断是否已经有这个单例，如果有则返回，如果没有则创建，创建的实例静态私有，构造函数也是私有， 使用场景： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 代码实现双检锁/双重校验锁（DCL,即 double-checker locking） 注意事项：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 1234567891011121314public class Singleton&#123; private volatile static Singleton singleton; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(singleton == null)&#123; synchronized(Singleton.class)&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 项目中用到的代码例子 123456789101112131415161718192021222324252627282930313233343536373839public class ParseXmlService &#123; private static ParseXmlService instance; private IParseXmlManager mgr; /** * 通过实现xml2sheets业务方法,解析xml * * @param cls * 类 * @param key * xml mapping配置文件的key值 * @param filePath * xml配置文件路径,包含文件名 * @return 解析的对象 * @see ParseXmlManagerImpl#xml2object(Class, String, String) * @throws ParseXMLException * 解析出错抛异常 */ public Object xml2object(Class cls, String key, String filePath) throws ParseXMLException &#123; return this.mgr.xml2object(cls, key, filePath); &#125; private ParseXmlService() &#123; mgr = (IParseXmlManager) ApplicationContextHolder.getInstance() .getBean(&quot;ParseXmlManagerImpl&quot;); &#125; public static ParseXmlService create() &#123; if (instance == null) &#123; instance = new ParseXmlService(); &#125; return instance; &#125;&#125; 工厂模式工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式 主要解决：解决接口选择的问题 ，明确地计划不同条件下创建不同实例时 如何实现：让其子类实现工厂接口，返回的也是一个抽象的产品，创建过程在其子类执行。 使用场景： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。 缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 使用场景： 日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，”POP3”、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口。 代码实现 创建建一个接口ID2NameDAO.java 12345678public interface ID2NameDAO &#123; /** * id转name * @param id 一般为表中的主键 * @return 返回主键对应的name(自定义) */ public String id2Name(String id); &#125; 创建实现接口的实体类 TawSystemProvinceDaoJdbcForDXLTE.java 123456789@Overridepublic class TawSystemProvinceDaoJdbcForDXLTE implements TawSystemProvinceDaoForDXLTE,ID2NameDAO&#123; @Override public String id2Name(String id) throws DictDAOException &#123; return CossUtil.getCfProvinceMgr().provinceId2Name(id); &#125;&#125; TawSystemCityDaoJdbcForDXLTE.java 123456789101112@Overridepublic class TawSystemCityDaoJdbcForDXLTE implements TawSystemCityDaoForDXLTE,ID2NameDAO &#123; @Override public String id2Name(String id) throws DictDAOException &#123; String cityName = &quot;&quot;; if(StringUtils.isEmpty(id))&#123; String cityId = id.replaceAll(&quot; &quot;, &quot;&quot;); cityName = CossUtil.getCfCityMgr().cityId2Name(cityId); &#125; return cityName; &#125;&#125; TawSystemUserDaoHibernate.java 1234567@Overridepublic String id2Name(final String id) throws DictDAOException &#123; HibernateCallback callback = new HibernateCallback() &#123; TawSystemUser user = null; user = (TawSystemUser) getHibernateTemplate().execute(callback); return user.getUsername(); &#125; 创建一个工厂，生成基于给定信息的实体类对象 12345678910111213141516171819public class ID2NameServiceImpl extends BaseManager implements ID2NameService &#123; public String id2Name(String id, String beanId) &#123; String name = null; try &#123; // 通过beanid取bean ID2NameDAO dao = (ID2NameDAO) ApplicationContextHolder.getInstance().getBean(beanId); // 转换后的name name = dao.id2Name(id); &#125; catch (Exception e) &#123; // 取id2name失败后的name默认值 name = Util.idNoName(); &#125; if (name == null || &quot;&quot;.equals(name)) &#123; name = Util.idNoName(); &#125; return name; &#125;&#125; 配置bean的信息 12345678&lt;bean id=&quot;ID2NameGetServiceCatch&quot; parent=&quot;dictBaseCacheProxy&quot;&gt; &lt;property name=&quot;target&quot;&gt; &lt;bean class=&quot;com.boco.eoms.commons.system.dict.service.impl.ID2NameServiceImpl&quot;&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; 使用该工厂123ID2NameService name = (ID2NameService) ApplicationContextHolder.getInstance().getBean(&quot;ID2NameGetServiceCatch&quot;);String provinceName = name.id2Name(mainProvince, &quot;tawSystemProvinceDaoForDXLTE&quot;);String regionName = name.id2Name(mainCity, &quot;tawSystemRegionDaoForDXLTE&quot;); 抽象工厂模式抽象工厂模式是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式。 主要解决：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品，主要解决接口选择的问题。 如何实现：在一个产品族里面，定义多个产品。 使用场景： QQ 换皮肤，一整套一起换。 生成不同操作系统的程序。 抽象工厂模式也就是不仅生产鼠标，同时生产键盘。 也就是 PC 厂商是个父类，有生产鼠标，生产键盘两个接口。 戴尔工厂，惠普工厂继承它，可以分别生产戴尔鼠标+戴尔键盘，和惠普鼠标+惠普键盘。 创建工厂时，由戴尔工厂创建。 后续工厂.生产鼠标()则生产戴尔鼠标，工厂.生产键盘()则生产戴尔键盘。 代理模式在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 主要解决：直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。想在访问一个类时做一些控制 如何实现：增加中间层；实现与被代理类组合。 简单例子代码实现： 新建一个接口实现pay方法 真实实现类和代理类都要实现该方法 在代理类中注入真实实现类，在代理类的实现方法pay()中调用真实实现类的pay()方法，然后增加做自己的业务逻辑 123public interface Payment&#123; void pay();&#125; 1234567public RealPayment implements Payment&#123; @Override public void pay()&#123; System.out.println(&quot;作为用户我只关心支付&quot;) &#125;&#125; 1234567891011121314151617public AliPay implements Payment&#123; private Payment payment; public AliPay(Payment payment) public void beforePay()&#123; System.out.println(&quot;从招行取款&quot;) &#125; @Override public void pay()&#123; beforePay()； payment.pay(); afterPay(); &#125; public void afterPay()&#123; System.out.println(&quot;支付给慕课网&quot;) &#125;&#125; 12Payment proxy = new AliPay(new RealPayment);proxy.pay();]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>单例模式</tag>
        <tag>工厂模式</tag>
        <tag>代理模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器部署]]></title>
    <url>%2F2019%2F11%2F19%2F%E5%AE%B9%E5%99%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[实现IntelliJ IDEA快速部署到远程docker IntelliJ IDEA安装Docker插件Docker 增加一个docker远程连接，此时连接的是我虚拟机上的docker 在项目的根目录下创建Dockerfile文件 1234567891011121314#指定基础镜像，在其上进行定制FROM hub.c.163.com/library/java:8-alpine#维护者信息MAINTAINER sunchenming &lt;scm_5@outlook.com&gt;#添加target/*.jar 到容器里ADD target/*.jar app.jar#声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务EXPOSE 8761#指定容器启动程序及参数 &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot;ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;app.jar&quot;] 打开IDEA右上角的 Run/Debug Configurations，新增Docker启动方式，然后在配置中填写如下信息 点击启动，构建成功 查看docker镜像 将镜像推送到阿里云的镜像个人中心 123$ sudo docker login --username=sunchenming registry.cn-hangzhou.aliyuncs.com$ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/monster_body/springcloud_eureka:[镜像版本号]$ sudo docker push registry.cn-hangzhou.aliyuncs.com/monster_body/springcloud_eureka:[镜像版本号] Ranch Rancher入门：https://www.jianshu.com/p/3a492440c89b Rancher是使用一系列的Docker容器进行部署的。运行Rancher跟启动两个容器一样简单。一个容器作为管理服务器部署，另外一个作为集群节点的Agent部署 使用docker安装 1sudo docker run -d --restart=unless-stopped -p 8080:8080 rancher/server:stable 确认安全组或防火墙允许以下通讯:与其他所有主机之间的 UDP 端口 500 和 4500 (用于IPsec网络) 防火墙如何开启和关闭？ 123456sudo systemctl start firewalldsudo systemctl stop firewalldfirewall-cmd --permanent --zone=public --add-port=4500/udp 开启nc -vuz 192.168.1.106 500firewall-cmd --reload //更新防火墙规则 在Ranch中添加主机，启动一台注册了Rancher-angent的主机 在应用选项-添加应用-springcloud 在springcloud应用下去添加服务 项目版本升级]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[链路监控]]></title>
    <url>%2F2019%2F11%2F18%2F%E9%93%BE%E8%B7%AF%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[Spring Cloud Sleuth 添加sleuth的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; 把 org.springframework.cloud.netflix.feign包 调整日志级别，添加配置 123logging: level: org.springframework.cloud.netflix.feign: debug 调用order服务的创建订单接口1INFO [order,5b8dbc3132a06305,5b8dbc3132a06305,false] 8940 --- [nio-8083-exec-2] c.netflix.config.ChainedDynamicProperty : sleuth打印的四个值[服务名,id1,id2,true/false]: id1: trace id,一条链路里面最多包含一条trans id，即一条链路的唯一 标识； id2: span id，一条链路一面可以包含多个span id，它是一个基本的工作单元（比如发送一个HTTP请求）； true：将信息输出给其他服务（如zipkin），反之为false Zipkin 链路可视化工具,集成Zinpin的步骤： docker 下安装 1docker run -d -p 9411:9411 openzipkin/zipkin 添加Zipkin的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 注：以上依赖包等同于 spring-cloud-starter-sleuth + spring-cloud-sleuth-zipkin的整合，因此原来的spring-cloud-starter-sleuth依赖可直接注释掉 配置参数 123456zipkin: base-url: http://192.168.1.106:9411///统计日志的百分比为全部，如果10%填0.1sleuth: sampler: percentage: 1 调用下单接口，访问 Zipkin地址 http://192.168.1.106:9411 OpenTracing OpenTracing是语义规范、是跨语言的，zipkin是根据这个规范的。 几个重要的概念：traceId：在哪生成的idspanId：下一次的请求idparentId：上一次请求的id 事件类型把一个请求的生命周期划成四种事件类型 cs(Client Send):客户端发起请求的时间 cr(Client Received):客户端收到处理完请求的时间 ss(Server Send):服务端处理完逻辑的时间 sr(Server Received):服务端收到调用端请求的时间]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
      <tags>
        <tag>链路监控</tag>
        <tag>Spring Cloud Sleuth</tag>
        <tag>Zipkin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务容错Hystrix]]></title>
    <url>%2F2019%2F11%2F18%2F%E6%9C%8D%E5%8A%A1%E5%AE%B9%E9%94%99Hystrix%2F</url>
    <content type="text"><![CDATA[防雪崩利器，雪崩就是A调用B，B调用C，C要是不好了，B也不好了 服务降级 优先核心服务，非核心业务不可用或弱可用 通过HystrixCommand注解指定 fallbackMethod（回退函数）中具体实现降级逻辑 实现步骤： 引入hystrix Jar包依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 启动类加注解@EnableCircuitBreaker ，或者可直接使用@SpringCloudApplication注解，此注解包含多个注解@SpringBootApplication、@EnableDiscoveryClient、@EnableCircuitBreaker 方法体上增加 @HystrixCommand(fallbackMethod = “fallback”) 注解，fallback是一个方法名，调用其他服务失败或方法内部抛出异常时会运行这个方法类上加@DefaultProperties(defaultFallback = “defaultFallback”) 注解 出现异常可默认调用defaultFallback方法处理 1234567891011121314@RestController@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)public class HystrixController &#123; @HystrixCommand(fallbackMethod = &quot;fallback&quot;) @GetMapping(&quot;/getProductInfoList&quot;) public String getProductInfoList()&#123; RestTemplate restTemplate = new RestTemplate(); return restTemplate.postForObject(&quot;http://127.0.0.1:8081/product/listForOrder&quot;, Arrays.asList(&quot;157875196366160022&quot;),String.class); &#125; private String fallback()&#123; return &quot;太拥挤了，请稍后再试&quot;; &#125;&#125; 超时设置 超时时间设置：方法上增加注解 123@HystrixCommand(commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.thread.timeoutInMilliseconds&quot;,value = &quot;3000&quot;) &#125;) 在yml文件中设置 12345678910111213hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 #给getProductInfoList方法单独设置 getProductInfoList: execution: isolation: thread: timeoutInMilliseconds: 1000 有时候第一次启动时都会超时。原因：因为第一次有懒加载的过程，造成了超时。解决方式：配置一下超时时间长一点就好了，如图 熔断 实现进程隔离，容器之间互不影响！ Hystrix依赖隔离：实现的是线程池的隔离，会为每个hystrix command创建独立的线程池，这样就是哪个在hystrix command包装的依赖服务出现延迟较高的情况，也只是对该依赖服务的调用产生影响，并不会拖慢其他服务。 使用了hystrix command把每个函数包装称hystrix mini时，hystrix框架就会自动为这个函数实现依赖隔离。所以，依赖隔离、服务降级在使用时都是一体化实现的！（一体化？？） 这样，利用hystrix来实现服务容错保护在编程模型上就非常方便了！ 依赖隔离： 线程池隔离 Hystrix 自动实现了依赖隔离 设置熔断的重要参数123456@HystrixCommand(commandProperties = &#123; @HystrixProperty(name=&quot;circuitBreaker.enabled&quot;,value = &quot;true&quot;), // 设置熔断 @HystrixProperty(name=&quot;circuitBreaker.requestVolumeThreshold&quot;,value = &quot;10&quot;),//最小请求数 @HystrixProperty(name=&quot;circuitBreaker.sleepWindowInMilliseconds&quot;,value = &quot;10000&quot;),//休眠时间窗口 @HystrixProperty(name=&quot;circuitBreaker.errorThresholdPercentage&quot;,value = &quot;60&quot;) //错误百分比 ，比如百分之70，就是10个请求有7个错误&#125;) Circuit Breaker：断路器 ，当故障达到一定值就跳闸 断路器状态机： closed，熔断器关闭状态，调用失败次数累计到一定阈值/比例，启动熔断机制，进入打开状态 open，熔断器打开状态，对服务直接返回错误，直接服务降级 half open，熔断器打开状态达到了一定的时间，会进入半熔断状态，允许定量的服务请求主逻辑。如果都调用成功，或者一定比例成功，则认为恢复，关闭熔断器；否则，熔断器回到打开状态 添加熔断的可视化组件 hystrix-dashboard 引入hystrix-dashboard包依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 启动类添加@EnableHystrixDashboard 注解 访问 http://localhost:8083/hystrix 添加配置进入]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
      <tags>
        <tag>服务容错</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul]]></title>
    <url>%2F2019%2F11%2F16%2FZuul%2F</url>
    <content type="text"><![CDATA[服务网关和Zuul常用的网关方案： Nginx+Lua Kong(配置比Nginx简单，很多要付费的插件) Tyk（各种支持、Go语言开发的） Spring Cloud Zuul(路由+过滤器，过滤：安全、监控、限流、路由…..) 服务网关作为请求入口，不能挂掉。需要保证稳定性、高可用、并发性、安全性、扩展性。网关适合处理非业务功能的绝佳场所：协议转发、日志监控、流量管控、api权限等等。 服务网管的要素 稳定性，高可用 性能、并发性 安全性 扩展性 Zuul组件内一次请求的生命周期 Zuul组件架构图 Zuul:路由转发，排除和自定义如何实现路由转发 新建项目api-getway 选择Cloud Routing -&gt;Zuul、Config Client、Eureka Client 配置config和eureka Application启动类添加 @EnableZuulProxy注解 直接访问 路由地址/服务名/接口地址 如 localhost:8080/product/product/list (8080为路由的端口) 如何自定义和排除1234567891011zuul: routes: # /myProduct/product/list -&gt; /product/product/list myProduct: path: /myProduct/** serviceId: product # 以上简洁写法 product: /myProduct/** # 排除某些路由，可写多个，- 表示空格 ignored-patterns: - /**/product/listForOrder 查看所有路由 localhost: 9090/application/routesZuul:Cookie和动态路由不过滤cookie的办法 sensitiveHeaders不填1234567891011management: security: enabled: falsezuul: ignored-patterns: - /**/product/listForOrder routes: myProduct: path: /myProduct/** sensitiveHeaders: &apos;&apos; serviceId: product 动态路由 使用spring Cloud Bus实现动态修改路由配置 如何在代码里修改配置不需要更新？1234567public class ZuuConfig &#123; @ConfigurationProperties(&quot;zuul&quot;) @RefreshScope public ZuulProperties zuulProperties()&#123; return new ZuulProperties() &#125;&#125; Zuul:高可用 Pre前置过滤器，限流。鉴权，把鉴权逻辑放在Pre。参数过滤，请求转发 Post后置过滤器，统计，日志 多台zuul，需要多台高可用，多个节点都注册到Eureka上面。 可用Nginx和Zuul进行混搭，使用Nginx暴露Url，把请求转发到多个Zuul服务上。Nginx继续做负载均衡 Zuul:Pre和Post过滤器 Pre过滤器的实现,继承ZuulFilter 实现四个方法 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class TokenFilter extends ZuulFilter&#123; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * filterOrder 是过滤器的顺序，越小的优先级越高 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; /** * 实现逻辑 * @return */ @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); //从url参数获取，也可以从cookie,header里获取 String tocken = request.getParameter(&quot;token&quot;); //token为空返回401 if(StringUtils.isEmpty(tocken))&#123; requestContext.setSendZuulResponse(false); requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); &#125; return null; &#125;&#125; Post过滤器的实现 12345678910111213141516171819202122232425@Componentpublic class AddResponseHeaderFilter extends ZuulFilter&#123; @Override public String filterType() &#123; return POST_TYPE; &#125; @Override public int filterOrder() &#123; return SEND_RESPONSE_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletResponse response = requestContext.getResponse(); //增加一个响应头 response.setHeader(&quot;X-Foo&quot;, UUID.randomUUID().toString()); return null; &#125;&#125; Zuul:限流令牌桶式限流时机：请求被转发之前调用 12345678910111213141516171819202122232425262728293031/** * 限流 */@Componentpublic class RateLimitFilter extends ZuulFilter &#123; //guava组件对令牌桶的实现 private static final RateLimiter RATE_LIMITER =RateLimiter.create(100); @Override public String filterType() &#123; return PRE_TYPE; &#125; @Override public int filterOrder() &#123; return SERVLET_DETECTION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; //尝试去取一个令牌 if(!RATE_LIMITER.tryAcquire())&#123; throw new RateLimitException(); &#125; return null; &#125;&#125; 继承ZuulFilter,实现4个方法，修改返回值 filterType()返回值为PRE_TYPE RateLimiter.create 限制100个 在run方法写限流抛异常 Zuul:鉴权要实现的业务： /order/create 只能买家访问 /order/finish 只能卖家访问 /product/list 都可以访问 /order/create 如何权限校验,先根据访问路径判断是否拦截，再根据买家和卖家各有的特点去判断 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 权限拦截（区分买家和卖家） */@Componentpublic class AuthBuyerFilter extends ZuulFilter&#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * filterOrder 是过滤器的顺序，越小的优先级越高 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); if(&quot;/order/order/create&quot;.equals(request.getRequestURI()))&#123; return true; &#125; return false; &#125; /** * 实现逻辑 * @return */ @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); /** * /order/create 创建订单只能买家访问 */ Cookie cookie = CookieUtil.get(request,&quot;openid&quot;); if(cookie == null || StringUtils.isEmpty(cookie.getValue()))&#123; requestContext.setSendZuulResponse(false); requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); &#125; return null; &#125;&#125; /order/finish 只能卖家访问 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 权限拦截（区分买家和卖家） */@Componentpublic class AuthSellerFilter extends ZuulFilter&#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * filterOrder 是过滤器的顺序，越小的优先级越高 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); if(&quot;/order/order/finish&quot;.equals(request.getRequestURI()))&#123; return true; &#125; return false; &#125; /** * 实现逻辑 * @return */ @Override public Object run() &#123; RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); /** * /order/finish 只能卖家访问 */ Cookie cookie = CookieUtil.get(request,&quot;token&quot;); if(cookie == null || StringUtils.isEmpty(cookie.getValue()) || StringUtils.isEmpty(stringRedisTemplate.opsForValue().get(String.format(RedisConstant.TOKEN_TEMPLATE,cookie.getValue()))) )&#123; requestContext.setSendZuulResponse(false); requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); &#125; return null; &#125;&#125; Zuul:跨域什么是跨域问题？ 同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。 同源 域名、协议、端口相同，也就是在同一个域里。 如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。 解决方案 在被调用的类或方法上增加@CrossOrigin注解 在Zuul里增加CorsFilter过滤器 12345678910111213141516171819202122/** * 跨域配置 * C-Cross O-Origin R-Resource S-Sharing */@Configurationpublic class CorsConfig &#123; @Bean public CorsFilter corsFilter()&#123; final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); final CorsConfiguration config = new CorsConfiguration(); //是否支持cookie跨域 config.setAllowCredentials(true); //原始域 http:a.com config.setAllowedOrigins(Arrays.asList(&quot;*&quot;)); config.setAllowedHeaders(Arrays.asList(&quot;*&quot;)); config.setAllowedMethods(Arrays.asList(&quot;*&quot;)); config.setMaxAge(300l); //把跨域的配置注册到source上 source.registerCorsConfiguration(&quot;*&quot;,config); return new CorsFilter(source); &#125;&#125;]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
      <tags>
        <tag>服务网关</tag>
        <tag>Zuul</tag>
        <tag>Cookie和动态路由</tag>
        <tag>限流</tag>
        <tag>鉴权</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的使用]]></title>
    <url>%2F2019%2F11%2F13%2Fdocker%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是docker? 从系统环境开始，自底至上打包应用 轻量级，对资源的有效该和管理 使用image Docker思想 集装箱 标准化： 运输方式 存储方式 API接口 隔离:类似于虚拟机，更加轻量 Docker解决了什么问题：让快速扩展，弹性伸缩变得简单 Docker核心技术 Docker镜像，实质上就是一系列文件（包括应用程序的文件、应用的运行环境的文件），使用了基于分层的联合文件系统实现了镜像存储 Docker容器，本质就是一个进程；可以想象成一个虚拟机，但是是分层的，最上一层可读可写。通过一个镜像可以生成多个容器，独立运行； Docker仓库，构建镜像在其他服务器上去运行我的程序。先把我的镜像传到仓库，再从其他服务器拉取，类似于起到中转作用 Docker 安装 保证apt-get是最新版本 1apt-get update 安装Docker 1apt-get install -y docker.io 查看Docker版本 1docker version 如何创建一个Docker镜像 拉取镜像 1docker pull [OPTIONS] NAME[:TAG] 查看本机都有哪些镜像 1docker images [OPTIONS] [REPOSITORY][:TAG] 后台运行镜像 1docker run NAME -d Docker运行Nginx 去网易云镜像中心下载nginx镜像 https://c.163yun.com/hub或者Docker的nginx镜像仓库：https://hub.docker.com/ 1docker pull hub.c.163.com/library/nginx:latest 查看正在找运行的容器 1docker ps 进入容器内部 12docker exec [OPTION] CONTAINER COMMAND [ARG...]docker exec -it nginx bash 退出容器 1exit 停止容器 1docker stop 进程名 Docker网络网络类型 Bridge 桥接模式，独立ip，网络隔离 Host 宿主模式，跟主机一个网络 None 把nginx的80端口映射到主机的8080端口 1docker run -d -p 8080:80 nginx 制作自己的景象 写好Dockerfile 12345from hub.c.163.com/library/tomcatMAINTAINER sunchenming ***@163.comCOPY jpress.war /usr/local/tomcat/webapps 构建镜像，docker build 1docker build -t jpress:latest]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统一配置中心]]></title>
    <url>%2F2019%2F11%2F13%2F%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[什么是统一配置中心？ 多人改一个配置不方便维护 配置中涉及到内容安全与权限，比如说数据库密码;这里可以把配置文件进行隔离不放进项目代码 每改一次配置都需要项目重启 Config的配置配置Config Server端 新建项目 选中Eureka Discovery Client和 Config Server 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; 启动类加注解 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableConfigServerpublic class ConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125;&#125; github上创建config-repo的仓库，在仓库中新增一个 order.yml 在config服务的application.yml增加github的配置信息如下： 12345678cloud: config: server: git: uri: https://github.com/ValarMorghulis521/config-repo.git username: ValarMorghulis521 password: ******** basedir: github的本地仓库地址 本地访问github上的yml配置信息 http://localhost:8080/release/order-dev.yml 配置命名的约定规则： /{name}-{profiles}.yml （/文件名-环境名.文件后缀） /{label}/{name}-{profiles}.yml （/分支名/文件名-环境名.文件后缀） name 代表服务名 profile 代表 环境名 label 代表分支 branch 如我要访问dev的配置（默认是master分支）http://localhost:8080/order-dev.yml如我要访问dev分支下dev的配置 http://localhost:8080/dev/order-dev.yml 配置Config Client端 在需要用到Config Client的服务上新增config-client依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; application.yml文件中新增config的配置,删除数据库其他配置信息 123456789spring: application: name: order cloud: config: discovery: enabled: true service-id: CONFIG profile: dev tips：当我们访问http://localhost:8080/dev/order-dev.yml 时是如何找到对应的配置？ appliction.name+profile.yml对应到github的配置 application.yml更名为bootstrap.yml，作为引导先启动；config-client会先去eureka上找配置的service-id,这里配置的是CONFIG，所以会去找名为“CONFIG”的服务，如果找不到会把127.0.0.01：8888当成config-server ;然后再从configServ上获取 order-deb.yml相关配置信息 只需要创建多个Config Server实例即可实现高可用，不需要相互注册 order.yml (不管选择哪个环境，这个是一定会加载访问的，所以可以把公共配置放这，用不上则注释掉吧) Spring Cloud Bus如何实现配置自动刷新 config-server用了Bus之后会提供一个/bus-refresh接口，访问这个接口，config-server便会将更新配置信息发送到消息队列里面（RabbitMA） 把bus-refresh接口地址配置到git上，通过webhook访问 每次git上配置文件有了变更，便通知config-server Spring Cloud Bus实操 修改Spring Cloud 和Spring Boot的版本 配置rabbitmq连接地址：为什么没有配置rabbitmq却可以连上 ,没用配置则使用默认12345public class RabbitProperties &#123; private String host = &quot;localhost&quot;; private int port = 5672; private String username = &quot;guest&quot;; private String password = &quot;guest&quot;; 如果你的mq不是搭建在本地，配置 123456spring: rabbitmq: host: port: username: password: feign组件升级为openfeign 配置Bus接口暴露出来：1234management: endpoins: web: expose: &quot;*&quot; 在需要刷新配置的类上加 @RefreshScope 注解 远程git修改之后对bus-refresh发送post请求刷新内容 1curl -v -X POST “http://~~/actuator/bus-refresh” 配置git 的webhookURL:http:***/monitorContent type 选择application/jsonurl需要外网地址，使用netapp.cn工具映射外网地址 使用配置的前缀来映射一个配置类： 配置文件： 123girl: name: lili age: 18 创建一个对应的类 12345678@Data@Component@ConfigurationProperties(&quot;girl&quot;)@RefreshScopepublic class GirlConfig&#123; private String name; private Integer age;&#125;]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
      <tags>
        <tag>Config Server</tag>
        <tag>Config Clent</tag>
        <tag>Spring Cloud Bus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息和异步]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%B6%88%E6%81%AF%E5%92%8C%E5%BC%82%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[异步和消息什么是异步客户端请求不会阻塞进程，服务端的响应可以是非即时的 异步的常见形态 通知 请求/异步响应 消息 微服务和容器是天生一对 通过docker的镜像部署超快速实现水平扩展副本克隆 docker的隔离性实现了不同的应用服务打包成不同的 MQ应用场景 异步处理：用户注册之后需要发短信，加积分；用户注册成功后通过异步消息让短信服务和积分服务去做他们的事 流量削峰：秒杀活动会因为流量暴增，在应用前端加入消息队列，控制活动的人数，消息队列超过最大长度，直接抛弃请求跳转到错误页面。 日志处理:kafuka 用于日志处理，通过日志采集定时写入kafuka队列，然后kafuka消息队列对日志进行接收储存转发 引用解耦：如用户下单后订单服务通知商品服务 RabbitMQRabbitMQ在docker下的安装 下载镜像地址 1docker pull hub.c.163.com/library/rabbitmq:3.7.3-management 安装启动RabbitMQ 1docker run -d --hostname my-rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.7.3-management 15672端口是rabbitmq的界面管理地址 访问，因为是安装在了虚拟机上，所以本机访问虚拟机的地址 http://192.168.1.105:15672 ok!默认账号密码 guest，成功访问！ RabbitMQ的基本使用 添加RabbitMQ的pom.xml的依赖配置 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 在yml文件中新增连接RabbitMQ的配置 123456spring: rabbitmq: host: port: username: password: 创建一个接收端的类用来接收mq消息 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 接收mq消息 */@Slf4j@Componentpublic class MaReceiver &#123;// 1. @RabbitListener(queues = &quot;myQueue&quot;)// 2. 自动创建队列 @RabbitListener(queuesToDeclare = @Queue(&quot;myQueue&quot;))// 3.自动创建，Exchange和Queue绑定 @RabbitListener(bindings = @QueueBinding( value = @Queue(&quot;myQueue&quot;), exchange =@Exchange(&quot;myExchange&quot;) )) public void process(String message)&#123; log.info(&quot;MqReceiver:&#123;&#125;&quot;,message); &#125; /** * 数码供应商服务接收消息 * @param message */ @RabbitListener(bindings = @QueueBinding( exchange =@Exchange(&quot;myOrder&quot;), key = &quot;computer&quot;, value = @Queue(&quot;computerOrder&quot;) )) public void processComputer(String message)&#123; log.info(&quot;computer MqReceiver:&#123;&#125;&quot;,message); &#125; /** * 水果供应商服务接收消息 * @param message */ @RabbitListener(bindings = @QueueBinding( exchange =@Exchange(&quot;myOrder&quot;), key = &quot;fruit&quot;, value = @Queue(&quot;fruitOrder&quot;) )) public void processFruit(String message)&#123; log.info(&quot;fruit MqReceiver:&#123;&#125;&quot;,message); &#125; 创建queue的两种方式 ： @RabbitListener(queues = “myQueue”) 并在RabbitMQ中手动创建一个myQueue的队列 @RabbitListener(queuesToDeclare = @Queue(“myQueue”)) 可自动创建 key是分组的意思 写一个发送方 用到amqpTemplate.convertAndSend()12345678910111213141516171819202122/** * 发送mq消息测试 *//** * 发送mq消息测试 */@Componentpublic class MqSenderTest extends OrderApplicationTests &#123; @Autowired private AmqpTemplate amqpTemplate; @Test public void send()&#123; amqpTemplate.convertAndSend(&quot;myQueue&quot;,&quot;now&quot;+ new Date()); &#125; //只会发送给 key=computer的监听 @Test public void sendOrder()&#123; amqpTemplate.convertAndSend(&quot;myOrder&quot;,&quot;computer&quot;,&quot;now&quot;+ new Date()); &#125;&#125; Spring Cloud Stream定义SpringCloud Stream提供更方便的消息处理，达到代码层面对消息中间件的无感知的效果，支持RabbitMQ和ActiveMQ。只需定义Input和Output，无需过多考虑rabbitmq的Exchange和RoutingKey Spring Cloud Stream的基本使用 添加Stream的pom.xml的依赖配置 123 &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 在yml中配置RabbitMQ的连接地址 先定义一个接口 1234567public interface StreamClient &#123; String INPUT = &quot;myMessage&quot;; @Input(StreamClient.INPUT) SubscribableChannel input(); @Output(StreamClient.INPUT) MessageChannel output();&#125; 定义一个接收端 123456789@Component@EnableBinding(StreamClient.class)@Slf4jpublic class StreamReceiver &#123; @StreamListener(StreamClient.INPUT) public void process(Object message)&#123; log.info(&quot;StreamReceiver:&#123;&#125;&quot;,message); &#125;&#125; 定义一个发送端 1234567891011@RestControllerpublic class SendMessageController &#123; @Autowired private StreamClient streamClient; @GetMapping(&quot;/sendMessage&quot;) public void process()&#123; String message = &quot;now&quot;+ new Date(); streamClient.output().send(MessageBuilder.withPayload(message).build()); &#125;&#125; 配置分组：一个实例发送消息只让一个实例收到消息group 表示分组；content-type表示传送的格式 12345stream: bindings: myMessage: group: order content-type: application/json 如何在收到消息后回发消息 12345678910111213@StreamListener(StreamClient.INPUT)@SendTo(StreamClient.INPUT2)public String process(Object message)&#123; log.info(&quot;StreamReceiver:&#123;&#125;&quot;,message); //使用SendTo 注解 回发mq消息给input2 return &quot;received.&quot;;&#125;@StreamListener(StreamClient.INPUT2)public void process2(String message)&#123; log.info(&quot;StreamReceiver2:&#123;&#125;&quot;,message);&#125; 商品和订单服务中使用MQ流程图 商品服务接入配置中心添加依赖 12345678910 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在yml文件中新增连接RabbitMQ的配置 123456spring: rabbitmq: host: port: username: password: 安装redis和RedisDesktopManager ，引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 启动redis 1docker run -d -p 6379:6379 redis:4.0.8 在订单服务中配置redis的信息 123redis: host: 192.168.1.105 port: 6379 在order服务中message包下新建ProductInfoReceiver 从mq中接受商品信息，把商品id和库存 放入redis中 123456789101112131415161718192021222324@Component@Slf4jpublic class ProductInfoReceiver &#123; private static final String PRODUCT_STOCK_TEMPLATE = &quot;product_stock_%s&quot;; @Autowired private StringRedisTemplate stringRedisTemplate; @RabbitListener(queuesToDeclare = @Queue(&quot;productInfo&quot;)) public void process(String message)&#123; //message =&gt; ProductInfoOutput //ProductInfoOutput productInfoOutput = (ProductInfoOutput)JsonUtil.fromJson(message, ProductInfoOutput.class); List&lt;ProductInfoOutput&gt; productInfoOutputList = ( List&lt;ProductInfoOutput&gt;)JsonUtil.fromJson(message, new TypeReference&lt; List&lt;ProductInfoOutput&gt;&gt;()&#123;&#125;); log.info(&quot;从&#123;&#125;接受到消息:&#123;&#125;&quot;,&quot;productInfo&quot;,productInfoOutputList); for(ProductInfoOutput productInfoOutput : productInfoOutputList)&#123; //储存到redis中 stringRedisTemplate.opsForValue().set(String.format(PRODUCT_STOCK_TEMPLATE,productInfoOutput.getProductId()), String.valueOf(productInfoOutput.getProductStock())); &#125; &#125;&#125; 在product服务中改造减库存的方法 1234567891011121314151617181920212223242526272829303132@Override public void decreaseStock(List&lt;DecreaseStockInput&gt; decreaseStockInputList) &#123; List&lt;ProductInfo&gt; productInfoList = decreaseStockProcess(decreaseStockInputList); //扣完库存发送mq消息 List&lt;ProductInfoOutput&gt; productInfoOutputList = productInfoList.stream().map(e -&gt;&#123; ProductInfoOutput output = new ProductInfoOutput(); BeanUtils.copyProperties(e,output); return output; &#125;).collect(Collectors.toList()); amqpTemplate.convertAndSend(&quot;productInfo&quot;, JsonUtil.toJson(productInfoOutputList)); &#125; @Transactional public List&lt;ProductInfo&gt; decreaseStockProcess(List&lt;DecreaseStockInput&gt; decreaseStockInputList) &#123; List&lt;ProductInfo&gt; productInfoList = new ArrayList&lt;&gt;(); for (DecreaseStockInput decreaseStockInput : decreaseStockInputList) &#123; Optional&lt;ProductInfo&gt; productInfoOptional = productInfoRepository.findById(decreaseStockInput.getProductId()); //判断商品是否存在 if (!productInfoOptional.isPresent()) &#123; throw new ProductException(ResultEnum.PRODUCT_NOT_EXIST); &#125; ProductInfo productInfo = productInfoOptional.get(); //库存是否足够 Integer result = productInfo.getProductStock() - decreaseStockInput.getProductQuantity(); if (result &lt; 0) &#123; throw new ProductException(ResultEnum.PRODUCT_STOCK_ERROR); &#125; productInfo.setProductStock(result); productInfoRepository.save(productInfo); productInfoList.add(productInfo); &#125; return productInfoList; &#125; 异步扣库存分析原始流程 查询商品信息（调用商品服务） 计算总价（生成订单详情） 商品服务扣库存（调用商品服务） 订单入库（生成订单） 改造成基于消息队列的异步事件驱动如果把订单入库这一步改造成异步的通过消息队列异步创建订单；如果第四步异步下单创失败了，解决办法 可以尝试重试生成订单，不处理成功mq的消息就一直存在 异步扣库存分析 如果商品服务扣库存也变成异步。如果订单服务生成订单成功，而商品扣库存失败又该如何回滚？ 方案一 订单创建成功后，订单的状态是排队中，发布一个order_create事件到mq上，由mq负责转发给订阅该消息的服务，如果商品服务收到创建订单消息后执行扣库存操作。 这里扣库存由于某些原因可能扣失败，商品服务会发送一个扣库存的消息给队列，消息里面的内容是扣库存的结果。订单服务来订阅扣库存的结果，接收到该消息后，如果扣库存成功将订单的状态改为已确认即下单成功，如果扣库存失败则把订单取消 以上需要可靠的消息投递。订单服务检测商品服务扣失败的情况，然后进行补偿 在这种情况下，用户体验的变化。用户是不能立刻马上知道下单的结果。像12306买票会得到排队中的结果。可以承受住很大的并发请求。适合秒杀类的业务场景 方案二 也可以订单创建后直接返回结果，发送创建订单的消息，让商品服务与订单服务订阅该消息并异步执行自己的操作，而创建订单写入数据库采用异步实现。但前提是若商品服务扣库存或订单服务下订单有一方操作失败要回滚，则异步写入数据库要实现相应错误处理或补偿机制】 异步扣库存分析汇总 订单服务实现复制一份库存副本，保存到Redis中 收到请求，Redis判断是否库存充足，减掉Redis中库存 订单服务创建订单写入数据库，并发送消息]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>Spring Cliud Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用通信]]></title>
    <url>%2F2019%2F11%2F11%2F%E5%BA%94%E7%94%A8%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[HTTP VS RPC Dubbo是一个RPC框架，服务治理集成非常完善，不仅提供了服务注册发现，负载均衡，路由等面向分布式集群，面向开发测试，服务治理和监控的可视化平台。 Spring Cloud，微服务架构下的一站式解决方案，微服务之间使用Http Restful调用方式：RestTemplate 、Feign; HttpRestful:本身轻量易用，适用性强，可以很容易跨语言跨平台，或者与已有的系统交互。 RestTemplateorder服务访问product的三种方式，本质上都是使用RestTemplateorder服务的调用代码块 123456789101112131415161718192021222324252627@RestController@Slf4jpublic class ClientController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private RestTemplate restTemplate; @GetMapping(&quot;/getProductMsg&quot;) public String getProductMsg()&#123; //1.第一种方式 ,直接使用restTemplate，url写死// RestTemplate restTemplate = new RestTemplate();// String response = restTemplate.getForObject(&quot;http://localhost:8080/msg&quot;,String.class); //2.第二种方式 利用loadBalancerClient通过应用名获取url，然后再使用restTemplate// RestTemplate restTemplate = new RestTemplate();// ServiceInstance serviceInstance = loadBalancerClient.choose(&quot;PRODUCT&quot;);// String url = String.format(&quot;http://%s:%s&quot;,serviceInstance.getHost(),serviceInstance.getPort()+&quot;/msg&quot;);// String response = restTemplate.getForObject(url,String.class); //3.第三种方式,利用 LoadBalanced，可在restTemplate里使用应用名字 String response = restTemplate.getForObject(&quot;http://PRODUCT/msg&quot;,String.class); log.info(&quot;response=&#123;&#125;&quot;,response); return response; &#125;&#125; 第三种方式还需要加个配置类把RestTemplate作为一个bean配置上去 12345678@Componentpublic class RestTemplateConfig &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 负载均衡器：RibbonEureka中是客户端这边做负载均衡的，而不是服务端 客服端负载均衡器：Ribbon RestTemplate、Feign、Zuul都使用到了Ribbon 主要组件ServerList，IRule,ServerListFilter 主要流程：首先通过ServerList获取所有可用服务列表，然后通过ServerListFilter过滤掉一部分地址，通过IRule选择一个实例作为最终目标结果； 追踪源码自定义负载均衡策略默认使用轮询 如何改变负载均衡策略？application.yml. 1234users: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule Feign的使用 声明式REST客户端（伪RPC），本质上是一个远程方法，http客户端发送http请求 采用了基于接口的注解 内部使用的Ribbon做负载均衡使用步骤 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.0.M3&lt;/version&gt;&lt;/dependency&gt; 在启动主类上添加@EnableFeignClients注解 12345678910@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125;&#125; 创建一个接口声明你要调用哪个服务的哪些方法 123456//调用product服务的msg@FeignClient(name=&quot;product&quot;)public interface ProductClient &#123; @GetMapping(&quot;/msg&quot;) String productMsg();&#125; 把接口注入到controller，直接调用 1234567891011@RestController@Slf4jpublic class ClientController &#123; @Autowired private ProductClient productClient; public String getProductMsg()&#123; String response = productClient.productMsg(); log.info(&quot;response=&#123;&#125;&quot;,response); return response; &#125;&#125; 业务流程中注意要点 controller方法中如果请求带参数必须使用 @RequestBody 结合@PostMapping 使用谷歌的Gson工具把json字符串转为list加入依赖1234&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt;&lt;/dependency&gt; 1234567//使用谷歌的Gson工具try &#123; orderDetailList = gson.fromJson(orderForm.getItems(),new TypeToken&lt;List&lt;OrderDetail&gt;&gt;()&#123;&#125;.getType());&#125;catch (Exception e)&#123; log.error(&quot;【json转换】错误,string=&#123;&#125;&quot;,orderForm.getItems()); throw new OrderException(ResultEnum.PARAM_ERROR);&#125; 整合接口打通下单流程 查询商品信息（调用商品服务） 计算总价 (遍历购物车的商品，单价*数量，累加 ) 扣库存（调用商品服务） 订单入库 核心业务代码 12345678910111213141516171819202122232425262728293031323334353637383940public OrderDTO cteate(OrderDTO orderDTO) &#123; String orderId = KeyUtil.getUniqueKey(); // 查询商品信息（调用商品服务） List&lt;String&gt; productIdList = orderDTO.getOrderDetailList().stream() .map(OrderDetail::getProductId) .collect(Collectors.toList()); List&lt;ProductInfo&gt; productInfoList = productClient.listForOrder(productIdList); // 计算总价 BigDecimal orderAmount = new BigDecimal(0); for(OrderDetail orderDetail :orderDTO.getOrderDetailList())&#123; for(ProductInfo productInfo : productInfoList)&#123; if(orderDetail.getProductId().equals(productInfo.getProductId()))&#123; //单价*数量 orderAmount = productInfo.getProductPrice() .multiply(new BigDecimal(orderDetail.getProductQuantity())) .add(orderAmount); BeanUtils.copyProperties(productInfo,orderDetail); orderDetail.setOrderId(orderId); orderDetail.setDetailId(KeyUtil.getUniqueKey()); //订单详情入库 orderDetailRepository.save(orderDetail); &#125; &#125; &#125; List&lt;CardDTO&gt;cardDTOList = orderDTO.getOrderDetailList().stream() .map(e -&gt; new CardDTO(e.getProductId(),e.getProductQuantity())) .collect(Collectors.toList()); //TODO 扣库存（调用商品服务） productClient.decreaseStock(cardDTOList); //订单入库 OrderMaster orderMaster = new OrderMaster(); orderDTO.setOrderId(KeyUtil.getUniqueKey()); BeanUtils.copyProperties(orderDTO,orderMaster); orderMaster.setOrderAmount(orderAmount); orderMaster.setOrderStatus(OrderStatusEnum.NEW.getCode()); orderMaster.setPayStatus(PayStatusEnum.WAIT.getCode()); orderMasterRepository.save(orderMaster); return orderDTO; &#125; 项目改成多模块存在问题 不能把自己数据表对应的实体类给暴露出去 同一个对象在多处定义 自己定义自己的接口暴露给外部调用 要拆分成的模块 product-server :所有的业务逻辑 product-client ：对外暴露的接口 获取商品列表、扣库存 product-common :公用的对象 如何打包商品服务的jar包给订单服务调用？mvn -Dmaven.test.skip=true -U clean install (将jar包清理且安装到本地) 如何启动且调用？ 启动商品服务 启动订单服务postman访问接口即可。 同步or异步 通过消息中间件，解耦,服务间的交互变得更加灵活 如果都使用同步服务，开销太大 可以通过消息队列解决同步的问题，使之变成异步 看一下，这个图中的消息中间件的作用。]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java的IO机制]]></title>
    <url>%2F2019%2F11%2F10%2FJava%E7%9A%84IO%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>Java常用类库与技巧</category>
      </categories>
      <tags>
        <tag>IO机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C包的梳理]]></title>
    <url>%2F2019%2F11%2F10%2FJ-U-C%E5%8C%85%E7%9A%84%E6%A2%B3%E7%90%86%2F</url>
    <content type="text"><![CDATA[java.util.concurrent：提供了并发编程的解决方案：CAS 是java.util.concurrent.atomic包的基础AQS 是java.util.concurrent.locks包以及一些常用类比如：Semophore,ReentrantLock类的基础 J.U.C包的分类 线程执行器executor 锁locks 原子变量类atomic 开发工具类tools 并发集合collections 并发工具类 闭锁 CountDownLatch 栅栏 CyclicBarrier 信号量 Semaphore 交换器 ExchangerCountDownLatch：让主线程等待一组事件发生后继续执行 CyclicBarrier:阻塞当前线程，等待其他线程 信号量 Semaphore 交换器 Exchanger collectionsBlockingQueue:提供可阻塞的入队和出队操作主要用于生产者-消费者模式，在多线程场景时生产者线程在队列尾部添加元素，而消费者线程在队列头部消费元素，通过这种方式能够达到将任务的生产和消费进行隔离的目的 由以下七个实现类， 都是线程安全]]></content>
      <categories>
        <category>Java常用类库与技巧</category>
      </categories>
      <tags>
        <tag>J.U.C包的梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap]]></title>
    <url>%2F2019%2F11%2F10%2FConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[Hashtable 早期Java类提供的哈希表的实现 线程安全：涉及到修改Hashtable的方法，使用synchronized修饰 串行化的方式运行，性能较差 如何优化Hashtable? 通过锁细粒度化，将整锁拆解成多个锁进行优化 早期的ConcurrentHashMap：通过分段锁Segment来实现 当前的ConcurrentHashMap:CAS+synchronized使锁更细化 只是锁住每个 table 的首节点，所以只要 Hash 不冲突，就不会产生并发。 使用Collections.synchronizedMap(hashMap);将HashMap包装成线程安全的。 源码分析 出自JUC包 成员变量与HashMap相似；sizeCtl 是 ConcurrentHashMap 特有的成员变量12//用来初始化或扩容的控制位标示量 private transient volatile int sizeCtl; put方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public V put(K key, V value) &#123; return putVal(key, value, false);&#125; final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不能放入为null的key if (key == null || value == null) throw new NullPointerException(); //去计算key的hash值 int hash = spread(key.hashCode()); int binCount = 0; //多数组的元素更新是使用CAS机制，需要不断的去做失败重试 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //数组为空初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //不等于0我们就通过hash值来找到f(头结点),根据定位到的元素检查是否存在 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果没有则尝试使用CAS进行添加，添加失败则break，进入下一次循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //如果被别的线程正在移动，我们就协助其扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; //判断f是否是链表的头结点，fh代表的是头结点的hash值 if (tabAt(tab, i) == f) &#123; //如果是链表的头结点，初始化计数器binCount， 遍历链表。如果存在我们就去更新value，如果不存在就在链表尾部添加新的结点 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; ConcurrentHashMap：put逻辑 判断Node[]数组是否初始化，没有进行初始化操作 通过hash定位数组的索引坐标之后，判断当前下标是否有元素，如果没有则利用CAS进行添加，添加失败进行下次循环 检查内部是否正在扩容，如果扩容，就帮他一块扩容 使用syn锁住当前下标,如果是链表则执行链表插入，如果是树，则进行树的操作 判断链表长度是否大于8，超过8进行树化 ConcurrentHashMap总结：比起Segment，锁拆的更细 首先使用无锁操作CAS插入头结点，失败则循环重试 若头结点已存在，则尝试获取头结点的同步锁，再进行操作 Hashap、Hashtable、ConcurrentHashMap三者的区别 HashMap线程不安全，数组+链表+红黑树 Hashtable线程安全，锁住整个对象，效率低，数组+链表 ConcurrentHashMap线程安全，CAS+同步锁，数组+链表+红黑树 Hashap的key、value均可为null,而其他的两个类均不支持]]></content>
      <categories>
        <category>Java常用类库与技巧</category>
      </categories>
      <tags>
        <tag>Hashtable</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap]]></title>
    <url>%2F2019%2F11%2F10%2FHashMap%2F</url>
    <content type="text"><![CDATA[Map的集合 HashMap(Java8以前)：数组+链表 HashMap的数组长度再没有给他赋任何初始值的时候默认16，一个长度为16的数组中每个元素存储的就是链表的头节点，通过hash(key.hashCOde())%len 函数去取模获得要添加的元素存放的数组的位置 HashMap的hash算法是通过位运算来进行的相比取模运算效率更高 存在极端情况，通过hash散列运算总是得到相同的值，即分配到同一个桶中，会使得某个桶的链表很长 HashMap(Java8以后)：数组+链表+红黑树1.红黑树的算法和实现 HashMap的内部结构解析HashMap相关源码 1transient Node&lt;K,V&gt;[] table; Node的源码 123456789101112static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; HashMap可以看做通过数组Node&lt;K,V&gt;这个table，和链表组成的数据结构。Node是由hash值，键值对，以及指向的下一个节点来组成的； 而数组被分为一个个的bucket，通过hash值决定了键值对在这个数据的寻址，hash值相同的键值对则以链表的形式来存储，而如果链表的大小超过了 TREEIFY_THRESHOLD =8 就会被改造成红黑树。当某bucket上面的元素的总数因为删除而变得低于阈值 UNTREEIFY_THRESHOLD =6 了之后，红黑树又被转成链表以保持更高的性能！ HashMap的构造函数源码 1234567/*** Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity* (16) and the default load factor (0.75).*/public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;根据构造函数可以看出HashMap 中的table数组并没有在开始初始化好，而是赋上了初始值，因为可以推断HashMap是按照lazyLoad去加载 HashMap的 put()方法源码分析加注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //根据源码可以看出如果数组为空就调用resize()方法给它初始化数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //做hash运算，算出键值对在table里面的具体位置，得到的运算还没有元素存储到里面则会直接new一个该键值对的node,放到该位置当中 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果发现同样的位置存在同样的已经存在键值对，且键和传入进来的键一致，则直接替换数组里面的元素 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //当前位置存储的是否是已经树化了之后的节点，如果是树化了的话则按照树的方式尝试存储键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果不是树化了，则按照链表的插入方式往链表后面添加元素，同时判断链表元素的总数，一旦超过TREEIFY_THRESHOLD，则将链表进行树化 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果插入的键位存在于hashMap中则对对应的键位进行值的更新操作 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //而当我们的HashMap的size大于阈值的时候也通用会调用resize()对HashMap进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 个人理解： 根据源码可以看出如果数组为空就给它初始化数组（调用resize()方法），而当我们的HashMap的size大于阈值的时候也通用会调用resize()对HashMap进行扩容,因此resize方法即具备初始化又具备扩容的功能。 put方法逻辑总结 若HashMap未被初始化，则进行初始化操作； 对key求Hash值，依据Hash值计算下标； 若未发生碰撞，则直接放入桶中； 若发生碰撞，则以链表的方式链接到后面； 若链表长度超过阈值，且HashMap匀速超过最低树化容量，则将链表转成红黑树； 若节点已经存在，则用新值替代旧值； 若桶满了（默认容量16*扩容因子0.75），就需要resize(扩容2倍后重排)； HashMap的 get()方法源码分析 12345678910111213141516171819202122232425public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; get方法逻辑总结 使用键对象的hashCode 通过hash算法找到bucket的位置； 找到bucket位置之后调用 key.equals(k) 去找到链表中正确的节点最终找到要找的值，并返回； HashMap如何有效减少碰撞 扰动函数：促使元素位置分布均匀，减少碰撞机率；对于很多元素我们能够通过数组来直接去获取，hash算法内部实现目的是让不同的对象返回不同的hashCode 使用final对象，并采用合适的equals和hashCode()方法:final类建议作为key是利用了其不可变性，如果一个key可以随便修改，那么修改后在hashmap就找不到了；适合String,Integer这样的键 HashMap的 hash()方法源码 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 先获取key的hashCode,再将高位数移动16位，再与原先的数据异或运算如上图：key的hashCode是返回int散列值，如果直接拿这个散列值作为下标去访问hashMap数组的话，考虑到二进制的三十二位int范围 -2147483648到2147483648，只要hash函数映射的均匀一般很难出现碰撞，一个40亿长度的数组内存是放不下的，况且HashMap的最初始数组大小才16，所以直接拿散列值用不现实！ 直接将高半区向右移动16位再跟自己去做异或，可以混合原始hash码的高位和低位以此来加大低位的随机性，混合后后的低位掺杂了高位的特征，从速度功效考虑，也不会有太大的开销。 HashMap的 扩容方法当hashMap无法装载更多的元素时，对象就需要扩大数组的长度；使用一个新的较大的数组来代替老的数组；hashMap的默认负载因子是0.75；当一个hashMap填满了75%的bucket的时候，将会创建原来hashMap大小的两倍的bucket数组来重新调整map的大小，这个过程是 rehashing HashMap扩容问题 多线程环境下，调整大小会存在条件竞争，容易造成死锁 rehashing是一个比较耗时的过程]]></content>
      <categories>
        <category>Java常用类库与技巧</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Collection体系]]></title>
    <url>%2F2019%2F11%2F10%2FCollection%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[优秀的算法和数据结构被封装到了Java的集合框架 数据结构重点： 数组和链表的区别； 链表的操作，如反转，链表环路检测，双向链表，循环链表相关操作 队列，栈的应用 二叉树的遍历方式及其递归和非递归的实现 红黑树的旋转算法重点： 内部排序：如递归排序、交换排序（冒泡、快排）、插入排序、选择排序 外部排序：掌握如何利用有限的内存配合海量的外部存储来处理超大数据集，写不出来有思路 Java集合框架 集合之List和Set]]></content>
      <categories>
        <category>Java常用类库与技巧</category>
      </categories>
      <tags>
        <tag>List</tag>
        <tag>Set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务拆分]]></title>
    <url>%2F2019%2F11%2F08%2F%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[微服务拆分的起点和重点微服务如何拆分： 先明白起点和终点 起点：既有的架构形态（老项目、新项目） 终点：好的架构不是设计出来的，而是进化而来的。进化一直在演进 需要考虑的因素与坚持的原则 不适合用微服务的业务场景 系统中包含很多很多强事务场景的 业务相对稳定，迭代周期长 访问压力不大，可用性要求不高 康威定律：沟通的问题会影响系统的设计 点餐业务服务拆分服务拆分的方法论：&lt;可扩展的艺术&gt; 扩展立方模型 x轴：水平复制，通过副本扩展，将应用程序水平复制，通过负载均衡运行程序的多个完全一样的副本方式，来实现应用程序的伸缩性，提高应用程序的容量和可用度。 Z轴：数据分区，每个服务器负责一个数据子集。每个服务器运行的代码是一样的。 Y轴：功能解耦，将不同职责的模块，分成不同的服务如何拆分功能 单一职责，松耦合、高内聚 ： （每个服务只负责业务功能的一个单独部分。服务之间耦合度低，修改一个服务不用导致另外一个服务跟着修改，高内聚指的是服务内部相关的行为聚集在一个服务内，而不是分散在不同的服务中，需要修改一个行为时，只需要修改一个服务就行） 关注点分离 按职责（给我们的服务进行分类，明显按照业务领域可以划分出来的服务，职责比较单一 按通用性（一些基础组件，与具体的业务无关的可以划分成单独的服务 消息 用户 按粒度级别服务和数据的关系 先考虑拆分业务功能，在考虑拆分业务功能对应的数据 无状态服务 一个数据需要被多个服务共享才能完成一个请求，这个数据就是有状态 把数据迁移到分布式缓存中存储，让业务服务变成无状态计算结点，后端服务能做到按需动态伸缩，在运行时动态增删结点不用考虑缓存同步问题 点餐业务拆分分析 服务拆分的方法论：&lt;可扩展的艺术&gt; 扩展立方模型： x轴：水平复制，通过副本扩展，将应用程序水平复制，通过负载均衡运行程序的多个完全一样的副本方式，来实现应用程序的伸缩性，提高应用程序的容量和可用度。 Z轴：数据分区，每个服务器负责一个数据子集。每个服务器运行的代码是一样的。 Y轴：功能解耦，将不同职责的模块，分成不同的服务 业务流程 开发商品服务和订单服务作为服务注册到 注册中心Eureka Server 每个服务的开发流程大致 连接数据库-&gt;创建所需对象-&gt;dao层-&gt;分析controller中方法的业务流程-&gt;写出需要的service方法-&gt;写controller ,注意每个方法写完后都及时单元测试 返回给前端的数据自定义VO对象 前端请求过来的数据使用form对象封装，controller传给service的数据使用DTO封装 如何拆数据 每个微服务都有单独的数据存储，达到松耦合，其它服务避免访问别的服务的数据库。一个服务的数据，只能通过这个服务提供的api来访问，服务之间都是有隔离的。 依据服务特点选择不同结构的数据库类型。依据功能特点选择合适的数据库。mongodb（前端服务，对事物要求低）、Elasticsearch(ES搜索)、mysql 难点在确定边界]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务注册与发现]]></title>
    <url>%2F2019%2F11%2F08%2F%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[微服务的注册与发现 （Spring Cloud Eureka）： 基于Netflix Eureka做了二次封装 两个组件： Eureka Server(注册中心） Eureka Client(服务注册) Eureka Server作为服务注册功能的服务器，它是服务注册中心，而系统中其他微服务使用Eureka Client客户端，连接到Eureka Server并维持心跳连接，这样就能监控系统中各个微服务是否正常运行 Eureka Server 注册中心Eureka Server的配置 新建项目 Cloud Discovery -&gt; Eureka Server 修改pom文件中spring boot 2.0.0.M3 和 spring cloud Finchley.M2的版本 启动主类EurekaApplication 添加注解 @EnableEurekaServer，表明这个有注册中心的功能 配置文件 12345678910111213141516eureka: client: service-url: # 配置的注册地址 defaultZone: http://localhost:8761/eureka/ # 本身就是注册中心，取消注册 register-with-eureka: false server: #Server端配置，关闭自我保护，开发环境 enable-self-preservation: false# 配置应用的名字spring: application: name: eurekaserver: port: 8761 mvn打包,后台启动 12mvn clean package nohup java -jar target/eureka-0.0.1-SNAPSHOT.jar &gt; /dev/null 2&gt;&amp; Eureka Client的配置 新建项目 Cloud Discovery -&gt; Eureka Client 修改pom文件中spring boot 2.0.0.M3 和 spring cloud Finchley.M2的版本 启动主类 ClientApplication 添加注解 @EnableDiscoveryClient，表明这个有注册中心的功能 配置文件123456789101112eureka: client: service-url: # 配置的注册地址 defaultZone: http://localhost:8761/eureka/ # 自定义连接跳转地址# instance:# hostname: clientName# 配置应用的名字spring: application: name: client EurekaClient的使用 引入依赖 配置上注册中心的地址 在启动的主类上加@EnableDiscoveryClient Eureka 的高可用eureka server实现高可用，可以将他集群，然后互相注册。client端注册所有集群eureka单个server且没有client的时候，自己注册自己，会显示自己，加一个参数register-with-eureka: false会取消显示； 3个server相互注册instances栏也不显示注册的另外的server（client）实例和自己本身，registered-replicas栏里倒是可以看另外的server；改动register-with-eureka: true后，另外两个server实例和自己本身将都会显示。 总结Eureka Server的高可用，通过多个Eureka相互注册实现。 @EnableEurekaServer @EnableEurekaClient 心跳检测，健康检查，负载均衡等功能 Eureka的高可用，生产上建议至少两台以上 分布式系统中，服务注册中心是最重要的部分 分布式下服务注册的地位和原理 服务端发现两种方式： 客户端发现：Eureka 服务端发现：Nginx,Zookeeper,Kubernetes 微服务的特点：异构 不同语言 不同类型的数据库 SpringCloud的调用方式：REST，其他语言可实现Eureka的客户端]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
      <tags>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务介绍]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[什么是微服务?微服务是一种架构风格，不是组件不是框架。 一系列微小的服务共同组成 跑在自己的进程 每个服务为独立的业务开发 独立部署 分布式的管理 什么是分布式？旨在支持应用程序和服务的开发，可以利用物理架构由多个自治的处理元素，不共享内存，但通过网络发送消息合作。 单体架构的优点：容易测试（本地启动完整的测试，不需要外部依赖）容易部署（直接打成war包，放在tomcat下面就可以了） 单体架构的缺点：开发效率低（容易提交代码的时候造成冲突）代码维护难（尤其是新人来的时候业务代码写在一块，不知从何下手）部署不够灵活（任何小修改都要重新构建，构建时间特别长）稳定性不够 （任何一个小问题容易让整个系统挂掉）扩展性不够（无法满足高并发下的业务需求） 微服务架构的基础框架或组件： 服务注册发现 服务网关（路由、监控、容器、日志、授权、反爬虫） 后端通用服务（请求时将地址信息放在服务注册表中） 前端服务（通过查询注册表发现并调用后端服务，主要是聚合后端服务和暴露外部接口） Spring Cloud 是什么？ Spring Cloud 是一个开发工具集，包含多个子项目主要是基于对 Netflix 开源组件的进一步封装 继承了了Spring Boot 的开发便利，简化了分布式开发 不仅需要掌握如何使用，更要理解分布式架构的特点]]></content>
      <categories>
        <category>微服务实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java异常]]></title>
    <url>%2F2019%2F11%2F07%2FJava%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[异常机制主要回答了三个问题 what：异常类型回答了什么被抛出 where：异常堆栈跟踪回答了在哪抛出 why：异常信息回答了为什么被抛出 Java的异常体系 RuntimeException：不可预知的，程序应当自行避免（NullPointerException，IndexOutOfBoundsException ….. ） 非RuntimeExceptin：可预知的，从编译器校验的异常（IOException，SqlException…）任 error和exceptin的区别从概念角度解析Java的异常处理机制 error：程序无法处理的系统错误，编译器不做检查（StackOverFlowError,OutOfMemoryError） exception：程序可以处理的异常，捕获后可能恢复总结：前者是程序无法处理的错误，后者是可以处理的异常 从责任角度看 Error属于jvm需要承担的责任 RuntimeException是程序应该承当的责任 Checked Exception可检查异常是Java编译器应该负担的责 12345678910111213public class ErrorAndException&#123; private void throwError()&#123; throw new StackOverflowError(); &#125; private void throwRuntimeException()&#123; throw new RuntimeExeption &#125; private void throwCheckedException () throws FileNotFoundExcpetion&#123; //此处编译器会报错，checkedException是必须要追踪处理的异常，要么此处加try()catch&#123;&#125;在catch中增加处理逻辑，理解这种Exception的成因结合实际业务去处理 //最好通过throw方式把异常抛出去，让调用模块去处理 throw new FileNotFoundExcpetion(); &#125;&#125; 常见Error以及ExceptionRuntimeException NullPointerException-空指针异常 ClassCastException-类型强制转换异常 IllegalArguementException-传递非法参数异常 IndexOutOfBoundsException-下标越界异常 NumberFormatException-数字格式异常非RuntimeException ClassNotFoundException -找不到指定class的异常 IOExceptin-IO操作异常 Error NotClassDefFoundError-找不到class定义的异常： NotClassDefFondError的成因： 类依赖的class或者jar不存在 类文件存在，但是存在不同域中：对应的class在Java的classpath中不可用，又或者有多个不同的类加载器重复加载了同一个class 大小写问题，javac编译的时候无视大小写，很肯能编译出来的class文件就与想要的不一样 StackOverflowError-深递归导致栈被耗尽而抛出的异常 OutOfMemeryError-内存溢出异常 Java的异常处理机制 抛出异常：创建异常对象，交由运行时系统处理 捕获异常：寻找合适的异常处理器处理异常，否则终止运行 Java异常的处理原则 具体明确：抛出的异常应该能通过异常类名和message准确说明异常的类型和产出异常的愿意； 提早抛出：应尽可能早的发现并抛出异常，便于精确定位问题； 延迟捕获异常的捕获和处理应可能延迟，让掌握更多信息的作用域来处理 高效主流的异常处理框架 设计一个通用的继承自RuntimeExceptin的异常来统一处理 其余异常都统一转译为上述异常AppException 在catch之后，抛出上述异常的子类，并提供足以定位的信息 由前端接受AppExcception做统一处理 try-catch的性能Java异常处理消耗性能的地方 try-catch块影响JVM的优化 异常对象实例需要保存栈快照等信息，开销较大]]></content>
      <categories>
        <category>Java常用类库与技巧</category>
      </categories>
      <tags>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程与并发-原理]]></title>
    <url>%2F2019%2F11%2F06%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91-%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[synchronized线程安全问题的主要诱因 存在共享数据（也称临界资源） 存在多条线程共同操作这些共享数据 解决问题的根本方法 同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作 互斥锁的特性 互斥性：即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程的协调机制，这样在同一时间只有一个线程对需要同步的代码块（复合操作）进行访问。互斥性也成为操作的原子性。 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值），否则另一个线程可能是在本地缓存的某个副本上继续操作，从而引起不一致 synchronized锁的不是代码，锁的是对象 根据获取的锁的分类：获取对象锁和获取类锁获取对象锁的两种用法 同步代码块(synchronized(this)，synchronized(类实例对象))，锁是小括号()中的实例对象 同步非静态方法(synchronized method)，锁的是当前对象的实例对象123456789101112131415/** *方法中有 synchronized(this|object) &#123;&#125; 同步代码块 */private void syncObjectBlock1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectBlock1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); synchronized (this) &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectBlock1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectBlock1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 12345678910111213/** *synchronized 修饰非静态方法 */private synchronized void syncObjectMethod1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectMethod1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectMethod1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncObjectMethod1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 获取类锁的两种用法 同步代码块（synchronized（类.class），锁是小括号（）中的类对象（Class对象） 同步静态方法（synchronized static method），锁是当前对象的类对象（Class对象） 123456789101112private void syncClassBlock1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassBlock1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); synchronized (SyncThread.class) &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassBlock1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncClassBlock1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 1234567891011//同步静态方法private synchronized static void syncClassMethod1() &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassMethod1: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); try &#123; System.out.println(Thread.currentThread().getName() + &quot;_SyncClassMethod1_Start: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;_SyncClassMethod1_End: &quot; + new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 类锁和对象锁的总结 有线程访问对象的同步代码块时，另外的线程可以访问该对象的非同步代码块； 若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个访问对象的同步代码块的线程会被阻塞； 若锁住的是同一个对象，一个线程在访问对象的同步方法时，另一个访问对象同步方法的线程会被阻塞； 若锁住的是同一个对象，一个线程在访问对象的同步代码块时，另一个访问对象同步方法的线程会被阻塞，反之亦然 同一个类的不同对象的对象锁互不干扰 类锁由于也是一种特殊的对象锁，因此表现和上述1，2，3，4一致，而由于一个类只有一把对象锁，所以同一个类的不同对象使用类锁将会是同步的 类锁和对象锁互不干扰 synchronized底层实现原理实现synchronized的基础 Java对象头 Monitor对象在内存中的布局 对象头：Mark Work + Class Metadata Address 实例数据 对齐填充 对象头的结构：Mark Work：默认存储对象的hashCode,分代年龄，锁类型，锁标志位等信息 非固定的数据结构，以便效率Class Metadata Address：类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的数据 重量级锁也就是通常说的synchronizd的对象锁，锁的标识位是10，指针指向的是Monitor对象的起始地址 Monitor：在java的设计中每一个对象天生自带一把看不见的锁它叫做内部锁，或者Monitor锁，Monitor也叫做管程或者监视器锁，可以把它理解为一个同步工具，也可以描述为一种同步机制。通常他被描述为一个对象。每个对象都存在着一个Monitor与之关联 ObjectMonitor源码 Monitor是由ObjectMonitor实现的，位于jvm源码即ObjectMonitor.hpp文件里面，它是通过c++来实现的，EntryList(锁池)，waitSet（等待池）。他们就是用来保存Objectwaiter的对象列表，每个对象锁的线程都会被封装成Objectwaiter来保存到里面，owner是指向指向持有ObjectMonitor的线程，当多个线程同时访问同一段同步代码的时候，首先会进如到EntryList集合里面，当线程获取到对象的Monitor后进入_Owner区域并把monitor中的_owner变量设置为当前线程，同时monitor中的计数器_count加1。即获得对象锁。若持有monitor的线程调用wait()方法，将释放当前持有的monitor，_owner变量恢复为null，_count自减1，同时该线程进入_WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。monitor对象存在于每个java对象的对象头中，monitor也是class,其实例会存储在堆中,MarkWord中保存的是它的指针https://blog.csdn.net/uftjtt/article/details/80250182 有类似的讲解 在上面的源码我们可以看到ObjectMonitor中有几个关键属性： _owner：指向持有ObjectMonitor对象的线程 _WaitSet：存放处于wait状态的线程队列 _EntryList：存放处于等待锁block状态的线程队列 重入:从互斥的设计上来说，当一个线程师徒操作一个由其他线程持有的对象锁临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入 为什么会对synchronized嗤之以鼻 早起版本中，synchronized属于重量级锁，依赖于Mutex Lock实现 线程之间的切换需要从用户态转换为内核态，开销较大 Java6以后，synchronized性能得到了很大的提升Adaptice Spining,Lock Eliminate,Lock Coarsening,Lightweight Locking ,Biased Locking 自旋锁与自适应自旋锁自旋锁 许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得 通过让线程执行忙循环等待锁的释放，不让出CPU 缺点：若锁被其他线程长时间占用，会带来许多性能上的开销 自适应自旋锁 自旋的次数不再固定 由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定（如果在同一个锁对象上自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，jvm会认位该锁自旋获取到锁的可能性很大，会自动增加等待时间，相反，如果对于某个锁 ，自旋很少成功获取到锁，那在以后要获取这个锁时，可能会省略掉自旋过程，以避免浪费处理器资源） 锁消除更彻底的优化：JIT编译时，对运行上下文进行扫描，去除不可能存在竞争的锁 123456public void add(String str1, String str2) &#123; //StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用 //因此sb属于不可能共享的资源,JVM会自动消除内部的锁 StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2);&#125; 锁粗化另一种极端：通过扩大加锁的范围，避免反复加锁和解锁 12345678public static String copyString100Times(String target)&#123; int i = 0; StringBuffer sb = new StringBuffer(); while (i&lt;100)&#123; sb.append(target); &#125; return sb.toString();&#125; synchronized的四种状态： 无锁、偏向锁、轻量级锁、重量级锁 锁膨胀方向：无锁-&gt; 偏向锁-&gt; 轻量级锁-&gt; 重量级锁 偏向锁:减少同一线程获取锁的代价 大多数情况下， 锁不存在多线程竞争，总是由同一线程多次获得核心思想：如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变成了偏向锁结构，当该线程再次请求锁时，无需再做任何同步操作，即获取锁的过程只需要检查Mark Word的锁标记为偏向锁，以及当前线程Id等于Mark Word的ThreadID即可，这样就省去了大量有关锁申请的操作不适用于锁竞争比较激烈的多线程场合 轻量级锁轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁会升级为轻量级锁适应的场景：线程交替执行同步块若存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁 锁的内存语义 偏向锁、轻量级锁、重量级锁的汇总 synchronized和ReentrantLock的区别ReentranLock(再入锁) 位于java.util.concurrent.locks(JUC)包 和CountDownLatch、Futask、Semaphore一样基于AQS实现 能够实现不synchronized更细粒度的控制，如控制fairness(公平性) 调用lock()之后，必须调用unlock()释放锁 性能未必比synchronized高，并且也是可重入的 AbstractQueuedSynchronizerAQS：是构建锁 或 其他同步组件 的基础框架，是J.U.C包的核心。一般使用方式为继承包含： volatile 数组成员表征状态state 一个FIFO等待线程队列 Node head和tail acquire()获取资源的独占权 (与同步相关的) release()释放对资源的独占权 (与同步相关的) 其他基于CAS的基础操作方法 ReentrantLock公平锁的设置1ReentrantLock fairLock = new ReentrantLock(true); 参数为true时，倾向于将锁赋予等待时间最久的线程 公平锁：获取锁的顺序按先后调用lock方法的顺序依次获取锁（慎用） 非公平锁：抢占的顺序不一定，看运气 synchronized是非公平锁，通用场景中公平性未必有想象的那么重要，Java默认的调度策略很少会导致饥饿情况的发生；若要保证公平性则会引入额外的开销，自然会导致一定的吞吐量下降，当程序确实有公平性需要的时候，才有必要指定公平 公平锁和非公平锁的例子 12345678910111213141516171819202122232425public class ReentrantLockDemo implements Runnable&#123; private static ReentrantLock lock = new ReentrantLock(true); @Override public void run()&#123; while (true)&#123; try&#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot; get lock&quot;); Thread.sleep(1000); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) &#123; ReentrantLockDemo rtld = new ReentrantLockDemo(); Thread thread1 = new Thread(rtld); Thread thread2 = new Thread(rtld); thread1.start(); thread2.start(); &#125;&#125; 公平锁和非公平锁的性能差异，差别在哪里？ReentrantLock的内部类Sync继承了AQS，分为公平锁FairSync和非公平锁NonfairSync 非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。 公平锁要维护一个队列，线程获取锁的顺序和调用lock的顺序一样 ，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在 wait，如果有自己要挂起，加到队列后面，然后唤醒队列最前面的线程。这种情况下相比较非公平锁多了一次挂起和唤醒 因此线程切换的开销，其实就是非公平锁效率高于公平锁的原因，因为非公平锁减少了线程挂起的几率，后来的线程有一定几率逃离被挂起的开销。 ReentrantLock将锁对象化 判断是否有线程，或者某个特定线程，在排队等待获取锁 带超时的获取锁的尝试 感知有没有成功获取锁 将wait\notify\notifyall对象化java.util.concurrent.locks.Condition synchronized和ReentrantLock的区别 synchronized是关键字，ReentrantLock是类 ReentrantLock可以对获取锁的等待时间进行设置，避免死锁 ReentrantLock可以获取各种锁的信息 ReentrantLock可以灵活地实现多路通知 机制：sync操作Mark Work,lock调用Unsafe类的park方法 JMM的内存可见性 Java内存模型JMM （Java Memory Model,简称JMM）是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（实例字段、静态字段、构成数组对象的元素）的访问方式 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方称为栈空间），用于存储线程私有的数据，而Java内存模型中规定所有变量都存储在主内存中，主内存是共享内存区域所有线程都可以访问，但线程对变量的操作（读取、赋值等）必须在工作内存中进行。 首先将变量从主内存copy到自己的工作内存空间当中，然后对变量进行操作，操作完成后，再将变量写回主内存，不能直接操作主内存中的变量； 工作内存中存储着主内存中变量的副本拷贝，工作内存是每个线程的私有区域，因此不同的线程间无法访问对方的工作内存，线程间的通信传值必须通过主内存完成 JMM中的主内存 存储Java实例对象 包括成员变量、类变量、常量、静态变量等 属于数据共享的区域，多线程并发操作时会引发线程安全问题 JMM中的工作内存 存储当前方法的所有本地变量信息，本地变量对其他线程不可见 字节码行号指示器、Native方法信息 属于线程私有数据区域，不存在线程安全问题 JMM与Java内存区域划分是不同的层次概念 JMM描述的是一组规则，围绕原子性，有序性，可见性展开 相似点：存在共享区域和私有区域 主内存与工作内存的数据存储类型以及操作方式归纳 方法里的基本数据类型本地变量将直接存储在工作内存的栈帧结构中 引用类型的本地变量：引用存储在工作内存中，实例存储在主内存中 成员变量，static变量、类信息均会被存储在主内存中 主内存共享的方式是线程各拷贝一份数据到工作内存，操作完成后刷新到主内存中 JMM如何解决可见性问题指令重排序需要满足的条件 在单线程环境下不能改变程序运行的结果 存在数据依赖关系的不允许重排序 无法通过happends-before原则推导出来的，才能进行指令的重排序 A操作的结果需要对B操作可见，则A与B存在happends-before关系是判断数据是否存在竞争，线程是否安全的主要依据；依靠这个原则我们便能解决在并发环境下两个操作之间存在冲突的问题。 12i = 1；//线程A执行j = i; //线程B执行 happends-before的八大原则 单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。 volatile的happen-before原则：对一个volatile变量的写操作happen-before对此变量的任意操作(当然也包括写操作了)。 happen-before的传递性原则：如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。 线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。 线程中断的happen-before原则：对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的代码。 线程终结的happen-before原则：线程中的所有操作都happen-before线程的终止检测。 对象创建的happen-before原则：一个对象的初始化完成先于他的finalize方法调用 happends-before的概念 如果两个操作不满足上述任意一个happends-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序 如果操作A happends-before操作B,那么操作A在内存上所做的操作对操作B都是可见的 1234567private int value = 0public void write(int input)&#123; value = input;&#125;public int read()&#123; return value;&#125; 假设线程A执行write方法，线程B执行read方法，此代码块块不满足happends-before的八大原则，所以这段代码不是线程安全的；解决办法： 加入synchronized锁 对value加入volatile修饰符即可 volatile:JVM提供的轻量级同步机制 保证被volatile修饰的共享变量对所有线程总是可见的 禁止被指令重排序优化 volatile的可见性 1234567public class VolatileViasibility&#123; public static volatile int value =0; public static void increase()&#123; value++; &#125;&#125; 此段代码中 value变量的任何变化都会反映到线程中，如果多个线程同时调用increase()会出现线程安全问题，因为value++操作不具备原子性（先读再写两步操作） 解决办法：incarease()使用synchronized修饰保证线程安全，synchronized解决的是执行控制的问题，阻止其他线程获取当前对象的监控锁，当前被synchronized修饰的代码块无法被其他线程访问 代码修改后： 1234567public class VolatileViasibility&#123; public static int value =0; public synchronized static void increase()&#123; value++; &#125;&#125; synchronized 会创建一个内存屏障，保证所有cpu结果都会刷到主存中，从而保证操作的内存可见性。 另外一种使volatile达到线程安全的场景 12345678910111213//对shutdown值的修改属于原子性操作public class VolatileSage( volatile boolean shutdown; public void close()&#123; shutdown=true; &#125; public void doWork()&#123; while(!shutdown)&#123; System.out.println(&quot;sage...&quot;); &#125; &#125;) volatile变量为何立即可见？ 当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量刷新到主内存中； 当读取一个volatile变量时，JMM会把该线程对应的工作内存置为无效 volatile如何禁止重排优化 通过插入内存屏障指令在内存屏障指令执行重排序优化 强制刷出各种cpu的缓存数据，因此任何cpu上的线程都能读取到这些数据的最新版本 内存屏障（Memory Barrier）1：保证特定操作的执行顺序2：保证某些变量的内存可见性 单例的双重检测实现123456789101112131415161718192021public class Singleton&#123; //禁止指令重排优化 private volatile static Singleton instance; private Singleton()&#123;&#125; public static Singleton getIntance()&#123; //第一次检测 if(instance==null)&#123; //同步 synchronized(Singleton.class)&#123; if (instance == null)&#123; //多线程环境下可能会出现问题的地方 instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 以上代码如果 intance不加volatile修饰会出现线程安全问题；某一个线程在执行到第一次检测时，读到的instance不为空时，instance的引用对象可能还没完全初始化，因为instance = new Singleton();分为以下三步完成 123memory = allocarte();//1.分配对象内存空间intance(memery); //2.初始化对象instance = memory;//3.设置instance指向刚分配的内存地址，此时instance!=null 如果发生了重排序 123memory = allocarte();//1.分配对象内存空间instance = memory;//3.设置instance指向刚分配的内存地址，此时候instance!=null,但是对象还没有初始化完成intance(memery); //2.初始化对象 volatile和synchronized的区别 volatile本质是在告诉JVM当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住知道该线程完成变量操作为止 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法和类级别 volatile仅能实现变量的修改可见性，不能保证修改的原子性；而synchronized则可以脑正变量修改的可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞 volatile标记的变量不会被编译器优化；synchronnized标记的变量可以被编译器优化 CAS(Compare and Swap) CAS思想：包含三个操作数——内存位置(V)、预期原值(A)和新值(B);执行CAS操作的时候将内存位置的值与预期原值进行比较，如果相匹配则将该位置的值更新成新值,否则处理器不做任何操作 一种高效实现线程安全性的方法 支持原子更新操作，适用于计算器，序列发生器等场景 属于乐观锁机制，号称 lock-free CAS操作失败时由于发者决定是继续尝试，还是执行别的操作 synchronized这种独占锁，属于悲观锁，悲观锁始终假定会发生并发冲突。因此会屏蔽一切可能违反数据完整性的操作，除此之外还有乐观锁。它假设不会发生并发冲突，因此只在提交操作时检查是否违反数据完整性，如果提交失败则会进行重试。 CAS多数情况下对开发者来说是透明的 J.U.C的atomic包提供了常用的原子性数据类型以及引用、数据等相关原子类型和更新操作工具，是很多线程安全程序的首选 Unsafe类虽然提供CAS服务，但因能够操纵任意内存地址读写而有隐患 Java9以后，可以使用Variable Handle API来代替Unsafe CAS存在的问题 若循环时间长，则开销很大 只能保证一个共享变量的原子操作 ABA问题：一个线程读到的值为A 进行compare的时候 也是A 不能说这个变量就没被改变过 可能是另外的线程对这个变量进行了改变 然后又改回了A 可以用AtomicStampedReferrence来解决 原理是会给当前结果一个版本号 compare的时候会比对这个版本号是否一样所以CAS适用于计数操作 Java线程池前言：在web开发中，服务器需要接受并处理请求，所以会为一个请求来分配一个线程进行处理，如果并发的请求数量非常多，但每个线程执行的时间很短，这样就会频繁的创建和销毁线程，如此一来会大大降低系统的效率，可能出现服务器在为每个请求创建新线程和销毁线程上花费的时间和消耗的系统资源要比处理实际的用户请求的时间和资源更多。 利用Executors创建不同的线程池满足不同场景的需求位于JUC包下Executor.java new FixedThreadPool(int nThreads):指定工作线程数量的线程池 newCachedThreadPool()处理大量短时间工作任务的线程池 试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程 如果线程闲置的时候超过阈值，则会被终止并移出缓存 系统长时间闲置的时候，不会消耗什么资源 newSingleThreadExecutor()：创建唯一的工作者线程来执行任务，如果线程异常结束，会有另一个线程取代它 newSingleThreadScheduledExecutor()与newScheduledThreadPool(int corePoolSize)定时或周期性的工作调度，两者区别在于单一工作线程还是多个线程 newWorkStealingPool()内部会构建ForkJoinPool,利用working-stealing算法，并行地处理任务，不保证处理顺序 Fork/Join框架：把大任务分割成若干小任务并行执行，最终汇总每个小任务结果后得到大任务结果的框架 Work-Stealing算法：某个线程从其他队列里窃取任务来执行 为什么要使用线程池? 降低资源消耗：通过重复利用已经创建的线程降低线程创建和销毁造成的消耗 提高线程的可管理性，线程是稀缺资源，不加以控制会消耗系统资源还会降低系统的稳定性，使用线程池可以进行统一的分配、调优和监控 Executor框架 J.U.C的三个Executor接口 Executor:运行新任务的简单接口，将任务提交和任务执行细节解耦 123456//直接启动线程Thread t = new Thread();t.start();//交给executeThread t = new Thread();execute.execute(t); ExecutorService:具备管理执行器和任务生命周期的方法，提交任务机制更完善例如，其中submit方法传入了Callable,弥补了Runnable无法返回结果的短板，因此较Executor提供了更加完善的提交机制 1&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); ScheduledExecutorService:扩展了ExecutorService，同时支持Future和定期执行任务 Java 线程池 ThreadPoolExecutor 线程池会有一个工作队列WorkQueue接客，存储用户提交的各个任务 队列接到任务后就会排队交给线程池 即工作线程的集合WorkerThread，该集合需要在运行的过程中管理线程的创建和销毁。线程池的线程被抽象为Worker静态内部类，ThreadPool其实维护的就是一组Worker对象。 ThreadPoolExecutor的构造函数： corePoolSize:核心线程数量； maximumPoolSize:线程不够用的时候能够创建最大线程数 workQueue:任务等待队列：当任务提交时如果线程池中的线程数量&gt;=corePoolSize的时候，把该任务封装成一个worker对象放入到等待队列中； keepAliveTime:线程池允许线程维护的空闲时间； threadFactory:创建新线程，默认使用的是Executors.defaultThreadFactory() handler:线程池的饱和策略： AborPolicy:直接抛出异常，这是默认策略； CallerRUnsPolicy:用调用者所在的线程来执行任务； DiscardOldersPolicy:丢弃队列中靠最前的任务，并执行当前任务； DiscardPolicy:直接丢弃任务； 实现RejectedExecutionHander接口的自定义hander 新任务提交execute执行后的判断 如果运行的线程少于 corePoolSize,则创建新线程来处理任务，即使线程池中的其他线程是空闲的； 如果线程池中的线程数量大于等于 corePoolSize切小于maximumPoolSize,则只有当workQueue满时才创建新的线程去处理任务； 如果设置的corePoolSize 和 maximumPoolSize相同，则创建线程池的大小是固定的，这使如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理; 如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务； 线程池的状态 RUNNING:能接受新提交的任务，并且也能处理阻塞队列中的任务 SHUTDOWN:不再接受新提交的任务，但可以处理存量任务 STOP:不再接受新提交的任务，也不处理存量任务 TIDYING:所有的任务都已经终止 TERMINATED:terminated()方法执行完后进入该状态 状态转换图 shutdown 会关闭提交任务到队列 但是队列中的任务还是会执行完 shutsownnow 会关闭提交任务到队列 且 不会执行队列中的任务 并且正在执行任务的线程也会被interrupt 工作线程的生命周期 线程池的大小如何选定 CPU密集型：线程数=按照核数或者核数+1设定 I/0密集型：线程数=CPU核数*(1+平均等待时间/平均工作时间)]]></content>
      <categories>
        <category>Java多线程与并发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java框架-Spring]]></title>
    <url>%2F2019%2F11%2F05%2FJava%E6%A1%86%E6%9E%B6-Spring%2F</url>
    <content type="text"><![CDATA[此篇文章帮助自己 从Spring 的源码角度了解Spring的原理 IOC原理IOC（Inversion of Control）：控制反转；Spring Core最核心部分；IOC是一种思想。 实现手段：依赖注入（Dependency Injection）把底层类作为参数传递给上层类，实现上层对下层的“控制” 依赖注入的方式 Setter Setter注入 Interface 接口注入 Constructor 构造器注入 Annotation 注解注入 依赖倒置原则、IOC、DI、IOC容器的关系 依赖倒置原则是一种思想，高层模块不应该依赖底层模块； 有了依赖倒置原则才有了IOC的思路； 实现IOC的思路又需要依赖注入的支撑； Spring的框架基于IOC提出了容器的概念，对于IOC来说最重要的就是容器了，容器管理着bean的生命周期，控制着bean的依赖注入。 IOC容器的优势 避免在各处使用new来创建类，并且可以做到统一维护 创建实例的时候不需要了解其中的细节当使用的时候，IOC容器在内部已经完成对象，调用者只需要调用即可！如图蓝色部分全部是由IOC容器完成！ 因为采用了依赖注入在初始化的过程中就不可避免的写大量的new,这里IOC容器就解决了这个问题，这个容器可以自动对代码初始化，你需要维护一个configuration,可以是xml或者可以是一段代码，而不用每次初始化一个行李箱，写一大堆的初始化代码 IOC容器可以隐藏具体创建实例的细节，上图中蓝色部分就像一个工厂，我们只需要向工厂请求一个Luggage实例，然后它就会按照config创建一个Luggage实例，我们不用管Luggage实例是怎么一步一步创建的；实例项目中有些Service是很多年以前写的，有几百个类作为它的底层，假设我们新写了一个API需要实例化这个service,总不可能回头去搞清楚这几百个类的构造函数吧；IOC Container就很完美的解决了这类问题；因为这个架构在要求你写class的时候需要编写响应的config文件，所以你要初始化很久以前的service的时候呢前人都已经写好了config文件了，你直接在用的地方注入这个service就可以了，这大大增加了项目的可维护性降低开发难度 IOC的应用Bean生成的简要步骤 Spring启动时读取应用程序提供的Bean配置信息，并在Spring容器中生成一份相应的Bean注册表。 根据生成的Bean注册表通过反射机制实例化Bean，并装配好Bean之间的依赖关系，为上层提供准备就绪的运行环境。Spring提供一个配置文件描述bean和bean之间的依赖关系，利用Java语言的反射功能实例化bean,并建立bean之间的依赖关系 将生成的Bean实例对象放入Spring容器中。 Spring IOC支持的功能： 依赖注入 依赖检查 自动装配 支持集合 指定初始化方法和销毁方法 支持回调方法 Spring IOC容器的核心接口BeanDefinition 主要是用来描述Bean的定义，Spring容器在启动的时候会将xml或者注解里的bean的定义解析成内部的BeanDefinition BeanDefinitionRegistry 提供向IOC容器注册BeanDefinition对象的方法 ； BeanDefinitionRegistry接口提供了 registerBeanDefinition 用来将我们的BeanDefinition注册到BeanFactory 接口的实现类 DefaultListableBeanFactory中的 beanDefinitionMap里，Spring将bean的定义解析成BeanDefinition之后会通过BeanDefinitionRegistry 以BeanName 为key,BeanDefinition为value存储到beanDefinitionMap里，同时还将BeanName存入到beanDefinitionNames里以便后续Bean的实例化 相关源码： 123public interface BeanDefinitionRegistry extends AliasRegistry &#123; void registerBeanDefinition(String var1, BeanDefinition var2) throws BeanDefinitionStoreException;&#125; 1234public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap(256); private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList(256);&#125; BeanFactory：Spring框架最核心的接口 提供IOC的配置机制 包含Bean的各种定义，便于实例化Bean 建立Bean之间的依赖关系 Bean生命周期的控制 ApplicationContext（继承多个接口） 继承BeanFactory:能够管理、装配Bean 继承ResourcePatternResolver:能够加载资源文件 继承MessageSource:能够实现国际化功能 继承ApplicationEventPublisher:能够注册监听器，实现监听机制 BeanFactory和ApplicationContext有什么区别？BeanFactory是Spring框架的基础设施，面向Spring,ApplicationContext面向使用Spring框架的开发者BeanFactory采用了工厂设计模式，负责读取bean配置文档，管理bean的加载，实例化，维护bean之间的依赖关系，负责bean的声明周期。而ApplicationContext除了提供上述BeanFactory所能提供的功能之外，还提供了更完整的框架功能：国际化支持、aop、事务等。同时BeanFactory在解析配置文件时并不会初始化对象,只有在使用对象getBean()才会对该对象进行初始化，而ApplicationContext在解析配置文件时对配置文件中的所有对象都初始化了,getBean()方法只是获取对象的过程。因此我们一般在使用的时候尽量使用ApplicationContext。 Spring中几个重要方法refresh 方法Spring容器在创建好了之后会调用refresh()方法SpringApplication.class 中 refresh的源码 1234protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext)applicationContext).refresh();｝ AbstractApplicationContext.class 123456789101112131415161718192021222324252627282930313233343536373839404142public void refresh() throws BeansException, IllegalStateException &#123; Object var1 = this.startupShutdownMonitor; synchronized(this.startupShutdownMonitor) &#123; //设置Spring容器的启动时间，开启活跃状态，初始化属性与信息，验证环境信息里面必须存在的属性 this.prepareRefresh(); //获取beanFactory ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); //设置beanFactory this.prepareBeanFactory(beanFactory); try &#123; this.postProcessBeanFactory(beanFactory); // 处理bean标签扫描bean文件，解析成一个个的bean this.invokeBeanFactoryPostProcessors(beanFactory); //bean的后置处理器 this.registerBeanPostProcessors(beanFactory); //初始化一些国际化相关的属性 this.initMessageSource(); //初始化事件的广播器，用于事件发布 this.initApplicationEventMulticaster(); //模板方法，方法体为空，不同的Spring容器去重写 this.onRefresh(); //注册监听器 this.registerListeners(); //实例化BeanFactory中已经被注册未被实例化的所有实例 this.finishBeanFactoryInitialization(beanFactory); //初始化生命周期管理器 this.finishRefresh(); &#125; catch (BeansException var9) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt: &quot; + var9); &#125; this.destroyBeans(); this.cancelRefresh(var9); throw var9; &#125; finally &#123; this.resetCommonCaches(); &#125; &#125; &#125; 为IOC容器以及Bean的生命周期管理提供条件 刷新Spring上下文信息，定义Spring上下文加载流程 getBean 方法通过AbstractBeanFactoryFactory.class 实现可以按类型获取bean的，也有按名称获取bean的getBean方法的代码逻辑 转换beanName 从工厂或者缓存中加载实例 实例化Bean 检测parentBeanFactory 检查初始化Bean的相关的依赖 创建Bean 常见问题1.Spring的五个作用域 singleton:Spring的默认作用域，容器里拥有唯一的Bean实例 prototype:针对每个getBean请求，容器都会创建一个Bean实例 request:为每个Httpp请求创建一个Bean实例 session：会为每个session创建一个Bean实例 globlaSession:会为每个全局Http Session创建一个Bean实例，该作用域仅对Portlet有效 2.SpringBean的生命周期 创建过程 销毁过程 若实现了DisposableBean接口，则会调用destroy方法 若配置了destry-method属性，则会调用其配置的销毁方法 bean如何装载到IOC容器中和依赖注入的用法第一种方式： 手动装配bean,简单粗暴，但是如果bean多的话是一件非常痛苦的事情 创建一个class Person 12345public class person&#123; private Long id; private String name; //get,set省略&#125; 定义一个Java的配置文件 ApplicationConfig,主要作用是高速IOC容器如何装配这个bean 12345678910@Configuretionpublic class ApplicationConfig&#123; @Bean(name=&quot;person&quot;) public Person initPerson()&#123; Person user = new Person(); user.setId(1L); user.setName(&quot;jack&quot;); return user; &#125;&#125; 通过ApplicationContext来获取bean实例1234ApplicationContext ctx = SpringApplication.run(ProductApplication.class, args);Person person = ctx.getBean(&quot;Peroson.class&quot;);//通过类型来获取System.out.println(&quot;Name is &quot;+person.getName);person.call(); 第二种方式： 以SpringBoot方式扫描装配Bean到IOC容器中 对Person进行改动 加入@Component 注解，表明哪个类要被扫描进入到SpringIOC容器中 12345678@Component(&quot;Person&quot;)public class person&#123; @Value(&quot;1&quot;) private Long id; @Value(&quot;Jack&quot;) private String name; //get,set省略&#125; 实现依赖注入 新建 Pet.class 123public inteface Pet&#123; void move();&#125; 创建Pet实现类 Dog 1234567@Componentpublic class Dog implements Pet&#123; @Override public void move()&#123; System.out.println(&quot;running&quot;); &#125;&#125; Person中注入 12345678910111213@Component(&quot;Person&quot;)public class person&#123; @Value(&quot;1&quot;) private Long id; @Value(&quot;Jack&quot;) private String name; @Autowired private Pet pet; public void call()&#123; pet.move(); &#125;&#125; 如果新增一个再增加一个Pet的实现类 Bird ,person.call()调用会报错，不知道该调用哪个实现方法，可以加@Primary 或 @Qualifier 告诉Spring该选择谁 12345678@Component@Primarypublic class Bird implements Pet&#123; @Override public void move()&#123; System.out.println(&quot;flying&quot;); &#125;&#125; 再次调用person.call() 就会正常输出 flying Spring AOP关注点分离：不同的问题交给不同的部分去解决 面向切面变成AOP正是此种技术的体现 通用代码的实现，对应的就是所谓的切面（Aspect） 业务功能代码和切面代码分开后，架构将变得高内聚低耦合 确保功能的完整性：切面最终需要被合并到业务中（Weave） AOP的三种织入方式 编译时织入：需要特殊的Java编译器，AspectJ 类加载时织入：需要特殊的Java编译器，如AspectJ和AspectWerkz 运行时织入：Spring采用的方式，通过动态代理的方式，实现简单 一个简单的代码实现：记录请求的信息 123456789@RestControllerpublic class HelloController &#123; @GetMapping(&quot;/hello&quot;) public String hello()&#123; String sentence = &quot;Hello World&quot;; System.out.println(sentence); return sentence; &#125;&#125; 新建切面类： 12345678910111213141516171819202122232425@Aspect@Componentpublic class RequestLogAspect &#123; private static final Logger logger = LoggerFactory.getLogger(RequestLogAspect.class); @Pointcut(&quot;execution(public * com.imooc.framework.controller..*.*(..))&quot;) public void webLog()&#123;&#125; @Before(&quot;webLog()&quot;) public void doBefore(JoinPoint joinPoint)&#123; //接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); //记录下请求内容 logger.info(&quot;URL: &quot;+ request.getRequestURI().toString()); logger.info(&quot;IP: &quot; + request.getRemoteAddr()); &#125; @AfterReturning(returning = &quot;ret&quot; ,pointcut = &quot;webLog()&quot;) public void doAfterReturning(Object ret)&#123; //处理完请求，返回内容 logger.info(&quot;RESPONSE: &quot; + ret); &#125;&#125; AOP主要名词概念 Aspect:通用功能代码的实现，切面 普通的java类RequestLogAspect Target:被织入Aspect的对象 HelloController Join Point：可以作为切入点的机会，所有的方法都可以作为切入点 所有方法的执行处，如前面的hello方法 Pointcut:Aspect实际被应用在的Join Point，支持正则 1@Pointcut(&quot;execution(public * com.imooc.framework.controller..*.*(..))&quot;) Advice:类里的方法以及这个方法如何织入到目标方法的方式 前置通知（Before） 后置通知（AfterReturning） 异常通知（AfterThrowing） 最终通知（After） 环绕通知（Around） Weaving:Aop的实现过程,将切面应用到实际对象从而创建一个新的代理对象的过程 AOP的实现：JdkProxy和Cglib 由AopProxyFactory根据AdvisedSupport对象配置来决定 默认策略如果目标是接口，则用JDKProxy来实现，否则用后者 JDKProxy的核心：InvocationHandler接口和Proxy类 Cglib:以继承的方式动态生成目标类的代理（如果某个类被标记成final它是无法使用Cglib做动态代理的） JDKProxy:通过Java的内部反射机制实现 Cglib:借助ASM实现，一种能够操作字节码的框架 反射机制在生成类的过程中比较高效 ASM在生成类之后的执行过程中比较高效 代理模式：接口+真实实现类+代理类简单代码实现： 新建一个接口实现pay方法 真实实现类和代理类都要实现该方法 在代理类中注入真实实现类，在代理类的实现方法pay()中调用真实实现类的pay()方法，然后增加做自己的业务逻辑 123public interface Payment&#123; void pay();&#125; 1234567public RealPayment implements Payment&#123; @Override public void pay()&#123; System.out.println(&quot;作为用户我只关心支付&quot;) &#125;&#125; 1234567891011121314151617public AliPay implements Payment&#123; private Payment payment; public AliPay(Payment payment) public void beforePay()&#123; System.out.println(&quot;从招行取款&quot;) &#125; @Override public void pay()&#123; beforePay()； payment.pay(); afterPay(); &#125; public void afterPay()&#123; System.out.println(&quot;支付给慕课网&quot;) &#125;&#125; 12Payment proxy = new AliPay(new RealPayment);proxy.pay(); Spring里的代理模式的实现 真实实现类的逻辑包含在了getBean方法里 getBean方法返回的实际上是Proxy实例 Proxy实例是Spring采用JDK Proxy或CGLIB动态生成的 底层逻辑代码实现：AbstractAutoProxyCreator.postProcessAfterInitialization() -&gt; wrapIfNecessary() -&gt;createProxy()-&gt;ProxyFactory.getProxy()-&gt;ProxyCreatorSupport.createAopProxy()-&gt;ProxyCreatorSupport.DefaultAopProxyFactory-&gt;DefaultAopProxyFactory.createAopProxy() 最终看到生成代理的最底层方法，这里只能说Spring的结构真实太复杂了，层层调用 0.0 123456789101112public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (!config.isOptimize() &amp;&amp; !config.isProxyTargetClass() &amp;&amp; !this.hasNoUserSuppliedProxyInterfaces(config)) &#123; return new JdkDynamicAopProxy(config); &#125; else &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: Either an interface or a target is required for proxy creation.&quot;); &#125; else &#123; return (AopProxy)(!targetClass.isInterface() &amp;&amp; !Proxy.isProxyClass(targetClass) ? new ObjenesisCglibAopProxy(config) : new JdkDynamicAopProxy(config)); &#125; &#125;&#125; Spring事务的相关问题 ACID 隔离级别 事务传播 可参考 什么是事务传播行为 可参考 spring的4种事务特性，5种隔离级别，7种传播行为]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>IOC</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程与并发]]></title>
    <url>%2F2019%2F11%2F05%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[进程和线程的区别进程和线程的由来 串行：初期的计算机智能执行任务，并且需要长时间等待用户输入 批处理：预先将用户的指令集中成清单，批量串行处理用户指令，仍然无法并发执行 进程：进程独占内存空间，保存各自运行的状态，互不干扰可以相互切换，为并发处理任务提供了可能 线程：共享进程的内存资源，相互间切换更快速，支持更细粒度的任务控制，使进程内的子任务得以并发执行 进程是资源分配的最小单位，线程是CPU调度的最小单位 所有与进程相关的资源都被记录在PCB中 进程是抢占处理机的调度单位；线程属于某个进程，共享其资源 线程只由堆栈寄存器、程序计数器和TCB组成 进程和线程的区别 线程不能看做独立应用，而进程可以看做独立应用 进程有独立的地址空间，相互不影响，线程只是进程不同的执行路径 线程没有独立的地址空间，多进程的程序比多线程程序健壮 进程的切换比线程的切换开销大 进程和线程的关系 Java对操作系统提供的功能进行封装，包括进程和线程 运行一个程序会产生一个进程，进程包含至少一个线程 每个进程对应一个JVM实例，多个线程共享JVM里的堆 Java采用单线程的编程模型，程序会自动创建主线程 主线程可以创建子线程，原则上要后于子线程完成执行 线程start和run方法的区别start()方法回去调用JVM的StartThread的方法，去创建一个新的子线程，并通过ThreadRun方法去调用run方法 调用start方法会创建一个新的子线程 run方法只是Thread的一个普通方法的调用 Thread和Runnable是什么关系 Thread是实现了Runnabela接口的类，使得run支持多线程 因类的单一继承原则，为了提升系统可扩展性推荐业务类实现Runnable接口，将业务逻辑封装在run()方法里例子1234567891011121314151617181920212223//Thread的使用public class MyThread extends Thread &#123; private String name; public MyThread(String name)&#123; this.name = name; &#125; @Override public void run()&#123; for(int i = 0 ; i &lt; 10 ; i ++)&#123; System.out.println(&quot;Thread start : &quot; + this.name + &quot;,i= &quot; + i); &#125; &#125;&#125;//测试类 public static void main(String[] args) &#123; MyThread mt1 = new MyThread(&quot;Thread1&quot;); MyThread mt2 = new MyThread(&quot;Thread2&quot;); MyThread mt3 = new MyThread(&quot;Thread3&quot;); mt1.start(); mt2.start(); mt3.start(); &#125; 12345678910111213141516171819202122232425//Runable的使用public class MyRunnable implements Runnable &#123; private String name; public MyRunnable(String name)&#123; this.name = name; &#125; @Override public void run()&#123; for(int i = 0 ; i &lt; 10 ; i ++)&#123; System.out.println(&quot;Thread start : &quot; + this.name + &quot;,i= &quot; + i); &#125; &#125;//测试类 public static void main(String[] args) throws InterruptedException &#123; MyRunnable mr1 = new MyRunnable(&quot;Runnable1&quot;); MyRunnable mr2 = new MyRunnable(&quot;Runnable2&quot;); MyRunnable mr3 = new MyRunnable(&quot;Runnable3&quot;); Thread t1 = new Thread(mr1); Thread t2 = new Thread(mr2); Thread t3 = new Thread(mr3); t1.start(); t2.start(); t3.start(); &#125; 如何实现处理线程的返回值如何给run方法传参 构造函数传参 成员变量传参 回调函数传参 如何实现处理线程的返回值 主线程等待法：让主线程循环等待，直到目标子线程返回值 使用Thread类的join()阻塞当前线程以等待子线程处理完毕 通过Callable接口实现：通过FutureTask Or 线程池获取; 代码实现：FutureTask获取返回值 123456789101112131415161718192021222324public class MyCallable implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception&#123; String value=&quot;test&quot;; System.out.println(&quot;Ready to work&quot;); Thread.currentThread().sleep(5000); System.out.println(&quot;task done&quot;); return value; &#125;&#125;public class FutureTaskDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; FutureTask&lt;String&gt; task = new FutureTask&lt;String&gt;(new MyCallable()); new Thread(task).start(); if(!task.isDone())&#123; System.out.println(&quot;task has not finished, please wait!&quot;); &#125; System.out.println(&quot;task return: &quot; + task.get()); &#125;&#125; 代码实现：通过线程池获取返回值 1234567891011121314151617//定义一个线程池ExecutorService newCacheThreadPool = Executors.newCachedThreadPool();//提交到线程池Future&lt;String&gt; feture = newCacheThreadPool.submit(new MyCallable());if(feture.isDone())&#123; System.out.println(&quot;task has not finished,wait&quot;);&#125;try &#123; System.out.println( feture.get() );&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;finally &#123; //关闭线程池 newCacheThreadPool.shutdown();&#125; 使用线程池的好处：提交多个实现Callable的类，让线程池并发的执行结果，方便对实现Callable的类做统一管理 线程的状态六个状态线程的六个状态 新建（New）：创建后尚未启动的线程的状态 运行（Runnable）：包含Running和Ready，处于Running状态的线程位于可运行线程中，等待被线程调度选中，获取CPU的使用权；处于Ready状态的线程位于线程池中，等待被线程调度选中，获取CPU的使用权，Ready状态的线程在获取CPU时间后，就会变成Running状态的线程 无限期等待（Waiting）：不会被分配CPU执行时间，需要显示被唤醒，即： 1）没有设置Timeout参数的Object.wait方法。 2）没有设置Timeout参数的Thread.join方法。 3）LockSupport方法。 限期等待（Timed Waiting）：在一定时间后会由系统自动唤醒。以下情况会造成限期等待： 1）Thread.sleep()方法 2）设置了Timeout参数的Object.wait()方法 3）设置了Timeout参数的Thread.join()方法 4）LockSupport.parkNanos()方法 5）LockSupport.parkUntil()方法 阻塞状态（Blocked）：等待获取排它锁,在另外一个线程放弃锁的时候发生 结束（Terminated）：已终止线程的状态，线程已经结束执行 sleep 和 wait的区别基本的差别sleep是Thread的方法，wait是Object类中定义的方法sleep()方法在任何地方都可以使用wait()方法只能在synchronized方法或synchronized块中使用最本质的区别Thread.sleep只会让出CPU,不会导致锁行为的改变Object.wait不仅让出CPU,也会释放锁已经占有的同步资源锁，所以wait在synchronized中使用才有意义例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class WaitSleepDemo &#123; public static void main(String[] args) &#123; final Object lock = new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;thread A is waiting to get lock&quot;); synchronized (lock)&#123; try &#123; System.out.println(&quot;thread A get lock&quot;); Thread.sleep(20); System.out.println(&quot;thread A do wait method&quot;); lock.wait(); System.out.println(&quot;thread A is done&quot;); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); try&#123; Thread.sleep(10); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;thread B is waiting to get lock&quot;); synchronized (lock)&#123; try &#123; System.out.println(&quot;thread B get lock&quot;); System.out.println(&quot;thread B is sleeping 10 ms&quot;); Thread.sleep(10); Thread.sleep(2000); System.out.println(&quot;thread B is done&quot;); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;).start(); &#125; &#125; notify和notifyall的区别 锁池 entryList ： 假设线程A已经拥有了某个对象（不是类）的锁，而其它线程B、C想要调用这个对象的synchronized方法（或者块），由于B、C线程在进入对象的synchronized方法（或者块）之前必须先获得该对象锁的拥有权，而该对象的锁目前被线程A锁占有，此时B、C线程就会被阻塞，进入一个地方去等待锁的释放，这个地方便是该对象的锁池 等待池 WaitList： 假设线程A调用了某个对象的wait方法，线程A就会释放该对象的锁，同时线程A就进入到了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的锁 notifyAll 会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会notify 只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 yield函数 当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意让出CPU使用的暗示，但是线程调度器可能会忽略这个暗示 关于 Thread.yield() 提示线程调度器表示当前线程可以让出 CPU， 但是调度器可能选择忽略 yield 不会改变当前同步锁的状态 1234567891011121314151617public static void main(String[] args) &#123; Runnable yieldTask = new Runnable() &#123; @Override public void run() &#123; for (int i = 1; i &lt;= 10; i++) &#123; System.out.println(Thread.currentThread().getName() + i); if (i == 5) &#123; Thread.yield(); &#125; &#125; &#125; &#125;; Thread t1 = new Thread(yieldTask, &quot;A&quot;); Thread t2 = new Thread(yieldTask, &quot;B&quot;); t1.start(); t2.start();&#125; interrupt 函数已经被抛弃的方法 stop（） suspend（）和resunme（）原因：暴力中断线程，如A调用B的stop去终止B线程，由于A不知道B的运行状态，突然停止将可能导致B的一些清理工作无法完成，stop（）方法执行后会马上释放锁，这可能引发数据不同步的问题 目前使用的方法 调用interrupt（），通知线程应该中断了1）如果线程处于阻塞状态，那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常2）如果线程处于正常活动状态，那么会将该线程的中断标记设置为true。被设置中断标志的线程将继续正常运行，不受影响 需要被调用的线程配合中断1）在正常运行任务时，进程检查本线程的中断标志位，如果被设置了中断标志就自行停止线程2）如果线程处于正常活动状态，那么会将该线程的终端标记设置为true。被设置中断标志的线程将继续正常运行，不受影响 线程状态以及线程状态之间的转换]]></content>
      <categories>
        <category>Java多线程与并发</category>
      </categories>
      <tags>
        <tag>进程和线程</tag>
        <tag>start和run</tag>
        <tag>Thread和Runnable</tag>
        <tag>notify</tag>
        <tag>yield</tag>
        <tag>interrupt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java垃圾回收之垃圾回收器]]></title>
    <url>%2F2019%2F11%2F02%2FJava%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前置概念 Stop-the-World： JVM由于要执行GC而停止了应用程序的执行 任何一种GC算法中都会发生 多数GC优化通过减少Stop-the-world发生的时间来提高程序性能 Safepoint 垃圾收集器的安全点 分析过程中对象引用关系不会发生变化的点 产生Safepoint的地方：方法调用；循环跳转；异常跳转 安全点数量得适中 常见的垃圾收集器 JVM的运行模式 Server:启动较慢,采用的重量级虚拟机，对程序采用了更多的优化；启动稳定后运行速度比Client快 Client:启动较快 垃圾搜集器之间的联系 年轻代垃圾收集器Serial收集器（-XX:UseSerialGC,复制算法） 单线程收集，进行垃圾收集时必须暂停所有工作线程 简单高效，Client模式下默认的年轻代收集器 尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间短适合与用户交互的程序，良好的响应速度能提升用户体验 ParNew收集器（-XX:+UseParNewGC,复制算法） 多线程收集，其余行为、特点和Serial收集器一样 单核执行效率不如Serial,在多核下执行才有优势；默认开启的收集线程数和CPU数量相同 Parallel Scavenge收集器（-XX:+UseParallelGC,复制算法） 比起管住用户线程停顿时间，更关注系统的吞吐量，高吞吐量可以高效的利用cpu时间尽可能快完成任务，适合在后台运算而不需要太多交互任务的情况 在多核模式下执行才有优势，Server模式下默认的年轻代收集器 配合自适应调节策略 -XX:+UseAdaptiveSizePolicy 把内存管理的调优任务交给虚拟机完成 吞吐量 = 运行用户代码时间/(运行用户代码时间+垃圾收集时间) 老年代垃圾收集器Serial Old收集器（-XX:UseSerialOldGC,标记-整理算法） 单线程收集，进行垃圾收集时必须暂停所有工作线程 简单高效，Client模式下默认的老年代收集器 Parllel Old收集器（-XX:+UseParallelOldGC,标记-整理算法） 多线程收集，吞吐量优先 进行垃圾收集时必须暂停所有工作线程 单核执行效率不如Serial,在多核下执行才有优势 CMS收集器（-XX:+UseConcMarkSweepGC,标记-清除算法） 初始标记：stop-the-world 并发标记：并发追溯标记，程序不会停顿 并发预清理：查找执行并发标记阶段从年轻代晋升到老年代的对象 重新标记：暂停虚拟机，扫描CMS堆中剩余对象 并发清理：清理垃圾对象，程序不会停顿 并发重置：重置CMS收集器的数据结构 由于是标记清除算法，会带来内存空间碎片化的问题 G1收集器（-XX:+UseG1GC,复制+标记-整理算法）Garbage Firlst收集器的特点： 并发和并行，使用多个cup缩短stop-the-world的时间，与用户线程并发执行 分代收集，独立管理整个堆 空间整合，解决内存碎片 可预测的停顿 Garbage First收集器： 将整个堆内存划分为多个大小相等的Region 年轻代和老年代不再物理隔离 问题整理：Object的finalize()方法的作用是否与C++的解析函数作用相同 与C++的析构函数不同，析构函数调用确定，而它的是不确定的 将未被引用的对象放置于F-Queue队列 方法执行随时可能被终止 给予对象最后一次重生机会 一个例子： 12345678910111213141516171819202122public class Finalization &#123; public static Finalization finalization; @Override protected void finalize()&#123; System.out.println(&quot;Finalized&quot;); finalization = this; &#125; public static void main(String[] args) &#123; Finalization f = new Finalization(); System.out.println(&quot;First print: &quot; + f); f = null; System.gc(); try &#123;// 休息一段时间，让上面的垃圾回收线程执行完成 Thread.currentThread().sleep(1000); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; System.out.println(&quot;Second print: &quot; + f); System.out.println(f.finalization); &#125;&#125; Java中的强引用，软引用，弱引用，虚引用有什么用？ 强引用（Strong Reference） 最普遍的引用：Object obj = new Object() 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象 通过将对象设置为null来弱化引用，使其被回收 软引用（Soft Reference）: 对象处在有用但非必须的状态 ; 只有当内存空间不足时，GC会回收该引用的内存 ; 可以用来实现高速缓存 一个例子： 12Stirng str = new String(&quot;abc&quot;);//强引用SoftRefence&lt;String&gt;softRef = new SoftRefence&lt;String&gt;(str);//弱引用 弱引用（Weak Reference） 非必须的对象，比软引用更弱一些 GC时会被回收 被回收的概率也不大，因为GC线程优先级比较低 适用于引用偶尔被使用且不影响垃圾收集的对象 虚引用（Phantom Reference） 不会决定对象的生命周期 任何时候都可能被垃圾收集器回收 跟踪对象被垃圾收集器回收的活动，起哨兵作用 必须和引用队列ReferenceQueue联合使用 123String str = new String(&quot;abc&quot;);ReferenceQuence queue = new ReferenceQuence();PhantomReference ref = new PhantomReference(str,queue) 引用队列（ReferenceQueue） 无实际存储结构，存储逻辑依赖于内部节点之间的关系来表达 存储关联的企鹅杯GC的软引用，弱引用以及虚引用]]></content>
      <categories>
        <category>GC相关</category>
      </categories>
      <tags>
        <tag>新生代垃圾收集器</tag>
        <tag>老年代垃圾收集器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java垃圾回收之回收算法]]></title>
    <url>%2F2019%2F11%2F02%2FJava%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B9%8B%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[标记-清除算法（Mark and Sweep） 标记：从根集合进行扫描，对存活的对象进行标记 清除：对堆内存从头到尾进行线性遍历，回收不可达对象内存 缺点：由于标记清除不需要进行对象的移动，并且仅对不存活的对象进行处理。会产生大量不连续的内存碎片。 复制算法（Copying） 分为对象面和空闲面 对象在对象面上创建 对象面上的内存不足时，存活的对象被从对象面复制到空闲面 将对象面所有对象内存清除 优点 解决碎片化问题 顺序分配内存，简单高效 适用于对象存活率低的场景（年轻代） 标记-整理算法（Compacting） 标记：从根集合进行扫描，对存货的对象进行标记 清除：移动所有存活的对象，切按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收 优点 避免内存的不连续行 不用设置两块内存互换 适用于对象存活率高的场景（老年代） 分代收集算法（Generational Collector） 垃圾回收算法的组合拳 按照对象生命周期的不同划分区域以采取不同的垃圾回收算法 目的：提高JVM的回收效率 GC的分类 Minor GC:发生在年轻中的垃圾收集动作，采用复制算法；年轻代是所有Java对象出生的地方 Full GC:与老年代相关 年轻代：尽可能快速地收集掉那些生命周期短的对象 Eden区（刚创建的对象） 两个Survivor区（幸存者区）新生代占用1/3堆空间，其中Eden 8/10, from1/10 ,to 1/10老年代 2/3堆空间 年轻代垃圾回收的过程： 对象创建在Eden区，当Eden区满了之后会触发一次Minor GC，把标记为存活的对象复制到Survivor0中，清理所有使用过的Eden区域，存活对象年龄+1； 当Eden区再次被填满，触发回Minor GC，会把Eden区和survivor0区中标记为存活的对象都复制到survivor1中，Eden和Survivor0区域将会被清空，周而复始 当对象达到一定年龄（默认15岁），会成为老年代；对于一些较大的对象，年轻代无法装下，会直接进入老年代 对象如何晋升到老年代？ 经历一定Minor次数依然存活的对象 Survivor区中或Eden区中存放不下的对象，对象优先在Eden区中分配 新生成的大对象（-XX:+PretenuerSizeThreshold） 常用的调优参数 XX:SurvivorRatio:Eden和Survivor的比值，默认8：1 XX:NewRatio:老年代和年轻代大小的比例 MaxTenuringThreshold:对象从年轻代晋升到老年代经过GC次数的最大阈值 老年代:存放生命周期较长的对象 标记-清理算法 标记-整理算法 当触发老年代的垃圾回收的时候，会伴随着新生代堆内存的回收，即对整个堆的垃圾回收。 Full GC和Major GC Full GC比Minor GC慢，但执行效率低 触发Full GC的条件 老年代空间不足 永久代空间不足（JDK8以前的版本） CMS GC时出现promotion failed,concurrent mode failure Minor GC晋升到老年代的平均大小大于老年代的剩余空间 调用System.gc() 使用RMI来进行RPC或管的JDK应用，每小时执行1次Full GC]]></content>
      <categories>
        <category>GC相关</category>
      </categories>
      <tags>
        <tag>回收算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java垃圾回收之标记算法]]></title>
    <url>%2F2019%2F11%2F02%2FJava%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B9%8B%E6%A0%87%E8%AE%B0%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[对象被判定为垃圾的标准 没有被其他对象引用 如何判断一个对象不被引用？ 引用计数算法 可达性分析算法 引用计数算法：判断对象的引用数量 通过判断对象的引用数量来决定对象是否可以被回收 每个对象实例都有一个引用计数器，被引用则+1，完成引用则-1 任何引用计数为0的对象实例可以被当做垃圾收集 优点：执行效率高，程序执行受影响较小缺点：无法检测出循环引用的情况，导致内存泄漏 可达性分析算法通过判断对象的引用链是否可达来决定对象是否可以被回收 比如方法区中的类静态属性引用的对象，是可以作为GC Root的， 123public class House &#123; public static Area area = new Area(new Street());&#125; 而Area里面有一个复合对象Street 123456public class Area &#123; private Street street; public Area(Street street)&#123; this.street = street; &#125;;&#125; 那么area 这个静态变量实例就是GC Roots，而Street就类似于Object1 2这些，所以通过Area能找到Street那么它就是可达的。 可作为GC Root的对象 虚拟机栈中引用的对象（栈帧中的本地变量表） 方法区中的常量引用的对象 方法区中的类静态属性引用的对象 本地方法栈中JNI(Natie方法)的引用对象 活跃线程的引用对象]]></content>
      <categories>
        <category>GC相关</category>
      </categories>
      <tags>
        <tag>标记算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的内存模型常见问题]]></title>
    <url>%2F2019%2F10%2F30%2FJava%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[JVM三大性能调优参数-Xms -Xmx -Xss的含义 -Xss：规定的每个虚拟机栈（堆栈）的大小。一般情况下，256K足够。此配置将会影响此进程中并发线程数的大小 -Xms：初始java堆的大小，即该进程刚创建出来的时候java堆的大小。 -Xmx：一旦对象容量超过-Xms大小，则将java堆大小扩容至改参数。为防止heap扩容导致内存抖动，影响程序运行稳定性，一般设置成与Xms一样大小 Java内存模型中堆和栈的区别内存分配策略静态存储：编译时确定每个数据目标在运行时的存储空间需求栈式存储：数据区需求在编译时未知，运行时模块入口前确定堆时存储：编译时或运行时模块入口都无法确定，动态分配 Java内存模型中堆和栈的区别联系：引用对象、数组时，栈里定义变量保存堆中目标的首地址管理方式：栈自动释放，堆需要GC空间大小：栈比堆小碎片相关：栈产生的碎片远小于堆分配方式：栈支持静态和动态分配，而堆仅支持动态分配效率：栈的效率比堆高 元空间、堆、线程独占部分间的联系-内存角度 不同JDK版本之间的intern()方法的区别——JDK6 VS JDK6+12Stirng s = new String (&quot;a&quot;);s.intern(); JDK6: 当调用intern 方法时，如果字符串常量池先前已创建出该字符串对象，则返回池中的该字符串的引用。否则，将此字符串对象添加到字符串常量池中，并且返回该字符串对象的引用JDK6+: 当调用intern 方法时，如果字符串常量池先前已创建出该字符串对象，则返回池中的该字符串的引用。否则，如果该字符串对象已经存在于java堆中，则将堆中对此对象的引用添加到字符串常量池中，并且返回该引用；如果堆中不存在，则在池中创建该字符串并返回其引用]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2019%2F10%2F30%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[内存简介计算机所有程序都是内存中运行的。在程序执行过程中，需要不断的将内存的逻辑地址和物理地址相互映射，找到相关的指令以及数据去执行。作为操作系统进程，java运行时受限于操作系统架构提供的可寻址空间。操作系统架构的可寻址空间由系统位数决定。 32位处理器：2^32的可寻址范围 64位处理器：2^64的可寻址范围地址空间的划分内核空间用户空间 JVM内存模型-JDK8 线程私有：程序计数器、虚拟机栈、本地方法栈 线程共享：MetaSpace、Java堆 程序计数器（Program Counter Register） 程序计数器（逻辑的），是当前线程所执行的字节码的行号指示器。 改变计数器的值来选取下一条需要执行的字节码命令 和线程是一对一的关系即“线程私有” 。由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程独立存储，这种内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie 方法，这个计数器值则为空（Undefined）。 因为只计数，所以不用担心内存泄露的问题 Java虚拟机栈（Stack） Java 方法执行的内存模型 每个方法执行时都会创建一个栈帧，包含多个栈帧。Java 虚拟机栈用来存储栈帧，栈帧持有局部变量和部分结果以及参与方法的调用与返回，方法调用结束时帧才会被销毁 局部变量表：包含方法执行过程中的所有变量操作数栈：入栈、出栈、复制、交换、产生消费变量 递归引发java.lang.StackOverflowError异常 原因：递归层数过多，当线程执行一个方法时就随之创建一个对应的栈帧，并将建立的栈帧压入虚拟机栈中，当方法执行完毕的时候便会当栈帧出栈，因此可知线程当前执行的方法所对应的的栈帧必定位于Java栈的顶部，而我们的递归函数不断去调用自身，每一次方法调用会涉及：第一，每新调用一次方法就会生成一个栈帧第二,它会保存当前方法的栈帧状态将它放到虚拟机栈中第三,栈帧上下文切换的时候会切换到最新的方法栈帧当中，而由于我们每个线程虚拟机栈深度是固定的，递归实现将导致栈的深度增加，每次递归都会往栈里压入一个栈帧，如果超出的最大允许的深度就会报StackOverfolwError 虚拟机栈过多引发java.lang.OutOfMemoryError异常当虚拟机栈可以自动扩展但是无法申请到新的内存空间时就会抛出java.lang.OutOfMemoryError异常例如： 12345678910public void stackLeakByThread()&#123; while(true)&#123; new Thread()&#123; public void run()&#123; while(true)&#123; &#125; &#125; &#125;.start() &#125;&#125; 本地方法栈 与虚拟机栈相似，主要用于标注了native方法 元空间（MetaSpace）元空间和永久代都是用来存储class的相关信息包括class对象的method和field等 ;在8以后使用元空间（使用本地内存）替代永久代（使用JVM内存）,原先位于方法区的字符串常量池被移到堆中 ;元空间和永久代均是方法区的实现，方法区只是JVM的规范 元空间（MetaSpace）与永久代（PermGen）的区别 元空间使用本地内存，而永久代使用的是JVM的内存 MetaSpace相比PermGen的优势 字符串常量池存在永久代中，容易出现性能问题和内存溢出 类和方法的信息大小难以确定，给永久代的大小指定带来困难 永久代会为GC带来不必要的复杂性 方便HotSpot与其它JVM如Jrockit的集成,永久代是HotSpot VM特有的，别的VM没有永久代 Java堆（Heap） 对象实例的分配区域 GC管理的主要区域]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>线程独占</tag>
        <tag>线程共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈ClassLoader]]></title>
    <url>%2F2019%2F10%2F26%2F%E8%B0%88%E8%B0%88ClassLoader%2F</url>
    <content type="text"><![CDATA[类从编译到执行的过程 编译器将Robot.java源文件编译为Robot.class字节码文件 ClassLoader将字节码转化为JVM中的 Class&lt; Robot &gt;对象 JVM利用Class&lt; Robot &gt;对象实例化为Robot对象 谈谈ClassLoaderClassLoader主要工作在Class装载的加载阶段，主要作用是从系统外部获取Class二进制数据流。它是Java的核心组件，所有的Class都是由ClassLoader进行加载的，负责通过将Class文件里的二进制数据流装载进系统，然后交给Java虚拟机进行连接，初始化等操作。 ClassLoader 的种类 BootStrapClassLoader：C++编写，加载核心库 java.* ExtClassLoader：Java编写，加载扩展库javaa.* AppClassLoader：Java编写，加载程序所在目录 自定义ClassLoader：Java编写，定制化加载 可能不在系统classpath范围内 ClassLoader双亲委派机制 自底而上检查类是否已经加载Custom ClassLoader–App ClassLoader–Extension ClassLoader–BootStrap ClassLoader 自上而下尝试加载类BootStrap:加载 jre\lib\rt.jar 或者 Xbootclasspath选项指定的jar包Extension:加载 jre\lib\ext*.jar 或者 Djava.ext.dirs指定目录下的jar包App: 加载ClassPath 或者 Djava.class.path所指定的目录下的类和jar包 为什么使用双亲委派机制 避免多份同样字节码的加载 类的装载过程 加载：通过ClassLoader加载class文件字节码生成Class对象 链接： 校验：检查加载的class的正确性和安全性 准备：为类变量分配存储空间并设置类变量初始值 解析：JVM将常量池内的符号引用转换为直接引用 初始化：执行类变量赋值和静态代码块 loadClass和forName的区别Class.forName是类加载到初始化的步骤Classloader.loadClass是刚执行完加载class Class.forName已完成初始化，那为什么还要用LoadClass呢？存在即合理；LoadClass在springIOC中资源加载器获取要读入的资源的时候，即读取一些bean的配置文件的时候，如果是以classPath方式来加载的话 就需要使用Classload.loadClass来加载，之所以这样做是和springIOC的lazy-loading（懒加载）有关，springIOC为了加快初始化速度因此大量使用延迟加载技术而使用ClassLoad不需要执行类中的初始化代码（static）步骤和链接步骤，这样子做可以加快加载速度 ，把类的初始化工作留到实际使用到这个类的时候才去做.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>ClassLoader</tag>
        <tag>类的装载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM如何加载class文件]]></title>
    <url>%2F2019%2F10%2F26%2FJVM%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BDclass%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Java虚拟机Java虚拟机：抽象化的计算机，通过在实际的计算机上个仿真模拟计算机功能来实现的，有自己完善的硬件架构：处理器，堆栈，寄存器等，还具有相应的指令系统，jvm 屏蔽了与具体操作系统平台相关的信息，使得java程序只需要生成在java虚拟机上运行的字节码，就可以在不同平台上不加修改的运行。其中最重要的两点：JVM内存结构模型，GC jvm是内存中的虚拟机，jvm的存储就是内存，所有写的 类，常量，变量，方法都在内存中这决定着程序的健壮和高效 Class Loader ： 依据特定格式，加载class文件到内存 Runtime Data Area ：JVM内存空间结构模型 Native Interface: 融合不同开发语言的原生库为Java所用 Execution Engine ：对命令进行解析 JVM结构： Class Loader, Runtime Data Area, Execution Engine, Native Interface Java反射机制JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 写一个反射的例子Robot.java 1234567891011package com.interview.javabasic.reflectpublic class Robot&#123; private String name; public void sayHi(String helloSentence)&#123; System.out.println(helloSentence + &quot;&quot; + name) &#125; private String throwHello(String tag)&#123; return &quot;Hello&quot; + tag; &#125;&#125; ReflectSample.java 1234567891011121314151617181920public static void main(String[] args)&#123; //先获取Robot类，需要全路径 Class rc = Class.forNam(&quot;com.interview.javabasic.reflect.Robot&quot;) //创建实例,需要强转，newInstance返回的是泛型 Robot r = (Robot)rc.newInstance(); System.out.println(&quot;Class name is &quot; + rc.getName()); //通过反射获取私有方法,throwHello接收一个String类型的参数 Method getHello = rc.getDeclaredMethod( name: &quot;throwHello&quot;,String.class)； getHello.setAccessible(true); //需要传入对象实例，和方法参数 Object str = getHello.invoke(r,&quot;Bob&quot;); System.out.println(&quot;getHello result is &quot; + str); //第二种获取方法获取方法 Method sayHi = rc.getMethod( name: &quot;sayHi&quot;,String.class)； sayHi.invoke(r,&quot;Welcome&quot;); //获取私有类型的Filed Filed name = rc.getDeclaredField(name: &quot;name&quot;); name.setAccessible(true); name.set(r,&quot;Alice&quot;)&#125; Metohd:newInstance()方法返回的是泛型。getDeclaredMethod可以获得该类所有的方法，除去继承和实现了接口的方法。如果是私有的方法，必须使用setAccessible(true)方法。getMethod可以获得该类所有的公有方法，还有所继承的以及实现了接口的方法。 Field:getDeclaredField获取属性如果是私有属性也要设置setAccessible(true)]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM内存结构模型</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈我对Java的理解]]></title>
    <url>%2F2019%2F10%2F25%2F%E8%B0%88%E8%B0%88%E6%88%91%E5%AF%B9Java%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[谈谈我对Java的理解从以下几个点进行扩展 平台无关性：一次编译到处运行GC垃圾回收：不用手动释放内存语言特性：泛型、lamda、反射面向对象：封装、继承、多态类库：自带的集合和并发库异常处理 Compile Once,Run Anywhere如何实现（如何实现平台无关的）？编译时：javac (查看字节码 javac -p)运行时：java.java文件首先经过javac编译生成字节码。将字节码保存在.class文件中。.class文件是跨平台的基础。再由不同平台的JVM进行解析，java语言在不同的平台上运行时不需要进行重新编译，java虚拟机在执行字节码的时候，把字节码转换成具体平台上的机器指令。 为什么jvm不直接执行源码，而是将字节码解析成机器码才去执行 每次执行都需要各种检查（语法，句法，语义的检查，每次执行的时候，这些语义分析结果不会被保留下来。因此引入字节码，在每次执行程序是不需要各种校验和补全的） 兼容性，可以将别的语言（groovy,scala）解析成字节码]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java特性</tag>
        <tag>平台无关性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux体系结构]]></title>
    <url>%2F2019%2F10%2F21%2FLinux%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux 体系结构 体系结构主要分为用户态（用户上层活动）和内核态 内核：本质是一段管理计算机硬件设备的程序 系统调用：内核的访问接口，是一种不能再简化的操作 公用函数库：系统调用的组合拳 Shell：命令解释器，可编程 远程登录终端利用ssh登录远程服务器 安装ssh： 1yum install ssh 启动ssh： 1service sshd start 登录远程服务器： 123ssh -p 50022 my@127.0.0.1输入密码：my@127.0.0.1: -p 后面是端口 my 是服务器用户名 127.0.0.1 是服务器 ip 回车输入密码即可登录 如何查找特定的文件find1语法：find path 【options】 params 作用：在指定目录下查找文件 常用的方式~表示当前用户的目录 1234 find ~ -name &quot;target1.java&quot; :查找精确文件 find ~ -name &quot;target*&quot; :查找精确文件 find ~ -iname &quot;target*&quot; :不区分文件名大小写去查找文件 man find : 更多关于find指令的使用说明 检索文件内容1语法：grep 【options】 pattern file 全称：Global Regular Expression Print作用：在指定目录下查找文件 12例如：查找包含内容&quot;moo&quot; 以target开头的文件grep &quot;moo&quot; target* 管道操作符|可将指令连接起来，前一个指令的输出作为后一个指令的输入 12例如：查找当前用户下以target开头的文件find ~ | grep &quot;target*&quot; 常用的方式123456781.在内容（文件）里面查找包含某字段的文件，并展示出对应行内容grep &apos;partial\[true\]&apos; bac-plat-al-data.info.log 2.-o 筛选出符合正则表达式的内容grep -o &apos;engine\[[0-9a-z]*\]&apos; 3.-v 过滤掉包含相关字符串的内容grep -v &apos;grep&apos; 对文件内容做统计场景：我想筛选出 partial为true的引擎，并统计日志里出现的次数。当我们发现某个检索引擎的partial为true超过一定次数后，说明该引擎需要从集群中摘掉进行修复； awk1语法：awk [options] &apos;cmd&apos; file 一次读取一行文本，按输入分隔符进行切片，切成多个组成部分 将切片直接保存在内建的变量中，$1,$2,..($0表示行的全部) 支持对单个切片的判断，支持循环判断，默认分隔符为空格 常用的方式12345678打印出第一列和第四列的内容：awk &apos;&#123;print $1,$4&#125;&apos; 文件名筛选出列指定字符的行：awk &apos;$1==&quot;tcp&quot; &amp;&amp; $2==1&#123;print $0&#125;&apos; 文件名打印出表头：awk &apos;($1==&quot;tcp&quot; &amp;&amp; $2==1) || NR==1 &#123;print $0&#125;&apos; 文件名以指定分隔符分割内容：awk -F &quot;,&quot; &apos;&#123;print $2&#125;&apos; 文件名 12Linux 命令 awk 统计：awk &apos;&#123;enginearr[$1]++&#125;END&#123;for (i in enginearr) print i &quot;\t&quot; enginearr[i]&#125;&apos; enginearr ：自定义的数组，如果第一列$1出现重复就自增1END ：扫描统计结束{for(i in enginearr)}：循环自定义的数组，定义变量 iprint i : 打印 i“\t” 拼接回车符enginearr[i] : 指定自定义数组 批量替换文本内容sed1语法：sed [option] &apos;sed command&apos; filenae 全名stream editor,流编辑器适合用于对文本的行内容进行处理 常用的方式12345678910111213141.将文件中以Str开头的字符串替换成 String：sed -i &apos;s/^Str/String/&apos; replace.txt2.将末尾的点号转为分号：sed -i &apos;s/\.$/\;/&apos; replace.txt3.将所有的&quot;Jack&quot;替换成&quot;me&quot;sed -i &apos;s/Jack/me/g&apos; replace.txt4.删除空行命令sed -i &apos;/^ *$/d&apos; replace.txt5.删除包含特定字符的行：sed -i &apos;/Integer/d&apos; replace.txt 特别指出： 指令中加入 -i 表示修改保存到文件中 替换语法后加入 /g 表示将文件中所有符合条件的内容全部替换，否则只替换一行中第一次匹配到的字符 总结：经常用到的Shell命令 find grep 管道操作符| awk sed]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis集群]]></title>
    <url>%2F2019%2F10%2F21%2FRedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Pipeline及主从同步]]></title>
    <url>%2F2019%2F10%2F21%2FPipeline%E5%8F%8A%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化方式]]></title>
    <url>%2F2019%2F10%2F21%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[RDB(快照)持久化：保存某个时间点的全量数据快照]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>RDB</tag>
        <tag>AOF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现异步队列]]></title>
    <url>%2F2019%2F10%2F20%2F%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[用list作为队列rpush 作为生产者生产消息， lpop 作为消费者消费消息缺点： 没有等待 队列里有值就直接消费弥补：可以通过在应用层引入sleep机制去调用lpop重试； 如果不用 sleep机制 ，可以使用 blpop key[key..] timeout 阻塞直到队列有消息或者超时缺点：一个生产者对应一个消费者 pub/sub 主题订阅模式发送者 pub 发送消息，订阅者 sub 接受消息订阅者可以订阅任意数量的频道缺点： 消息无状态，无法保证可达]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>异步队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过Redis实现分布式锁]]></title>
    <url>%2F2019%2F10%2F18%2F%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[什么是分布式锁分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁的实现 分布式锁需要解决的问题 互斥性：任意时刻只能有一个客户端获取到锁 安全性：锁只能被持有该锁的客户端删除 死锁：获取锁的客户端因为某些原因宕机而未能释放锁，其他客户端再也无法获取到该锁而导致的死锁 容错：当部分Redis节点宕机了之后客户端仍然能够获取锁和释放锁SENTNX key value:如果key不存在，则创建并赋值 时间复杂度 O(1) 返回值：设置成功，返回1；设置失败，返回0 1234get locknx(nil)setnx locknx test(integer)1 setnx 操作是原子性的，初期被用来实现分布式锁；在执行某段代码逻辑的时候先尝试使用setnx对某个key设值，如果设置成功则证明此时没有别的线程在执行该段代码（占用该独占资源），这个时候线程就可以顺利的执行该段代码逻辑，如果设置失败则证明有别的程序或线程占用该资源。当前线程需要等待直至setnx成功 如何解决SETNX长期有效的问题EXPIRE key seconds 设置key的生存时间，当key过期时（生存时间为0），会被自动删除 缺点：原子性得不到满足 12//设置过期时间2秒钟expire locknx 2 伪代码示例： 12345678RedisService redisService = SpringUtils.getBean(RedisService.class)long status = redisService.setnx(key,&quot;1&quot;)if(status == 1)&#123; redisService.expire(key,expire); //执行独占资源逻辑 doOcuppiedWord()&#125; 潜在问题，在setnx后线程挂掉，key将会被一直占用 SET key value [EX seconds][PX milliseconds][NX|XX]ex:设置键的过期时间为单位妙px:设置键的过期时间为单位毫秒NX:只在键不存在时，才对键进行设置操作XX:只在键已经存在时，才对键进行设置操作设置成功返回ok,否则返回nil 1set locktarget 12345 ex 10 nx 大量的key同时过期的注意事项集中过期，由于清除大量的key很耗时，会出现短暂的卡顿现象解决方案：在设置key的过期时间的时候，给每个key加上随机值]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis简介]]></title>
    <url>%2F2019%2F10%2F16%2FRedis%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[缓存中间件——Memcache和Redis的区别Mecache：代码层次类似Hash 支持简单数据类型 不支持数据持久化存储 不支持主从 不支持分片Redis 数据类型丰富 支持数据磁盘持久化存储 支持主从 支持分片 为什么Redis能这么快100000+QPS(QPS既query per second 每秒内查询次数) 完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高 数据结构简单，对数据操作也简单 采用单线程，单线程也能处理高并发请求，想多核也可启动多实例 使用多路I/O 复用模型，非阻塞IO redis 是跑在单线程中的，所有的操作又是按照线性顺序执行的，但是由于读写操作等待用户输入或者输出都是阻塞的，所以io操作在一般情况下往往不能直接返回，这会导致某一文件的io阻塞，进而导致整个进程无法对其他客户端提供服务而io多路复用就是为了解决这个问题的 多路I/O复用模型FD：File Descriptor,文件描述符一个打开的文件通过唯一的描述符进行引用，该描述符是打开文件的元数据到文件本身的映射 Redis采用的I/O多路复用函数：epoll/kqueue/evport/select? 因地制宜 优先选择时间复杂度为O(1)的I/O多路复用函数作为底层实现 以时间复杂度为O(n)的select作为保底 基于react设计模式监听I/O事件 Redis常用的数据类型 String:最基本的数据类型，二进制安全 Hash:String 元素组成的字典，适合用于存储对象 List:列表，按照String元素插入顺序排序 Set:String元素组成的无序集合，通过哈希表实现，不允许重复 Sorted-Set:通过分数来为集合中的成员进行从小到大的排序 用于计数的HyperLogLog ,用于支持存储地理信息位置的Geo 从海量数据查询某一固定的前缀key使用keys对线上的业务的影响KEYS pattern：查找所有符合给定模式pattern的key KEYS指令一次性返回所有匹配的key 键的数量过大会使服务器卡顿 KEYS CURSOR [MATCH pattern][COUNT count] 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次游历 不保证每次执行都返回某个给定数量的元素，支持模糊查询 一次返回的数量不可控，只能是大概率符合count参数 12//开始迭代返回以k1开始的key,希望一次返回10个scan 0 match k1* count 10]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>多路I/O复用模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库关键语法]]></title>
    <url>%2F2019%2F10%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%B3%E9%94%AE%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[关键语法 GROUP BY HAVING 统计相关：COUNT,SUM,MAX,MIN,AVG GROUP BY 满足 SELECT子句中列名必须为分组列或者列函数 列函数对于group by子句定义的每个组各返回一个结果 HAVING 通常与GRPUP BY子句一起使用 WHERE过滤行，HAVING过滤组 出现在同一sql的顺序：WHERE&gt;GROUP BY&gt;HAVING]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB可重复读隔离级别下如何避免幻读]]></title>
    <url>%2F2019%2F10%2F16%2FInnoDB%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8B%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%B9%BB%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[InnoDB可重复读隔离级别下如何避免幻读表象：快照读（非堵塞读） –伪MVCC内在：next-key锁（行锁+gap锁） next-key锁（行锁+gap锁） 行锁 Gap锁 Gap锁Gap的定义：索引字段排序结果的左开右闭区间，例如：1，3，5，7 的Gap为（-∞,1] (1,3] (2,7] (7,+∞]Gap锁的触发条件：使用主键/唯一索引的当前读: where条件精确每一行，只触发行锁 命中部分行，不命中任何一行，触发Gap锁 使用非唯一索引的当前读: 触发Gap锁 不使用索引： 触发Gap锁，并且锁定所有的Gap，相当于锁表]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[锁模块之当前读和快照读]]></title>
    <url>%2F2019%2F10%2F16%2F%E9%94%81%E6%A8%A1%E5%9D%97%E4%B9%8B%E5%BD%93%E5%89%8D%E8%AF%BB%E5%92%8C%E5%BF%AB%E7%85%A7%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[当前读和快照读 当前读：就是加了锁的增删改查语句。读取的是记录的最新版本。读取的时候保证其他事务不能对数据进行修改。 12select ... lock in share mode ,select ... for update update,delete,insert 快照读：不加锁的非阻塞读 ，select RC、RR级别下的InnoDB的非堵塞读（快照读）如何实现 数据行里的DB_TRX_ID、DB_ROLL_PTR、DB_ROW_ID字段 DB_TRX_ID：事务ID，标识对本行数据最近一次的更新(增删改) DB_ROLL_PTR：回滚指针， 指向回滚日志undo log的一条记录，一次更新对应一条undo log记录 DB_ROW_ID：新行插入，产生一个自增ID undo日志undo log：回滚日志，存储各个老版本的数据，由undo链串起来 含insert undo log和 update undo log read view：决定当前数据看到的是哪个版本。用来做可见性判断,即我们做快照读select的时候，会针对我们查询的数据，创建出一个read view来决定当前事务能看到那个版本的数据，可能当前最新，也可能是undo log 中某个版本的数据。它遵循一个可见性算法，主要是将要修该的数据的DB_TRX_ID取出来与系统其他活跃事务id作对比，如果大于或等于就通过DB_ROLL_PTR指针取出undo log 上一层的的DB_TRX_ID直到小于这些活跃事务为止。这样保证了我们获取的数据版本是当前可见的最稳定版本。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>锁模块</tag>
        <tag>当前读</tag>
        <tag>快照读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁模块之数据事务]]></title>
    <url>%2F2019%2F10%2F12%2F%E9%94%81%E6%A8%A1%E5%9D%97%E4%B9%8B%E6%95%B0%E6%8D%AE%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库事务的四大特性ACID 原子性(Athomic) : 事务包含的全部操作要么全部执行，要么全部失败回滚 一致性(Consistency) : 事务应确保数据库的状态从一个一致状态到另一个一致状态(eg:转账问题，A和B一共2000，无论来回怎么转总和还是2000) 隔离性(Isolaton)：一个事务的执行不应该影响其它事务的执行 持久性(Durability)：一个事务的提交代表了它对数据库的修改永久保存在数据库中，当系统发生故障时确保已提交事务的更新不能丢失，确保已提交事务的更新能恢复 事务隔离级别以及各级别下的并发访问问题更新丢失（MySQL所有事务隔离级别在数据库层面上均可避免）事务A对数据进行操作时，事务B也在对同一数据更新操作并完成了提交，然后事务A遇到异常进行回滚导致事务B的更新丢失。 脏读一个事务读到另一个事务未提交的数据。 不可重复读事务A在多次读取同一数据的过程中，事务B对数据进行更新并提交，导致事务A多次读取同一数据时结果不一致。 幻读事务A读取若干行数据，事务B以插入或删除行的方式来修改事务A的结果集。 其中不可重复读与幻读比较相似，不可重复读侧重对同一数据的修改，幻读侧重插入增加或删除数据。事务隔离级别越高，对性能的影响也越大。 事务并发访问引起的问题以及如何避免 更新丢失——mysql所有事务隔离级别在数据库层面上均可避免 脏读——READ-COMMITTED事务隔离级别以上避免 不可重复读——REPEATABLE-READ事务隔离级别以上可避免 幻读——SERIALIZABLE事务隔离级别避免 事务隔离级别 更新丢失 脏读 不可重复度 幻读 未提交读 避免 发生 发生 发生 已提交读 避免 避免 发生 发生 可重复读 避免 避免 避免 发生 串行化 避免 避免 避免 避免]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>锁模块</tag>
        <tag>数据库事务</tag>
        <tag>ACID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁模块MyISAM与InooDB关于锁方面的区别]]></title>
    <url>%2F2019%2F10%2F11%2F%E9%94%81%E6%A8%A1%E5%9D%97MyISAM%E4%B8%8EInooDB%E5%85%B3%E4%BA%8E%E9%94%81%E6%96%B9%E9%9D%A2%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[常见问题 MyISAM与InnoDB关于锁方面的区别是什么 数据库事务的四大特性 事务隔离级别以及各级别下的并发访问问题 InnoDB可重复度隔离级别下如何变幻读 RC、RB级别下的InnoDB的非阻塞读如何实现MyISAM与InnoDB关于锁方面的区别 MyISAM默认用的是表级锁，不支持行级锁 ，MyISAM不支持事务 InnoDB默认用的是行级锁 ，也支持表级锁，InnoDB在不走索引的时候用的是表级锁，而sql用到索引的时候用的是行级锁 值得注意的是： MyISAM默认会给select语句上共享锁(读锁) InnoDB默认不会给select语句上共享锁(读锁) 上了共享锁的可以再上共享锁但是不能上排他锁 上了排他锁的不可以再上共享锁和排他锁共享锁和排斥锁的兼容性 X S X 冲突 冲突 S 冲突 兼容 1234#查看session是否为自动提交show variables like &apos;autocommit&apos;;#将session设置为自动提交set autocommit = 1; MyISAM适合的场景 频繁执行全表count语句（有个变量保存了表的行数，可直接读该变量） 对数据进行增删改的频率不高，查询非常频繁（增删改会涉及到锁表操作） 没有事务 InnoDB适合的场景 数据增删改查相当频繁（增删改的时候只是某些行被锁，大多数情况下，避免阻塞） 可靠性要求比较高，要求支持事务 数据库锁的分类 按锁的粒度划分，表级锁，行级锁，页级锁 按锁级别划分，共享锁，排他锁 按加锁方式划分，自动锁（意向锁），显式锁（手工加锁） 按操作划分，DML锁，DDL锁 按使用方式划分，乐观锁，悲观锁]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>锁模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引额外问题之如何调优sql]]></title>
    <url>%2F2019%2F10%2F11%2F%E7%B4%A2%E5%BC%95%E9%A2%9D%E5%A4%96%E9%97%AE%E9%A2%98%E4%B9%8B%E5%A6%82%E4%BD%95%E8%B0%83%E4%BC%98sql%2F</url>
    <content type="text"><![CDATA[常见问题总结 如何定位并优化慢查询sql 联合索引的最左匹配原则的成因 索引建立的越多越好吗如何定位并优化慢sql大致思路 根据慢日志定位慢sql 12345SHOW VARIABLES LIKE &apos;%quer%&apos;; 查看慢查询是否打开set global slow_query_log =on; 打开慢查询:set global long_query_time=1; 设置慢查询最大时间超过一秒就记录为慢查询 SHOW STATUS LIKE &apos;%slow_queries%&apos;; 查看慢sql条数sudo vim /usr/local/mysql/data/VM_33_68_centos-slow.log; 查看被记录到慢日志里面的日志 使用explain等工具分析sql explain字段 type ： mysql找到数据行的方式index 和 all 是全表扫描 extra：有很多值 Using filesort ，Using temporary 最常的慢的， 修改sql或者尽量让sql走索引 具体走那个索引是mysql查询优化器决定， 要强制制定走某个索引 要加上 force index（primary/其他） 联合索引的最左匹配原则 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询（&gt; , &lt; , between, like ）就停止匹配，比如a=3 and b = 4 and c &gt; 5 and d =6 如果建立（a，b，c，d）顺序的索引，d是用不到索引的，如果建立（a，b，d，c）的索引则可以用到，a、b、d的顺序可以任意调整 =和in可以乱序，比如a=1 and b=2 and c=3建立（a,b,c）索引可以任意顺序，mysql查询优化器会帮你优化成索引可以识别的形式 索引是建立得越多越好吗 数据量小的表不需要建立索引，建立索引会增加额外的索引开销 数据变更需要维护索引，因此更多的索引意味着更多的维护成本 更多的索引也意味着更多的空间]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密集索引和稀疏索引]]></title>
    <url>%2F2019%2F10%2F11%2F%E5%AF%86%E9%9B%86%E7%B4%A2%E5%BC%95%E5%92%8C%E7%A8%80%E7%96%8F%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[密集索引和稀疏索引的区别 密集索引文件中的每个搜索码值都对应一个索引值 稀疏索引文件只为索引码的某些值建立索引项 InnoDB 和 MyISAM InnoDB 采用密集索引+稀疏索引,主键索引可以直接找到叶子节点中的数据,辅助键索引需要先找到主键再通过主键B+树找到数据 ,即InnoDB数据和索引是存放在一个文件里的 MyISam 全部采用稀疏索引,根据主键和辅助键的索引都只能找到一个地址信息,要再根据这个地址信息去另外一个文件中寻找数据,即MyISam的索引和数据是分开存放的 表结构都存储在*.frm中MyISAM索引和数据是分开存储的.MYI存储索引.MYD存储数据InnoDB索引和数据是存在一起的.ibd]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>索引</tag>
        <tag>密集索引</tag>
        <tag>稀疏索引</tag>
        <tag>InnoDB</tag>
        <tag>MyISAM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化你的索引]]></title>
    <url>%2F2019%2F10%2F10%2F%E4%BC%98%E5%8C%96%E4%BD%A0%E7%9A%84%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[二叉查找树二叉树,(有明显缺陷的数据结构): 如果添加的数据一直在某一侧的时候,就会变成线性而二叉树,查询复杂度会上升,查找效率会大幅度降低 影响数据检索最根本的原因是IO,即数据库文件的读写，也就是将硬盘的数据读到内存中而我们的二叉树在检索深度每次加1后都需要读取一个节点,执行一次IO,效率很低 B-TreeB-TREEB树的定义： 根节点至少包含两个孩子 树中每个节点最多含有m个孩子（ m &gt;= 2） 除根节点和叶节点外，其他每个节点至少有 ceil(m/2)个孩子 所有叶子节点都位于同一层 假设每个非终端节点包含有n个关键字信息，其中 Ki(i=1,…n)为关键字，关键字按顺序排序K(i-1)&lt;Ki 关键字个数n必须满足 : [cell(m/2)-1]&lt;=n&lt;=m-1 非叶子节点的指针：P[1],p[2],….,p[M];其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1],K[i])的子树 B+-TreeB+树定义： 非叶子节点的子树指针和关键字个数相同 非叶子节点的子树指针P[i],指向关键字值[K[i],K[i+1])的子树, 大于等于 K[i] 小于 K[i+1] 非叶子节点仅用来做索引，数据都保存在叶子节点中 所有叶子节点均有一个链指针指向下一个叶子节点 B+Tree更适合用来存储索引 B+ 树的磁盘读写代价更低（程序运行，往往最耗时的操作就是IO，如果IO的次数越少，那么运行也就越快，代价也就越低，非叶子节点结构没有指向关键字对应表记录的指针，只存放索引，因此节点比B树更小） B+ 树的查询效率更加稳定，数据存放在叶节点中，也就意味着每次查询都需要经过从根节点到叶节点的查询路径，时间复杂度味为O(logn)，比较稳定 B+ 树更有利于对数据库的扫描（因为数据只存放在叶节点中，而且有顺序，所以更好的查询数据范围） Hash 索引 hash 命中key 直接定位数据，理论上高于 b-tree b+tree 只能用 = 和 in ，不能范围查询，不能排序，不能组合索引(比较hash值是否相等来查询数据,并不能代表hash值的实际大小) hash值命中同一个存放位置， 效率不稳定，有可能还不如b+ tree（想想线性二叉树）bitmap 索引bitmap位图，适用于字段值只是固定的几个，如男、女，颜色；便于高效统计。Oracle支持位图索引，数据结构了类似B+树。锁很严重，可能因为某行修改都会锁。适合并发较少，统计较多的情况]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>索引</tag>
        <tag>索引数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库架构]]></title>
    <url>%2F2019%2F10%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[如何去设计一个关系型数据库第一部分为存储部分，相当于文件系统，将数据持久化到存储设备中 第二部分为程序实例，对存储进行逻辑上的管理。 程序实例分为8个模块： 存储管理：将数据的逻辑关系转化为物理存储关系。 缓存机制：优化执行效率。 SQL解析：解析SQL语句。 日志管理：记录操作。 权限划分：进行多用户管理。 容灾机制：灾难恢复。 索引管理：优化数据查询效率。 锁管理：使数据库支持高并发。 常见问题 为什么要使用索引 什么样的信息能成为索引 索引的数据结构 密集索引和稀疏索引的区别 为什么要使用索引先说不使用索引情况下的全表扫描: 数据库存储的最小单位是块或者页,是由多行记录组成的。(一个表就是多个块或者多个页)我们把这些块或者页加载进来,然后对每个块或页进行轮询,找到目标返回,类似:要从一本字典的第一页开始查找数据,一页一页的查,如果数据量小还好,数据量大就很慢 所以我们推出索引的概念:也就是引入字典中目录的概念,我们可以通过字典的拼音,部首,进行一层又一层的有条理的查询而这些被另外定义出来的例如:拼音,部首,就可以叫做索引 简单讲就是:为了避免全表扫描,大幅提高查询数据的效率 什么样的信息能成为索引主键、唯一键、普通键 索引的数据结构 生成索引，建立二叉查找树进行二分查找 生成索引，建立B-Tree结构进行查找 生成索引，建立B+-Tree结构进行查找 生成索引，建立Hash结构进行查找]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP与HTTPS的区别]]></title>
    <url>%2F2019%2F10%2F08%2FHTTP%E4%B8%8EHTTPS%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[HTTP（Hypertext Transfer Protocol）超文本传输协议是用来在 Internet 上传送超文本的传送协议，它可以使浏览器更加高效，使网络传输减少。但 HTTP 协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险。 HTTPS(Secure Hypertext Transfer Protocol) 安全超文本传输协议是一个安全的通信通道，它基于 HTTP 开发，用于在客户计算机和服务器之间交换信息。HTTPS 使用安全套接字层(SSL)进行信息交换，简单来说 HTTPS 是 HTTP 的安全版，是使用 TLS/SSL 加密的 HTTP 协议。 HTTPS 简介 HTTP HTTPS HTTP HTTP SSL OR TLS TCP TCP IP IP HTTPS:以计算机网络通信安全为目的的传输协议 SSL(Security Sockets Layer,安全套接层) 为网络通信提供安全及数据完整性一种安全协议 是操作系统对外API ,SSL3.0 后更名为TLS 采用身份验证和数据加密保证网络通信安全和数据完整性 HTTP数据传输流程 浏览器将支持的加密算法发送给服务器 服务器选择一套浏览器支持的加密算法，以证书形式回发给浏览器 浏览器验证证书合法性，结合证书公钥加密信息发送给服务器 服务器使用私钥解密，验证哈希加密响应消息回发浏览器 浏览器解密响应消息，对消息进行验真，之后进行加密交换数据 HTTPS 和 HTTP 的区别主要为以下四点： HTTPS需要到CA申请证书，目前市面上的免费证书也不少，收费的也都比较贵。HTTP不需要 HTTP超文本传输协议明文传输，HTTPS密文传输，HTTPS基于具有安全性的SSL加密 连接方式不同，用的端口也不一样 HTTPS默认使用443端口，HTTP使用80端口 http 的连接很简单，是无状态的 ，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP的滑动窗口]]></title>
    <url>%2F2019%2F10%2F06%2FTCP%E7%9A%84%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[RTT和RTO RTT:发送一个数据包到接受对应ACK所花费的时间 RTO:重传时间间隔；RTT是根据RTO计算出来的 我们要实现对数据的批量发送，TCP要解决可靠传输和包乱序的问题，所以TCP需要知道网络实际的数据处理带宽或是数据处理速度才不会引起网络拥塞导致丢包 TCP使用滑动窗口做流量控制与乱序重排 保证TCP可靠性 保证TCP的流控特性。（流量控制：window，用于接收方通知发送方自己还有多少缓冲区可以接收数据，发送方根据接收方的处理能力发送数据，不会导致接受不过来） TCP的传输可靠性来源于确认重传机制，TCP的滑动窗口可靠性也是建立在确认重传基础上。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>滑动窗口</tag>
        <tag>RTT</tag>
        <tag>RTO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP相关]]></title>
    <url>%2F2019%2F10%2F06%2FHTTP%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[超文本传输协议HTTP主要特点 支持客户/服务器模式 简单快速 灵活 无连接 无状态 请求/响应的步骤 客户端连接到web服务器 发送HTTP请求 服务器接受请求并返回HTTP响应 释放连接TCP连接 客户端浏览器解析HTML内容 在浏览器地址键入URL，按下回车之后经历的流程 DNS解析 浏览器依据URL逐层查询DNS服务器缓存，解析URL中的域名所对应的的IP TCP连接 找到IP地址后根据IP和对应端口和服务器建立TCP连接，结合三次握手讲解 浏览器发送HTTP请求 服务器处理请求并返回HTTP响应报文 浏览器解析渲染页面 连接结束 结合四次挥手HTTP状态码五种可能的取值 1XX : 指示信息 – 表示请求已接收，继续处理 2XX : 成功–表示请求已被成功接收、理解、接受 3XX : 重定向 – 要完成请求必须进行更进一步的操作 4xx : 客户端错误 – 请求有语法错误或请求无法实现 5XX : 服务器端错误–服务器未能实现合法的请求常见状态码 200 OK : 正常返回信息 400 Bad Request : 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized : 请求未经授权，这个状态码必须和WWW-Authenticate 报头域一起使用 403 Forbidden : 服务器收到请求，但是拒绝提供服务 404 Not Found : 请求资源不存在,eg,输入错误的URL 500 Internal Server Error : 服务器发生了不可预期的错误 503 Server Unavailable : 服务器当前不能处理客户端的请求，一段时间后可能恢复正常GET请求和POST请求的区别 Http报文层面：GET将信息放在URL，POST放在报文体中 数据库层面：GET符合幂等性和安全性，POST不符合 （幂等性：对数据库多次操作获得结果是一样的。安全性：没有改变数据库中的数据） 其他层面：GET可以被缓存、被储存，而POST不行 Cookie和Session的区别Cookie简介 由服务器发给客户端的特殊信息，以文本的形式存放在客户端 客户端再次请求的时候，会把Cookie回发 服务器接收到后，会解析Cookie生成与客户端相对应的内容 Cookie 的设置以及发送过程 客户端发送HTTP Request 到服务端 服务端发送HTTP Response + Set-Cookie 客户端发送HTTP Request + Cookie 服务器发送HTTP Response Session 简介 服务器端的机制，在服务器上保存的信息 解析客户端请求并操作session id,按需保存状态信息 Session的实现方式方式 使用Cookie来实现 服务器给每个session分配一个JSESSIONID,并通过Cookie发送给客户端，当客户端发起新的请求的时候，将在Cookie头中携带这个JSESSIONID，这样服务器能够找到客户端对应的session 使用URL回写来实现 URL回写指服务器在发送给浏览器页面的所有链接中都携带JSSESSIONID的参数，点击任何一个链接都会把JSESSIONID带回服务器。 Tomcat对session的实现一开始同时实现的，使用Cookie和URL回写机制，如果发现客户端支持cookie,就继续使用cookie停止使用URL回写，如果发现Cookie被禁用，就一直使用URL回写 Cookie和Session的区别 Cookie数据存放在客户的浏览器上，Session数据放在服务器上 Session相对Cookie更安全 若考虑减轻服务器负担，应当使用Cookie]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP和UDP的区别]]></title>
    <url>%2F2019%2F10%2F06%2FTCP%E5%92%8CUDP%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[UDP简介 面向非连接 不维护连接状态，支持同时向多个客户端传输相同消息 数据包报头只有8个字节，额外开销较小 吞吐量只受限于数据生成速率，传输速率及机器性能 尽最大努力交付，不保证可靠交付，不需要维护复杂链接状态表 面向报文，不对应用程序提交的报文信息进行拆分或合并 TCP和UDP的区别 面向连接 VS 无连接 可靠性 有序性 速度 量级]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信点餐系统-service层设计]]></title>
    <url>%2F2019%2F09%2F20%2F%E5%BE%AE%E4%BF%A1%E7%82%B9%E9%A4%90%E7%B3%BB%E7%BB%9F-service%E5%B1%82%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[常用注解@Entity 表明该类为一个实体类,类名和表明要一致。@Table 当实体类映射的数据表名不同名时使用，与@Entity并列使用 @Table(name=”XXXXX”)。@DynamicUpdate 自动更新updateTime@Data 自动生成getter和setter方法以及构造方法@Transational 在测试方法中使用测试完自动回滚，数据不保存数据库 如何自动生成getter/setter,toString的方法、1.引入lombok依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt; &lt;/dependency&gt; 2.安装lombok插件3.使用注解@Data 如何根据categoryType 查询返回List 对象方法命名规则： 123List&lt;ProductCategory&gt; findByCategoryTypeIn(List&lt;Integer&gt; list)List&lt;Integer&gt; list = Arrays.asList(1,2,3,4);repository.findByCategoryTypeIn(list); JAVA8特性把List里的属性封装进另一个List 1List&lt;Integer&gt; categoryTypeList = productInfoList.strem().map(e -&gt; e.getCategoryType()).collect(Collectors.toList()) VO ViewObject 返回给前端的对象1.应根据前端需要的字段重新定义一个 VO，不要有多余字段2.VO字段应该和对象的字段名称保持一致，方便Copy属性3.@JsonProperty 注解的使用， 123//返回给前台的JSON字段 转成自定义的名称@JsonProperty(&quot;id&quot;)private String productId 写代码中的注意事项1.不要在 for循环里有查询2.不要在代码里直接写数字，应该使用枚举]]></content>
      <categories>
        <category>Spring Boot 实战</category>
      </categories>
      <tags>
        <tag>lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信点餐系统-日志框架]]></title>
    <url>%2F2019%2F09%2F18%2F%E5%BE%AE%E4%BF%A1%E7%82%B9%E9%A4%90%E7%B3%BB%E7%BB%9F-%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[使用的日志框架日志门面：SLF4J日志实现：Logback 使用slf4j 打印日志的两种方式1.手动初始化Log4j的一个实例 12Logger logger = LoggerFactory.getLogger(this.class)logger.info(&quot;info...&quot;); 2.使用注解 @Slf4j ,可以直接使用log添加依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 1log.info(&quot;info...&quot;); 使用占位符可直接打印变量123String name = &quot;root&quot;;String password = &quot;123455&quot;;log.info(&quot;name: &#123;&#125;, password: &#123;&#125;&quot; , name,password) Logback配置1.创建 logback-spring.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;configuration&gt; &lt;appender name=&quot;consoleLog&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt; %d - %msg%n &lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=&quot;fileInfoLog&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!--滚动策略,每天一个日志--&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--路径--&gt; &lt;fileNamePattern&gt; F:\log\tomcat\info.%d.log &lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name=&quot;fileErrorLog&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;!--滚动策略--&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--路径--&gt; &lt;fileNamePattern&gt; F:\log\tomcat\error.%d.log &lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;consoleLog&quot;/&gt; &lt;appender-ref ref=&quot;fileInfoLog&quot;/&gt; &lt;appender-ref ref=&quot;fileErrorLog&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>Spring Boot 实战</category>
      </categories>
      <tags>
        <tag>日志框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信点餐系统-数据库设计]]></title>
    <url>%2F2019%2F09%2F18%2F%E5%BE%AE%E4%BF%A1%E7%82%B9%E9%A4%90%E7%B3%BB%E7%BB%9F-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[数据库设计表的的构成类目表，商品表，订单主表，订单详情表 日期时间类型设置默认时间，DEFAULT CURRENT_TIMESTAMP时间类型字段自动更新数据，ON UPDATE CURRENT_TIMESTAMP SQL UNIQUE 约束UNIQUE约束唯一标识数据库表中的每条记录。UNIQUE和PRIMARY KEY 约束均为列或列激活提供了唯一性的保证。PRIMARY KEY 拥有自动定义的 UNIQUE约束。请注意，每个表可以有多个UNIQUE约束，但是每个表只能有一个 PRIMARY KEY 约束。 数据库编码使用 UTF-8 unicode(uftf8mb4)可以存表情]]></content>
      <categories>
        <category>Spring Boot 实战</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP的三次握手和四次挥手]]></title>
    <url>%2F2019%2F05%2F22%2FTCP%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP的三次握手TCP报文头source port （源端口）destination（目标端口）Sequence Number（同步序号）Acknowledgement Number（确认序号）Offset（偏移量）Reserved（保留域）TCP Flags（标志位）Window（滑动窗口）CheckSum（检验和）Urgent Pointer（紧急指针）TCP Options（定义一些可选参数） TCP报文头包含源端口及目的端口，IP地址可以唯一标识主机，TCP协议加端口可以唯一标识主机中的一个进程。可以使用IP+协议+端口来唯一标识网络中的一个进程。在一些场景下也把这种模式称为“套接字”即Socket。 TCP FlagsURG: 紧急指针是否有效ACK: 表示确认标志，携带 ACK 标志的报文也称为确认报文PSH: 提示接收端收到报文之后应该立即将数据推送给应用程序，而不是放在缓冲区排队RET: 表示要求对方重新建立连接。SYN: 同步序列号，用于建立连接过程FIN: 传输结束标志，告知对方自己即将关闭连接。 TCP三次握手流程（“握手是为了建立连接”） 在TPC/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接 第一次握手： 建立连接时，客户端发送SYN包（seq=x）到服务器，并进入SYN_SENT状态，等待服务器确认 第二次握手：服务器收到SYN包，必须确认客户的SYN(ack=x+1),同时自己也发送一个SYN包（sql=y）,即SYN+ACK包，此时服务器进入SYN_RECV状态 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1) ,此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手各个状态的意义如下： LISTEN - 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； 为什么需要三次握手才能建立连接为了初始化Sequence Number的初始值 首次握手隐患——SYN超时 Server收到Client的SYN，回复SYN-ACK的时候未收到ACK确认 Server不断重试直至超时，Linux默认5次，总共需要63秒断开连接。针对SYN Flood的防护措施客户端给服务器发送一个SYN报文，下线，服务器需要默认等63秒才会断开。通过这个方法可以耗尽服务器的SYN连接队列。 SYN队列满后，通过tcp_syncookies参数回发SYN Cookie 若为正常连接则Client会回发SYN Cookie，直接建立连接建立连接后，Client出现故障怎么办保活机制：建立TCP连接后，TCP有保活机制，以应对其中一端出现故障。若连接处于非活动状态，则开启保活功能的一方将向另一方发送保活探测报文，达到keepalive time时间间隔仍未收到响应则重试，若尝试次数达到保活探测数仍未收到对方的响应，则连接断开。 TCP的四次挥手TCP四次挥手流程（挥手是为了终止连接）第一次挥手： Client发送一个FIN,用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态； 第二次挥手： Server收到FIN后，发送ACK给Client,确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态； 第三次握手： Server发送一个FIN,用来关闭Server到Client的数据传送，Server进入LAST_ACK状态； 第四次挥手： Clien收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server,确认序号为收到的序号+1，Server进入CLOSED状态，完成四次挥手； TCP连接必须经过时间2MSL后才真正释放掉？ 保证有足够时间让对方收到ACK包 避免新旧连接混淆 为什么四次挥手才能断开连接因为TCP是全双工的，发送方和接收方都需要FIN报文和ACK报文 服务器出现大量CLOSE_WAIT状态的原因对方关闭socket连接，我方忙于读或写，没有及时关闭 检查代码，特别是释放资源的代码 检查配置，特别是处理请求的线程配置 netstat查看机器网络状态的指令12查看服务器处于各个状态下的连接数 netstat -n | awk &apos;/^tcp/&#123;++S[$NF]&#125;END(FOR(a in S) print a,S[a])&apos;]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>TCP的三次握手</tag>
        <tag>TCP的四次挥手</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基础知识]]></title>
    <url>%2F2019%2F04%2F25%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[OSI开放式互联参考模型 物理层： 定义物理设备标准（网线类型、光纤接口类型、各种传输介质的传输速率）,主要作用：传输比特流0101二进制数据 —&gt; 转化为电流强弱 —&gt; 0101 数模转换和模数转换 单位:比特 （网卡） 数据链路层： 定义了如何格式化数据以进行传输，和控制对物理介质的访问。主要作用：提供错误检测和纠正，确保数据传输可靠性。该层将比特数据组成为帧。（交换机） 网络层： 将网络地址翻译成对应的物理地址，决定数据从发送方路由到接收方，单位是数据包。有IP协议）路由器 传输层： 解决主机间的数据传输。（传输协议，流量控制，接收方接收数据快慢程度，规定发送速率；还可以分割大的数据包；TCP和UDP协议） 会话层： 定义不同机器上的用户之间建立及管理回话，解决应用程序之间的通信，自动收发包和寻址的功能 表示层： 解决不同操作系统之间的通信语法问题。信息的语法语义，加密解密，转换翻译 应用层： 规定接收方发送方必须使用一个固定长度的消息头，消息头必须使用固定的组成继续消息体的长度，关注TCP/IP协议中的http协议 OSI 参考模型并不是一个标准，概念性框架。事实的标准是 TCP/IP 四层架构参考模型 OSI的“实现” TCP/IP协议 TCP/IP四层模型（从下到上）：链路层：获取以太网首部网络层：获取IP首部传输层：获取TCP首部应用层：HTTP数据]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>OSI七层模型</tag>
      </tags>
  </entry>
</search>
